Topological Comparisons of Proximity Measures

Djamel Abdelkader Zighed, Raﬁk Abdesselam, and Asmelash Hadgu

Department of Computer Science and Statistics, ERIC laboratory,
University Lumi´ere of Lyon 2, Campus Porte des Alpes, France

{abdelkader.zighed,rafik.abdesselam}@univ-lyon2.fr,

asmelashtk@gmail.com

Abstract. In many ﬁelds of application, the choice of proximity measure directly
affects the results of data mining methods, whatever the task might be: clustering,
comparing or structuring of a set of objects. Generally, in such ﬁelds of appli-
cation, the user is obliged to choose one proximity measure from many possible
alternatives. According to the notion of equivalence, such as the one based on pre-
ordering, certain proximity measures are more or less equivalent, which means
that they should produce almost the same results. This information on equiva-
lence might be helpful for choosing one such measure. However, the complexity
O(n4) of this approach makes it intractable when the size n of the sample exceeds
a few hundred. To cope with this limitation, we propose a new approach with less
complexity O(n2). This is based on topological equivalence and it exploits the
concept of local neighbors. It deﬁnes equivalence between two proximity mea-
sures as having the same neighborhood structure on the objects. We illustrate our
approach by considering 13 proximity measures used on datasets with continuous
attributes.

Keywords: proximity measure, pre-ordering, topological equivalence.

1 Introduction

In order to understand and act on situations that are represented by a set of objects,
very often we are required to compare them. Humans perform this comparison subcon-
sciously using the brain. In the context of artiﬁcial intelligence, however, we should be
able to describe how the machine might perform this comparison. In this context, one
of the basic elements that must be speciﬁed is the proximity measure between objects.
Certainly, application context, prior knowledge, data type and many other factors
can help in identifying of the appropriate measure. For instance, if the objects to be
compared are described by boolean vectors, we can restrict our comparisons to a class
of measures speciﬁcally devoted to this data type. However, the number of candidate
measures might still remain quite large. Can we consider that all those remaining are
equivalent and just pick one of them at random? Or are there some that are equivalent
and, if so, to what extent? This information might interest a user when seeking a speciﬁc
measure. For instance, in information retrieval, choosing a given proximity measure is
an important issue. We effectively know that the result of a query depends on the mea-
sure used. For this reason, users may wonder which one more useful? Very often, users

P.-N. Tan et al. (Eds.): PAKDD 2012, Part I, LNAI 7301, pp. 379–391, 2012.
c(cid:2) Springer-Verlag Berlin Heidelberg 2012

380

D.A. Zighed, R. Abdesselam, and A. Hadgu

try many of them, randomly or sequentially, seeking a ”suitable” measure. If we could
provide a framework that allows the user to compare proximity measures and therefore
identify those that are similar, they would no longer need to try out all measures.

The present study proposes a new framework for comparing proximity measures.
We deliberately ignore the issue of the appropriateness of the proximity measure as it
is still an open and challenging question currently being studied. Comparing proximity
measures can be analyzed from different angles:

– Axiomatically, as in the works of [1], [2] and [7], where two measures are consid-

ered equivalent if they possess the same mathematical properties.

– Analytically, as in the works of [2], [3] and [7], where two measures are considered

equivalent if one can be expressed as a function of the other.

– Emperically, as in [20], where two proximity measures are considered similar if,
for a given set of objects, the proximity matrices brought about over the objects
are somewhat similar. This can be achieved by means of statistical tests such as
the Mantel test [13]. We can also deal with this issue using an approach based on
preordonance [7][8][18], in which the common idea is based on a principle which
says that two proximity measures are closer if the preorder induced in pairs of
objects does not change. We will provide details of this approach later on.

Nevertheless, these approaches can be uniﬁed depending on the extent to which they
allow the categorization of proximity measures. Thus, the user can identify measures
that are equivalent from those that are less so [3][8].

In this paper, we present a new approach for assessing the similarity between prox-
imity measures. Our approach is based on proximity matrices and hence belongs to
empirical methods. We introduce this approach by using a neighborhood structure of
objects. This neighborhood structure is what we refer to as the topology induced by the
proximity measures. For two proximity measures ui and u j, if the topological graphs
produced by both of them are identical, then this means that they have the same neigh-
borhood graph and consequently, the proximity measures ui and u j are in topological
equivalence. In this paper, we will refer to the degree of equivalence between proxim-
ity measures. In this way, we can calculate a value of topological equivalence between
pairs of proximity measures which would be equal to 1 for perfect equivalence and 0
for total mismatch. According to these values of similarity, we can visualize how close
the proximity measures are to each other. This visualization can be achieved by any
clustering algorithm. We will introduce this new approach more formally and show the
principal links identiﬁed between our approach and that based on preordonnance. So
far, we have not found any publication that deals with the problem in the same way as
we do here.

The present paper is organized as follows. In Section 2, we describe more pre-
cisely the theoretical framework and we recall the basic deﬁnitions for the approach
based on induced preordonnance. In Section 3, we introduce our approach, topological
equivalence. In section 4, we provide some results of the comparison between the two
approaches, and highlight possible links between them. Further work and new lines
of inquiry provided by our approach are detailed in Section 5, the conclusion. We also

Topological Comparisons of Proximity Measures

381

make some remarks on how this work could be extended to all kinds of proximity
measures, regardless of the representation space: binary [2][7][8][26], fuzzy [3][28] or
symbolic, [11][12].

2 Proximity Measures and Preordonnance

2.1 Proximity Measures

In this article we limit our work to proximity measures built on Rp. Nevertheless, the
approach could easily be extended to all kinds of data: quantitative or qualitative. Let
us consider a sample of n individuals x,y, . . . in a space of p dimensions. Individuals
are described by continuous variables: x = (x1, . . . ,xp). A proximity measure u between
two individual points x and y is deﬁned as follows:

u : Rp × Rp

(cid:2)−→ R

(x,y) (cid:2)−→ u(x,y)

with the following properties, ∀(x,y) ∈ Rp × Rp:
P1: u(x,y) = u(y,x).
P2: u(x,x) ≤ u(x,y)
P2’: u(x,x) ≥ u(x,y).
,
P3: ∃α∈ R: u(x,x) = α.

We can also deﬁne δ: δ(x,y) = u(x,y)− α a proximity measure that satisﬁes the fol-
lowing properties, ∀(x,y) ∈ Rp× Rp:

T1: δ(x,y) ≥ 0.
T2: δ(x,x) = 0.
T3: δ(x,x) ≤ δ(x,y).
T4: δ(x,y) = 0 ⇒ ∀z δ(x,z) = δ(y,z).
T5: δ(x,y) = 0 ⇒ x = y.

T6: δ(x,y) ≤ δ(x,z) + δ(z,y).
T7: δ(x,y) ≤ max(δ(x,z),δ(z,y)).
T8: δ(x,y) + δ(z,t) ≤ max(δ(x,z) +

δ(y,t),δ(x,t) + δ(y,z)).

A proximity measure that veriﬁes properties T1, T2 and T3 is a dissimilarity measure.
If it satisﬁes the properties T5 and T6 it becomes a distance. As shown in [1], there are
some implications between these properties: T7 ⇒ T 6 ⇐ T 8

In Table 1, we give a list of 13 conventional proximity measures.
For our experiments and comparisons, we took many datasets from the UCI-
repository and we carried out a lot of sub sampling on individuals and variables. Table
4 shows the datasets used in this work.

2.2 Preorder Equivalence

Two proximity measures, ui and u j generally lead to different proximity matrices. Can
we say that these two proximity measures are different just because the resulting matri-
ces have different numerical values? To answer this question, many authors,[7][8][18],
have proposed approaches based on preordonnance deﬁned as follows:

382

D.A. Zighed, R. Abdesselam, and A. Hadgu

Table 1. Some proximity measures

MEASURE
EUCLIDEAN

MAHALANOBIS
MANHATTAN
MINKOWSKI
TCHEBYTCHEV
COSINE DISSIMILARITY

CAN
CANBERRA
SQUARED CHORD
SC
WEIGHTED EUCLIDEAN WE
χ2
CHI-SQUARE
JEFFREY DIVERGENCE
JD
PEARSON’S CORRELATION ρ
NORMALIZED EUCLIDEAN NE

SHORT FORMULA
uE (x, y) =
EUC

(cid:2)

j=1

(x j − y j)2

∑p
(cid:2)
(x− y)t ∑−1(x− y)

γ

j=1

MAH uMah(x, y) =
|x j − y j|
MAN uMan(x, y) = ∑p
j=1
|x j − y j|γ) 1
uMinγ(x, y) = (∑p
MIN
uT ch(x, y) = max1≤ j≤p|x j − y j|
TCH
uCos(x, y) = 1− <x,y>(cid:11)x(cid:11)(cid:11)y(cid:11)
COS
|x j−y j|
uCan(x, y) = ∑p
|x j|+|y j|
√
x j −√
j=1
(cid:2)
uSC(x, y) = ∑p
y j)2
(
j=1
αi(x j − y j)2
∑p
uW E (x, y) =
j=1
(x j−m j)2
uχ2 (x, y) = ∑p
(x j log x j
uJD(x, y) = ∑p
j=1
m j
uρ(x, y) = 1−|ρ(x, y)|
(cid:2)
( x j−y jσj
uNE (x, y) =

∑p

j=1

j=1

)2

m j

+ y j log y j
m j

)

Where p is the dimension of space, x = (x j) j=1,...,p and y = (y j) j=1,...,p two points in Rp,
(αj) j=1,...,p ≥ 0, ∑−1 the inverse of the variance and covariance matrix, σ2
j the variance, γ> 0,
m j = x j+y j
2

and ρ(x, y) denotes the linear correlation coefﬁcient of Bravais-Pearson.

Deﬁnition 1. Equivalence in preordonnance: Let us consider two proximity measures
ui and u j to be compared. If for any quadruple (x,y,z,t), we have: ui(x,y) ≤ ui(z,t) ⇒
u j(x,y) ≤ u j(z,t), then, the two measures are considered equivalent.
This deﬁnition has since reproduced in many papers such as [2], [3], [8] and [28]. This
deﬁnition leads to an interesting theorem which is demonstrated in [2].

Theorem 1. Equivalence in preordonnance: with two proximity measures ui and u j,
if there is a strictly monotonic function f such that for every pair of objects (x,y) we
have: ui(x,y) = f (u j(x,y)), then ui and u j induce identical preorder and therefore they
are equivalent. The converse is also true.

In order to compare proximity measures ui and u j, we need to deﬁne an index that could
be used as a similarity value between them. We denote this by S(ui,u j). For example,
we can use the following similarity index which is based on preordonnance.

S(ui,u j) = 1

n4 ∑x ∑y ∑z ∑t δi j(x,y,z,t)

(cid:3) 1 if [ui(x,y)− ui(z,t)]× [u j(x,y)− u j(z,t)] > 0

or ui(x,y) = ui(z,t) and u j(x,y) = u j(z,t)

where δi j(x,y,z,t) =

0 otherwise

S varies in the range [0, 1]. Hence, for two proximity measures ui and u j, a value of 1
means that the preorder induced by the two proximity measures is the same and there-
fore the two proximity matrices of ui and u j are equivalent.

Topological Comparisons of Proximity Measures

383

The workﬂow in Fig 1 summarizes the process that leads to the similarity matrix

between proximity measures.

Fig. 1. Workﬂow of preorder equivalence

As an example, in Table 2 we show the similarity matrix between the 13 proximity

measures. This is the result of the work ﬂow on the iris dataset.

Table 2. Preordonnance similarities: S(ui, u j)

1

1

1

1

uE uMah uMan uMinγ uT ch uCos uCan uSC uW E uχ2 uJD uρ uNE
1

S
uE
uMah .713
uMan .966 .709
uMinγ .987 .712 .955
uT ch .954 .694 .927 .965
uCos .860 .698 .848 .864 .857 1
uCan .889 .678 .888 .886 .869 .861 1
uSC .947 .703 .935 .946 .926 .880 .932 1
uW E
uχ2
uJD .949 .704 .937 .947 .928 .880 .931 .998 .949 .997 1
uρ .857 .682 .845 .862 .856 .940 .839 .865 .857 .866 .865 1
uNE .911 .751 .915 .905 .882 .838 .872 .898 .911 .901 .899 .830 1

.951 .705 .939 .950 .930 .881 .930 .995 .951 1

1

.713 .966 .987 .954 .860 .889 .947 1

The comparison between indices of proximity measures has also been studied by
[19], [20] from a statistical perspective. The authors proposed an approach that com-
pares similarity matrices, obtained by each proximity measure, using Mantel’s test [13],
in a pairwise manner.

3 Topological Equivalence

This approach is based on the concept of a topological graph which uses a neighborhood
graph. The basic idea is quite simple: we can associate a neighborhood graph to each

384

D.A. Zighed, R. Abdesselam, and A. Hadgu

proximity measure ( this is -our topological graph- ) from which we can say that two
proximity measures are equivalent if the topological graphs induced are the same. To
evaluate the similarity between proximity measures, we compare neighborhood graphs
and quantify to what extent they are equivalent.

3.1 Topological Graphs

For a proximity measure u, we can build a neighborhood graph on a set of individuals
where the vertices are the individuals and the edges are deﬁned by a neighborhood rela-
tionship property. We thus simplify have to deﬁne the neighborhood binary relationship
between all couples of individuals. We have plenty of possibilities for deﬁning this re-
lationship. For instance, we can use the deﬁnition of the Relative Neighborhood Graph
[16], where two individuals are related if they satisfy the following property:
If u(x,y) ≤ max(u(x,z),u(y,z)); ∀z (cid:13)= x,(cid:13)= y then, Vu(x,y) = 1 otherwise Vu(x,y) = 0.
Geometrically, this property means that the hyper-lunula (the intersection of the two
hyper-spheres centered on two points) is empty. The set of couples that satisfy this
property result in a related graph such as that shown in Figure 2. For the example shown,
the proximity measure used is the Euclidean distance. The topological graph is fully
deﬁned by the adjacency matrix as in Figure 2.

⎛

⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎝

⎞

⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎠

...

...

...

...

Vu . . . x y z t u . . .
... . . .
...
x . . . 1 1 0 0 0 . . .
y . . . 1 1 1 1 0 . . .
z . . . 0 1 1 0 1 . . .
. . . 0 1 0 1 0 . . .
t
u . . . 0 0 1 0 1 . . .
...
... . . .

...

...

...

...

...

...

Fig. 2. Topological graph built on RNG property

In order to use the topological approach, the property of the relationship must lead
to a related graph. Of the various possibilities for deﬁning the binary relationship, we
can use the properties in a Gabriel Graph or any other algorithm that leads to a related
graph such as the Minimal Spanning Tree, MST. For our work, we use only the Relative
Neighborhood Graph, RNG, because of the relationship there is between those graphs
[16].

3.2 Similarity between Proximity Measures in Topological Frameworks

From the previous material, using topological graphs (represented by an adjacency ma-
trix), we can evaluate the similarity between two proximity measures via the similarity

Topological Comparisons of Proximity Measures

385

Fig. 3. Workﬂow of topological equivalence

between the topological graphs each one produces. To do so, we just need the adjacency
matrix associated with each graph. The workﬂow is represented in Figure 3.

Note that Vui and Vu j are the two adjacency matrices associated with both proximity
measures. To measure the degree of similarity between the two proximity measures, we
just count the number of discordances between the two adjacency matrices. The value
is computed as:

S(Vui

,Vu j

) = 1

n2 ∑x∈Ω ∑y∈Ω δi j(x,y) where δi j(x,y) =

(cid:3) 1 if Vui

0 otherwise

(x,y) = Vu j

(x,y)

S is the measure of similarity which varies in the range [0,1]. A value of 1 means that
the two adjacency matrices are identical and therefore the topological structure induced
by the two proximity measures in the same, meaning that the proximity measures con-
sidered are equivalent. A value of 0 means that there is a full discordance between the
(x,y) ∀ω∈ Ω 2 ). S is thus the extent of agreement between
two matrices ( Vui
the adjacency matrices. The similarity values between the 13 proximity measures in the
topological framework for iris are given in Table 3.

(x,y) (cid:13)= Vu j

Table 3. Topology similarities: S(ui, u j)

1

1

S
uE uMah uMan uMinγ uT ch uCos uCan uSC uW E uχ2 uJD uρ
uE
1
uMah .978
1
uMan .988 .974
uMinγ .998 .977
uT ch .980 .966
uCos .973 .972
uCan .982 .975
uSC .989 .979
uW E
.978
uχ2
.989 .979
uJD .989 .979
uρ
.971 .971
uNE .985 .979

.982
.973 .959
.981 .967 .971
.987 .973 .974 .988
.998 .980 .973 .982 .989
.987 .973 .974 .988
.987 .973 .974 .988
.970 .958 .980 .969 .971 .971 .971 .971
.984 .971 .972 .983 .985 .985 .985 .985 .970

.987
.971
.968
.984
.984
.988
.984
.984
.967
.984

.989
.989

1

1
1

1

1
1

1

1

1

1

1

1

uNE

1

386

D.A. Zighed, R. Abdesselam, and A. Hadgu

4 Relationship between Topological and Preordonnance

Equivalences

4.1 Theoretical Results

We have found some theoretical results that establish a relationship between topolog-
ical and preordonnance approaches. For example, from Theorem 1 of preordonnance
equivalence we can deduce the following property, which states that in the case where
f is strictly monotonic then if the preorder is preserved this implies that the topology is
preserved and vice versa. This property can be formulated as follows:

Property 1. Let f be a strictly monotonic function of R+ in R+, ui and u j two proximity
measures such that: ui(x,y) → f (ui(x,y)) = u j(x,y) then,

ui(x,y) ≤ max(ui(x,z) , ui(y,z)) ⇔ u j(x,y) ≤ max(u j(x,z) , u j(y,z)).

Proof. Let us assume that max(ui(x,z) , ui(y,z)) = ui(x,z),

by Theorem 1, we provide ui(x,y) ≤ ui(x,z) ⇒ f (ui(x,y)) ≤ f (ui(x,z)),
ui(y,z) ≤ ui(x,z) ⇒ f (ui(y,z)) ≤ f (ui(x,z))
again,
⇒ f (ui(x,z)) ≤ max( f (ui(x,z)), f (ui(y,z))),
u j(x,y) ≤ max(u j(x,z),u j(y,z)).

hence the result,
The reciprocal implication is true, because if f is continuous and strictly monotonic
(cid:15)(cid:16)

−1 is continuous in the same direction of variation as f .

then its inverse f

Proposition 1. In the context of topological structures induced by the relative neigh-
bors graph, if two proximity measures ui and u j are equivalent in preordonnance, they
are necessarily topologically equivalent.
Proof. If ui ≡ u j (preordonnance equivalence) then,

ui(x,y) ≤ ui(z,t) ⇒ u j(x,y) ≤ u j(z,t) ∀x,y,z,t ∈ Rp.
We have, especially for t = x = y and z (cid:13)= t,
ui(x,y) ≤ ui(z,x) ⇒ u j(x,y) ≤ u j(z,x)
ui(x,y) ≤ ui(z,y) ⇒ u j(x,y) ≤ u j(z,y)

we deduce, ui(x,y) ≤ max(ui(z,x),ui(z,y)) ⇒ u j(x,y) ≤ max(u j(z,x),u j(z,y))
using symmetry property P1,
ui(x,y) ≤ max(ui(x,z),ui(y,z)) ⇒ u j(x,y) ≤ max(u j(x,z),u j(y,z))
hence, ui ≡ u j (topological equivalence).

(cid:15)(cid:16)

It is easy to show the following theorem from the proof of property 1.

Theorem 2. Equivalence in topology. Let ui and u j be two proximity measures, if there
is a strictly monotonic function f such that for every pair of objects (x,y) we have:
ui(x,y) = f (u j(x,y)) then, ui and u j induce identical topological graphs and therefore
they are equivalent.

The converse is also true, i.e. two proximity measures which are dependent on each
other induce the same topology and are therefore equivalent.

Topological Comparisons of Proximity Measures

387

4.2 Empirical Comparisons

Comparison of Proximity Measures. We want to visualize the similarities between
the proximity measures in order to see which measures are close to one another. As we
already have a similarity matrix between proximity measures, we can use any classic
visualization techniques to achieve this. For example, we can build a dendrogram of
hierarchical clustering of the proximity measures. We can also use Multidimensional
scaling or any other technique such as Laplacian projection to map the 13 proximity
measures into a two dimensional space. As an illustration we show (Figure 4) the results
of the Hierarchical Clustering Algorithm, HCA, on the iris dataset according to the two
similarity matrices (Table 2 and Table 3) associated with each approach.

a) Topological structure: (RNG)

b) Pre-ordonnance

Fig. 4. Comparison of hierarchical trees

Now the user has two approaches, topological and preordonnance, to assess the
closeness between proximity measures relative to a given dataset. This assessment
might be helpful for choosing suitable proximity measures for a speciﬁc problem. Of
course, there are still many questions. For instance, does the clustering of proximity
measures remain identical when the data set changes? What is the sensitivity of the
empirical results when we vary the number of variables or samples within the same
dataset? To answer these questions we carried out a series of experiments. The core
idea of these experiments was to study whether proximity measures are clustered in the
same way regardless of the dataset used. To this end, given a dataset with N individuals
and P variables, we veriﬁed the effect of varying the sample size, N, and dimension, P,
within a given dataset and using different datasets. All datasets in our experiments were
taken from the UCI repository, [24], as shown in Table 4.

388

D.A. Zighed, R. Abdesselam, and A. Hadgu

Table 4. Datasets used in our experiments

Dataset Id

1
2
3
4
5
6
7
8

Name

Breast Tissue

Connectionist Bench

Dimension
106 × 9
208 × 60
150 × 4
360 × 91
195 × 23
Waveform Database Generator (Version 2) 5000 × 40
178 × 13
1484 × 8

Libras movement

Wine
Yeast

Iris

Parkinsons

– Sensitivity to change in dimension: To examine the effect of changing the dimen-
sion within a given dataset, the wave form data setwas used. 4 samples were gener-
ated by taking 10, 20, 30, and 40 variables from the dataset with 2000 individuals
for the topological approach and 200 samples for the preorder approach. The re-
sults given in Tables 5 and 6 respectively show that there was a slight change in the
clustering but that we could observe some stability.

– Sensitivity to change in sample size: To examine the inﬂuence of changing the num-
ber of individuals, we generated ﬁve samples from the waveform dataset varying
the sample size from 1000 to 5000 for the topological approach and 100 to 400
for the preorder approach because of the complexity of the algorithm. The number
of variables, 40, was the same for all experiments. The results of HCA clustering
using each approach are shown in Tables 7 and 8 respectively. Clearly, there was a
slight change in the clustering but it seems there was a relative stability.

– Sensitivity to varying data sets: To examine the effect of changing the data sets, the
two approaches were tested with various datasets. The results are shown in Tables
9 and 10. In the topological approach, regularity {chSqr, SC, JD} and {Euc, EucW,
Min} was observed regardless of the change in individuals and variables within the
same dataset or across different datasets.

Table 5. The inﬂuence of varying number of variables in a data set, topological

Data set

Expt
1 wave form[2000, 10] {Tch}, {Man, Can}, {Cos, Pir}, {chSqr, Sc, JD, Euc, EucW, Min, NEuc, Mah}
2 wave form[2000, 20] {Tch}, {Man, Can}, {chSqr, Sc, JD, NEuc}, {Euc, EucW, Min, Cos, Pir, Mah}
3 wave form[2000, 30] {Tch}, {Man, Can}, {chSqr, Sc, JD, NEuc, Mah}, {Euc, EucW, Min, Cos, Pir}
4 wave form[2000, 40] {Tch}, {Man, Can}, {chSqr, Sc, JD, NEuc, Mah}, {Euc, EucW, Min, Cos, Pir}

Cluster of Proximity Measures

Topological Comparisons of Proximity Measures

389

Table 6. The inﬂuence of varying number of variables in a data set, preorder

Data set

Expt
1 wave form[200, 10] {Cos, Pir}, {Mah, NEuc}, {chSqr, Sc, JD, Man, Can}, {Tch, Min, Euc, EucW}
2 wave form[200, 20] {Tch}, {Mah}, {chSqr, Sc, JD, NEuc, Man, Can}, {Pir, Cos, Min, Euc, EucW}
3 wave form[200, 30] {Tch}, {Mah}, {chSqr, Sc, JD, NEuc, Man, Can}, {Pir, Cos, Min, Euc, EucW}
4 wave form[200, 40] {Tch}, {Mah}, {ChSqr, Sc, JD, NEuc, Man, Can}, {Pir, Cos, Min, Euc, EucW}

Cluster of Proximity Measures

Table 7. The inﬂuence of varying size of individuals in a data set, topological

Expt Data set
1 wave form[1000, 40] {Tch}, {Mah}, {Man, Can}, {Euc, EucW, Cos, Min, Pir, ChSqr, Sc, JD, NEuc}
2 wave form[2000, 40] {Tch}, {Mah, Man, Can}, {Euc, EucW, Cos, Min, Pir}, {ChSqr, Sc, JD, NEuc}
3 wave form[3000, 40] {Tch}, {Man, Can}, {Euc, EucW, Cos, Min, Pir}, {ChSqr, Sc, JD, NEuc, Mah}
4 wave form[4000, 40] {Tch}, {Man, Can}, {Euc, EucW, Cos, Min, Pir}, {ChSqr, Sc, JD, NEuc, Mah}
5 wave form[5000, 40] {Tch}, {Man, Can}, {Euc, EucW, Cos, Min, Pir}, {ChSqr, Sc, JD, NEuc, Mah}

Cluster of Proximity Measures

Table 8. The inﬂuence of varying size of individuals in a data set, preorder

Expt Data set
1 wave form[100, 40] {Tch}, {Mah}, {Pir, Min, Cos, Euc, EucW}, {ChSqr, Sc, JD, NEuc, Man, Can}
2 wave form[200, 40] {Tch}, {Mah}, {Pir, Min, Cos, Euc, EucW}, {ChSqr, Sc, JD, NEuc, Man, Can}
3 wave form[300, 40] {Can}, {Man, Tch, Pir}, {Euc, EucW, Cos, Min}, {ChSqr, Sc, JD, NEuc, Mah}
5 wave form[400, 40] {Min, ChSqr}, {Man, JD, Mah, Sc, NEuc}, {Cos, Pir}, {Tch, Can, Euc, EucW}

Cluster of Proximity Measures

Table 9. The inﬂuence of varying datasets, topological

Iris [150, 4]

Cluster of Proximity Measures

Expt Data set
{Pir, Cos}, {Mah}, {Euc, EucW, Min, Tch} , {chSqr, Sc, JD, NEuc, Man, Can}
1
2 Breast Tissue[106, 9] {Sc, JD}, {Euc, EucW, Min, Tch, Man, chSqr}, {Cos, Pir}, {Mah, Can, NEuc}
{chSqr, Sc, JD }, {Euc, EucW, Min, Man, Tch}, {Pir, Cos}, {NEuc, Can, Mah}
3 Parkinsons [195, 23]
{chSqr, Sc, JD }, {Tch}, {Can, NEuc}, {Euc, EucW, Min, Cos, Pir, Man, Mah}
4 C.Bench [208, 60]
{chSqr, Sc, JD}, {Euc, EucW, Min, Man, Tch}, {Cos, Pir}, {Mah, Can, NEuc}
5 Wine [178, 13]
{chSqr}, {JD}, {Tch}, {Cos, Pir, Sc, Euc, EucW, Min, Mah, NEuc, Man, Can}
6 Yeast [1484, 8]
7 L.Movement [360, 91] {JD}, {Mah}, {Cos, Pir, Tch}, {Euc, EucW, Min, NEuc, chSqr, Sc, Man, Can}
8 wave form[5000, 40] {Tch}, {Man, Can}, {Euc, EucW, Cos, Min, Pir}, {ChSqr, Sc, JD, NEuc, Mah}

Table 10. The inﬂuence of varying datasets, preorder

Iris [150, 4]

Expt Data set
{Mah}, {Cos, Pir}, {Euc, EucW, Min, Man, Tch, NEuc} , {Can, chSqr, Sc, JD}
1
2 Breast Tissue[106, 9] {Cos, Pir}, {Sc, JD}, {Mah, Can, NEuc}, {Euc, EucW, Min, Tch, Man, chSqr}
{Mah}, {Can, NEuc}, {Cos, Pir}, {chSqr, Sc, JD ,Euc, EucW, Min, Man, Tch}
3 Parkinsons [195, 23]
{Mah}, {Can, NEuc}, {Cos, Pir}, {chSqr, Sc, JD, Euc, EucW, Min, Man, Tch}
4 Wine [178, 13]
5 L.Movement [360, 91] {Can, NEuc, WEuc, Euc, Pir}, {Man, Min}, {Mah, Tch, Sc}, {JD, Cos, ChSqr}

Cluster of Proximity Measures

5 Conclusion

In this paper, we have proposed a new approach for comparing proximity measures
with complexity O(n2). This approach produces results that are not totally identical to
those produced by former methods. One might wonder which approach is the best. We

390

D.A. Zighed, R. Abdesselam, and A. Hadgu

believe that this question is not relevant. The topological approach described here has
some connections with preordonnance, but proposes another point of view for compar-
ison. The topological approach has a lower time complexity. From theoretical analysis,
when a proximity measure is a function of another proximity measure then we have
shown that the two proximity measures are identical for both approaches. When this is
not the case, the experimental analysis showed that there is sensitivity to sample size,
dimensionality and the dataset used.

References

1. Batagelj, V., Bren, M.: Comparing resemblance measures. In: Proc. International Meeting on

Distance Analysis, DISTANCIA 1992 (1992)

2. Batagelj, V., Bren, M.: Comparing resemblance measures. Journal of classiﬁcation 12, 73–90

(1995)

3. Bouchon-Meunier, M., Rifqi, B., Bothorel, S.: Towards general measures of comparison of

objects. Fuzzy Sets and Systems 84(2), 143–153 (1996)

4. Clarke, K.R., Somerﬁeld, P.J., Chapman, M.G.: On resemblance measures for ecological
studies, including taxonomic dissimilarities and a zero-adjusted Bray-Curtis coefﬁcient for
denuded assemblages. Journal of Experimental Marine Biology & Ecology 330(1), 55–80
(2006)

5. Fagin, R., Kumar, R., Sivakumar, D.: Comparing top k lists. In: Proceedings of the Fourteenth
Annual ACM-SIAM Symposium on Discrete Algorithms. Society for Industrial and Applied
Mathematics (2003)

6. Kim, J.H., Lee, S.: Tail bound for the minimal spanning tree of a complete graph. Statistics

& Probability Letters 64(4), 425–430 (2003)

7. Lerman, I.C.: Indice de similarit´e et pr´eordonnance associ´ee, Ordres. In: Travaux Du

S´eminaire Sur Les Ordres Totaux Finis, Aix-en-Provence (1967)

8. Lesot, M.J., Rifqi, M., Benhadda, H.: Similarity measures for binary and numerical data: a

survey. IJKESDP 1(1), 63–84 (2009)

9. Lin, D.: An information-theoretic deﬁnition of similarity. In: Proceedings of the 15th Inter-

national Conference on Machine Learning, pp. 296–304 (1998)

10. Liu, H., Song, D., Ruger, S., Hu, R., Uren, V.: Comparing Dissimilarity Measures for
Content-Based Image Retrieval. In: Li, H., Liu, T., Ma, W.-Y., Sakai, T., Wong, K.-F., Zhou,
G. (eds.) AIRS 2008. LNCS, vol. 4993, pp. 44–50. Springer, Heidelberg (2008)

11. Malerba, D., Esposito, F., Gioviale, V., Tamma, V.: Comparing dissimilarity measures for
symbolic data analysis. In: Proceedings of Exchange of Technology and Know-how and
New Techniques and Technologies for Statistics, vol. 1, pp. 473–481 (2001)

12. Malerba, D., Esposito, F., Monopoli, M.: Comparing dissimilarity measures for probabilistic
symbolic objects. In: Data Mining III. Series Management Information Systems, vol. 6, pp.
31–40 (2002)

13. Mantel, N.: A technique of disease clustering and a generalized regression approach. Cancer

Research 27, 209–220 (1967)

14. Noreault, T., McGill, M., Koll, M.B.: A performance evaluation of similarity measures, docu-
ment term weighting schemes and representations in a Boolean environment. In: Proceedings
of the 3rd Annual ACM Conference on Research and Development in Information Retrieval
(1980)

15. Park, J.C., Shin, H., Choi, B.K.: Elliptic Gabriel graph for ﬁnding neighbors in a point set and
its application to normal vector estimation. Computer-Aided Design 38(6), 619–626 (2006)

16. Preparata, F.P., Shamos, M.I.: Computational geometry: an introduction. Springer (1985)

Topological Comparisons of Proximity Measures

391

17. Richter, M.M.: Classiﬁcation and learning of similarity measures. In: Proceedings der
Jahrestagung der Gesellschaft fur Klassiﬁkation. Studies in Classiﬁcation, Data Analysis and
Knowledge Organisation. Springer (1992)

18. Rifqi, M., Detyniecki, M., Bouchon-Meunier, B.: Discrimination power of measures of re-

semblance. In: IFSA 2003. Citeseer (2003)

19. Schneider, J.W., Borlund, P.: Matrix comparison, Part 1: Motivation and important issues for
measuring the resemblance between proximity measures or ordination results. Journal of the
American Society for Information Science and Technology 58(11), 1586–1595 (2007)

20. Schneider, J.W., Borlund, P.: Matrix comparison, Part 2: Measuring the resemblance between
proximity measures or ordination results by use of the Mantel and Procrustes statistics. Jour-
nal of the American Society for Information Science and Technology 58(11), 1596–1609
(2007)

21. Spertus, E., Sahami, M., Buyukkokten, O.: Evaluating similarity measures: a large-scale
study in the orkut social network. In: Proceedings of the Eleventh ACM SIGKDD Inter-
national Conference on Knowledge Discovery in Data Mining. ACM (2005)

22. Strehl, A., Ghosh, J., Mooney, R.: Impact of similarity measures on web-page clustering. In:

Workshop on Artiﬁcial Intelligence for Web Search, pp. 58–64. AAAI (2000)

23. Toussaint, G.T.: The relative neighbourhood graph of a ﬁnite planar set. Pattern Recogni-

tion 12(4), 261–268 (1980)

24. UCI Machine Learning Repository, http://archive.ics.uci.edu/ml
25. Ward, J.R.: Hierarchical grouping to optimize an objective function. Journal of the American

Statistical Association, JSTOR 58(301), 236–244 (1963)

26. Warrens, M.J.: Bounds of resemblance measures for binary (presence/absence) variables.

Journal of Classiﬁcation 25(2), 195–208 (2008)

27. Zhang, B., Srihari, S.N.: Properties of binary vector dissimilarity measures. In: Proc. JCIS

Int’l Conf. Computer Vision, Pattern Recognition, and Image Processing, vol. 1 (2003)

28. Zwick, R., Carlstein, E., Budescu, D.V.: Measures of similarity among fuzzy concepts: A

comparative analysis. Int. J. Approx. Reason 2(1), 221–242 (1987)


