Multi-Manifold Ranking: Using Multiple

Features for Better Image Retrieval

Yang Wang1,2, Muhammad Aamir Cheema1, Xuemin Lin1, and Qing Zhang2,1

1 The University of New South Wales, Sydney, Australia

{wangy,macheema,lxue}@cse.unsw.edu.au
2 Australian E-Health Research Center

Qing.Zhang@csiro.au

Abstract. Manifold Ranking (MR) is one of the most popular graph-
based ranking methods and has been widely used for information re-
trieval. Due to its ability to capture the geometric structure of the image
set, it has been successfully used for image retrieval. The existing ap-
proaches that use manifold ranking rely only on a single image manifold.
However, such methods may not fully discover the geometric structure of
the image set and may lead to poor precision results. Motivated by this,
we propose a novel method named Multi-Manifold Ranking (MMR)
which embeds multiple image manifolds each constructed using a diﬀer-
ent image feature. We propose a novel cost function that is minimized
to obtain the ranking scores of the images. Our proposed multi-manifold
ranking has a better ability to explore the geometric structure of image
set as demonstrated by our experiments. Furthermore, to improve the
eﬃciency of MMR, a speciﬁc graph called anchor graph is incorporated
into MMR. The extensive experiments on real world image databases
demonstrate that MMR outperforms existing manifold ranking based
methods in terms of quality and has comparable running time to the
fastest MR algorithm.

Keywords: Image retrieval, integrated features, manifold ranking.

1

Introduction

Traditional image retrieval techniques rely on the semantic labels attached to the
images such as image annotations [13] and tags [7]. However, a severe drawback
of such techniques is that the manual labelling is laborious, expensive and time-
consuming. Another disadvantage is that such techniques do not consider the
content of the images and this may lead to poor results especially if the quality
of the labelling is poor.

To address the issues mentioned above, content-based image retrieval (CBIR)
[10,5,12] may be used which utilizes the low-level features (e.g., color, shape,
texture) for image retrieval. These low-level features can be extracted automati-
cally and remain consistent for each image in contrast to the manually attached
labels. However, it is diﬃcult to choose an ideal descriptor for the images be-
cause the low-level features may not represent the same semantic concepts. For
example, two images having similar color visualization may have totally diﬀerent

J. Pei et al. (Eds.): PAKDD 2013, Part II, LNAI 7819, pp. 449–460, 2013.
c(cid:2) Springer-Verlag Berlin Heidelberg 2013

450

Y. Wang et al.

semantic meanings (e.g., a green apple and a tennis ball as shown in Fig. 1). This
is one of the main challenges CBIR needs to address.

query

Top Rank

Bottom Rank

Fig. 1. If only the color feature is used, the most relevant results include a green tennis
ball and a green angry bird instead of the red apple. Hence, a single feature may not
provide desired results.

To address this challenge, He et al. [4] used manifold ranking that uses low-
level features as well as the intrinsic structure of the images. The basic idea
behind the manifold ranking is as follows. A weighted graph is constructed where
the vertices represent the images and, for each vertex, its near by vertices are
connected to it by weighted edges. The queries are assigned a positive ranking
and the remaining vertices are ranked with respect to the queries. The vertices
spread their ranking scores to their neighbors via the weighted graph. The spread
process is repeated until convergence. This approach has been shown to yield
better retrieval results because it utilizes the intrinsic structure of the image
set. Xu et al. [18] proposed a faster manifold ranking approach that uses anchor
graphs [8] to approximate the original graph and provides the results of similar
quality.

The above mentioned manifold ranking techniques use a single feature. In
other words, these techniques utilize the intrinsic structure of the images based
only on a single feature. The ranking based on the single manifold may have low
precision especially if the selected feature is not very representative. Motivated by
this, in this paper, we propose a technique called multi-manifold ranking (MMR)
that ranks the images by considering multiple manifolds each constructed using a
diﬀerent feature. MMR demonstrates excellent ability to retrieve relevant images
because it considers multiple intrinsic structures of the images. We propose a
novel cost function that is minimzed to obtain the ranking scores of the images.
Our proposed approach provides better results than the existing techniques.
Furthermore, we present eﬃcient techniques to create the multiple manifolds.

We remark that Huang et al. [6] also utilizes more than one low-level features.
However, they construct only one manifold by using average manifold distance
of multiple features. Since only a single manifold is used, the proposed approach
does not preserve the original geometric structure of any of the features. In
contrast, our approach constructs multiple manifolds and utilizes the geomet-
ric structure of each feature. This enables our approach to yield better results
as demonstrated in our experiments. Furthermore, we show that our proposed
approach is more eﬃcient and can be used on large image databases.
• We propose multi-manifold ranking (MMR) that utilizes multiple intrinsic
structures of the images to provide a better ranking of the images.
• To handle large image databases, we improve the eﬃciency of MMR by using
singular value decomposition [1] as well as anchor graphs.

Our contributions in this paper are summarized below.

Multi-Manifold Ranking: Using Multiple Features for Better Image Retrieval

451

• Our extensive experimental results on real world image databases demonstrate
that our algorithm provides better retrieval results than state of the art existing
techniques (MR [4], ADF [6] and EMR [18]) that use a single manifold for image
retrieval. Furthermore, the running time of our algorithm is similar to that of
EMR and is signiﬁcantly lower than those of MR and ADF. We also present
simple extensions of MR and EMR that use more than one manifolds. Although
these extended versions demonstrate better retrieval results than the original
versions, our proposed multi-manifold ranking performs signiﬁcantly better.

The rest of the paper is organized as follows. Related work is reviewed in Sec-
tion 2. The details of multi-manifold ranking are presented in Section 3. Exten-
sive experimental study on real world image databases is presented in Section 4.
Section 5 concludes the paper.

2 Related Work

Zhou et al. [20] explored the importance of intrinsic geometrical structure of the
data. They propose manifold ranking [21] that considers the intrinsic structure
of the data for the ranking. Manifold ranking has been successfully used on
various data types such as text [15], image [4] and video [19]. He et al. [4]
are the ﬁrst to use manifold ranking for image retrieval. While the proposed
approach demonstrates good quality results, it is computationally expensive. Xu
et al. [18] propose a more eﬃcient approach that can eﬃciently handle large
image databases. They replace the original image graph with anchor graph [8]
which is signiﬁcantly smaller in size but provides the results of similar quality.
Huang et al. [6] use a probabilistic hypergraph for image retrieval. They construct
a single manifold using the average manifold distance of multiple features.

All of the above manifold ranking based approaches consider geometric struc-
ture of a single image manifold which may not precisely represent the image
content. Motivated by this, we propose a multi-manifold ranking based method
for image retrieval which exploits the geometric structure of multiple manifolds
each constructed using a diﬀerent feature. Our idea for MMR is inspired by
[3], which addresses the problem of video annotation through multi-graph using
diﬀerent video features.

3 Multi-Manifold Ranking

3.1 Preliminaries

Let X be a set containing n images, i.e. X = {x1, x2,··· , xn}. Multi-manifold
ranking assigns each image xi a ranking score Fi. F = {F1, F2,··· , Fn} is the
ranking score vector containing the score of each image. L = {L1, L2,··· , Ln} is
an indicator label vector where Li = 1 if xi is the query image, otherwise Li = 0.
Multi-manifold ranking (MMR) constructs N graphs each using a diﬀerent
feature. Gk denotes a s-NN graph constructed on X using kth feature. Specif-
ically, Gk is constructed by connecting every two vertices xi and xj if one is
among the s nearest neighbors of the other. Here, the nearest neighbors are

452

Y. Wang et al.

computed using Euclidean distance between the kth feature vectors of the im-
ages. The Euclidean distance between the kth feature vectors of xi and xj is
denoted as ||xi, xj||k.

W k denotes the edge aﬃnity matrix of Gk. Each entry W k
the similarity between xi and xj according to the kth feature vector. W k
deﬁned by a Gaussian kernel and is set to exp(−||xi, xj||2
edge in Gk between xi and xj. Otherwise, W k
of Gk where each element Dk
ii is deﬁned as Dk

ij in W k represents
ij is
k/2σ2) if there is an
ij is zero. Dk is the diagonal matrix
ii =

W k
ij .

(cid:2)n

j=1

3.2 Objective Cost Function

In this section, we propose a novel cost function, inspired by [3], to obtain the
ranking scores of the images in X. The cost function O(F ) considers N image
manifolds each constructed using a diﬀerent feature. The ranking score vector
F is obtained by minimizing the cost function O(F ) given in Eq. 1.

O(F ) =

N(cid:2)

(
k=1

1
2

n(cid:2)

i,j=1

W k
ij (

1(cid:3)

Dk
ii

Fi − 1(cid:4)
Dk
jj

2

Fj )

+ λ

n(cid:2)

i=1

(Fi − Li)

2

)

(1)

The ﬁrst term ensures that nearby points (i.e., similar images in the multiple
image manifolds) are assigned similar ranking scores. The second term is the
ﬁtting constraint which ensures that the ranking results should ﬁt the initial label
assignment. λ is the regularization trade-oﬀ parameter for the ﬁtting constraint.
∂F = 0, which leads to the following equa-

We minimize O(F ) by setting

∂O(F )

tion.

N(cid:3)

k=1

((I−(Dk)

− 1

2 W k(Dk)

2 )F +λ(F −L)) =
− 1

N(cid:3)

((1+λ)F −SkF −λL) = 0 (2)

k=1

where Sk = (Dk)
equation.

− 1

2 W k(Dk)

− 1

2 . Note that Eq. 2 is equivalent to the following

N(cid:3)

k=1

(F − Sk
1 + λ

F − λ
1 + λ

L) = 0

(3)

Let α = 1
ﬁnal optimal ranking score vector denoted by F ∗

1+λ . Eq. 3 is equivalent to

(cid:2)N
k=1(I − αSk)F = N (1 − α)L. Hence, the

can be obtained as follows.

F ∗

N(cid:3)

= (

(I − αSk))

−1N (1 − α)L

k=1

(4)

where I is the identity matrix. Since both (1 - α) and N remain the same for
all the images, they do not aﬀect the retrieval results. Therefore, F ∗
can be
obtained as follows.

F ∗

N(cid:3)

= (

k=1

(I − αSk))

−1L

(5)

Multi-Manifold Ranking: Using Multiple Features for Better Image Retrieval
Eq. 5 is the closed form for the optimal solution F ∗

. In large scale problems,
the iteration scheme is preferred [18]. Therefore, we also consider the iterative
form which is given below.

453

F (t + 1) = F (t) + μ

N(cid:3)

(F (t) − SkF (t) + λ(F (t) − L))

(6)

where F (t) is the ranking score vector at time stamp t. By setting μ = − 1
the following equation can be obtained.

N (1+λ) ,

k=1

F (t+1) = F (t)−

1

N (1 + λ)

N(cid:2)

((1+λ)F (t)−SkF (t)−λL) =

k=1

(cid:5)N

k=1(αSkF (t) + (1 − α)L)

N

(7)

Since N remains constant for all images, it is suﬃcient to consider the following
equation which omits N .

F (t + 1) =

N(cid:3)

(αSkF (t) + (1 − α)L)

k=1

(8)

The above iterative form can be used in the iterative scheme. During each it-
eration, each vertex (i.e., image) receives information from its neighbors (the
ﬁrst term) and retains its initial information (the second term). The iteration
process is repeated until convergence. By following the arguments similar to [21],
it can be shown that Eq. 8 is converged to the following equation when F (0) is
initialized to L.

F ∗

t→∞ F (t) = N (1 − α)(I − αS)

−1L

= lim

(9)
Note that both N and (1 − α) can be omitted from Eq. 9 without changing the
ﬁnal retrieval results because they are constant for all images. Therefore, the
optimal ranking results can be obtained as follows.

F ∗

t→∞ F (t) = (I − αS)

= lim

−1L

(10)

We remark that although Eq. 10 may assign negative scores to some of the
images, the relative ranking order of the images is preserved. Nevertheless, if
desired, the scores of all the images may be normalized (e.g., by shifting) such
that each image gets a positive score.

3.3 Improving the Eﬃciency of MMR

The approach we mentioned in the previous section has two major limitations.
Firstly, the time complexity for constructing the aﬃnity matrix for n data points
using s nearest neighbors is O(sn2) [8]. Secondly, the inverse matrix computation
in Eq. 5 requires O(n3). Clearly, the cost of constructing the aﬃnity matrix and
inverse matrix computation is prohibitive for large image databases. Hence, this
approach is not suitable for the large image databases.

454

Y. Wang et al.

The ﬁrst limitation can be addressed by using anchor graphs [8] in a similar
way as used in [18]. This reduces the cost from O(sn2) to O(dmn) where m (cid:2) n
and d (cid:2) n. Next, we use singular decomposition to address the second limitation
and reduce the cost from O(n3) to O(m3) where m (cid:2) n.
Let Ir denote an identity matrix of size r × r. Before we present the details

of eﬃcient matrix inversion, we prove that the following equation holds.

(N In − αHH T )

−1 =

In − H(H T H − N

α Im)

−1H T

N

(11)

Proof. We prove the correctness of the equation by showing that R.H.S. divided
by L.H.S. equals to an identity matrix.

α Im)

In−H(HT H− N

(N In − αHH T )(
=

−1HT
N In−αHHT −(N H−αHHT H)(HT H−( N
α Im+HT H)(HT H− N
N In−αHHT +αH(− N
=
= N In−αHHT +αHHT
= N In

N
N = In

N

N

N

)

α Im))

α Im)

−1HT
−1HT

(cid:2)
Based on Eq. 11, we show that the cost of the matrix operation can be reduced.
Let H k be deﬁned as following.

H k = (Dk)

2 Z k(Λk)

1
2

− 1

The following equation can be veriﬁed.

H k(H k)T = (Dk)

2 W k(Dk)

− 1

− 1

2

Recall that R.H.S. of Eq. 14 equals to Sk (see Eq. 2 in Section 3.2).

We replace Sk in Eq. 5 with its value in Eq. 15 which yields the following.

Sk = H k(H k)T

(12)

(13)

(14)

(15)

(16)

F ∗

= (N I − α

N(cid:3)

k=1

H k(H k)T )

−1L

Note that each H k(H k)T is a symmetric matrix. Hence,
symmetric matrix. Without loss of generality, we set S =
is a n × n gram matrix.

(cid:2)N

H k(H k)T is also a
H k(H k)T which

k=1
(cid:2)N

k=1

F ∗

= (N I − αS)

−1L

(17)
We decompose S by using singular value decomposition [1] S = U ΛU T such that
U T U = In. Note that the decomposition takes O(n3) but it can be eﬃciently
approximated in O(m3) by using the techniques presented in [16]. Assume that
we have obtained the approximate decomposition of S as follows.

S = UmΛmU T
m

(18)

Multi-Manifold Ranking: Using Multiple Features for Better Image Retrieval

455

where Um is a n× m matrix formed by the ﬁrst m normalized eigenvectors of U
and m equals to the number of anchor images. Λm is the diagonal matrix with m
diagonal elements (sorted in decreasing order from left to right) and correspond
to the m largest eigenvalues of S. Eq. 18 is equivalent to the following equation.

S = UmΛ

1
2

mΛ

1
2

mU T

m = Y Y T

(19)

where Y = UmΛ
equation.

1
2
m. By combining Eq. 17 and Eq. 19, we obtain the following

F ∗

= (N In − αS)

−1L = (N In − αY Y T )

−1L =

In − Y (Y T Y − N

α Im)

−1Y T

N

L

(20)
Since N remains constant for all of the images, the optimal ranking score vector
F ∗

can be obtained as follows.

F ∗

= (In − Y (Y T Y − N
α

(21)
Note that Eq. 21, requires the inversion of a m × m matrix in contrast to Eq. 5
that requires the inversion of a n × n matrix. Hence, Eq. 21 reduces the cost
from O(n3) to O(m3).

−1Y T )L

Im)

4 Experimental Results

In this section, we evaluate the performance of our proposed approach (MMR) by
using several real world image databases. All the experiments are implemented in
Matlab R2009a and C++. First, we present the experimental setup in Section 4.1.
Then, in Section 4.2, we evaluate the performance of our proposed approach.

4.1 Experimental Setup

Data Sets. We evaluated the performance of MMR on the following data sets.
• COREL: It is composed of 7700 images divided into 77 categories.
• Caltech101: This image database contains 8677 images from 101 diﬀerent cat-
egories.
• MSRC: The data set contains 18 diﬀerent categories and consists of approxi-
mately 4300 images.

Competitors. We compare our proposed approach with several manifold rank-
ing based algorithms. Below are the details.
•MR. This is the ﬁrst work [4] that applied manifold ranking (MR) for image
retrieval.
•EMR. This is the algorithm proposed by Xu et al. [18]. While MR demon-
strated good quality results, it is not suitable for large scale image databases
because of its high computational cost. EMR proposes interesting techniques to
improve the eﬃciency of MR and demonstrates that it retrieves the results of
similar quality.

456

Y. Wang et al.

•ADF. This algorithm is proposed in [6]. ADF uses multiple features to con-
struct a single image manifold.

Recall that our proposed approach uses multiple features to construct multiple
image manifolds. We argue that using multiple image manifolds yield better
results than the previous techniques. A natural question is whether previous
approaches (e.g., MR and EMR) can perform better if they also utilize more than
one features. To answer this question, we extend the previous techniques such
that they utilize multiple features. Below are the details of how each technique
is extended.
•MR+N . N denotes the total number of features used by the algorithm. Let F k
i
be the ranking score of xi computed by MR [4] using kth feature. The ﬁnal score
i . MR+N ranks the images according to the ﬁnal
F k
of each image xi is
scores. Note that MR+1 is the same as original MR algorithm proposed in [4].
•EMR+N . Similar to MR+N , EMR+N computes the score of each image ac-
cording to each feature. The images are then ranked according to their ﬁnal
scores. We remark that EMR+1 is the original EMR algorithm proposed in [18].
Later, we show that these extended versions retrieve better results than their
respective original versions. Moreover, the quality of the retrieved results im-
proves as the value of N increases. Similar to the notations used for extended
version of MR and EMR, we use MMR+N to denote that our algorithm MMR
was run using N features. Similarly, ADF+N denotes that ADF was run using
N features.

(cid:2)N

k=1

Features used by the algorithms. We use some of the most popular features
in the algorithms. More speciﬁcally, we use DoG-SIFT (Scale-Invariant Feature
Transform) [9], HOG (Histogram of Oriented Gradients) [2], LBP (Local Binary
Patterns) [11], Centrist [17] and RBG-SIFT [14]. Table 1 shows these features
in a particular order. Any algorithm using N features uses the ﬁrst N features
shown in Table 1. For example, MMR+3 is our algorithm and uses the ﬁrst three
features (DoG-SIFT, HOG and LBP). Similarly, EMR+2 denotes that EMR was
run using ﬁrst two features (DoG-SIFT and HOG). ADF+5 denotes that ADF
was run using all of the features. We remark that this order of the features best
suits EMR+N which is our main competitor.

Table 1. Features used by the algorithms

1

2

3

4

5

Feature DoG-SIFT HOG LBP Centrist RGB-SIFT

Evaluation metric. Each image in the image databases has its own category la-
bel (e.g., car, aeroplane etc.). A query is randomly selected from these databases
and a retrieved result is considered correct if its label matches with the query
label. For each query, we retrieve top-K results where the default value of K is
10 unless mentioned otherwise. We use precision as the main evaluation metric
which corresponds to the number of correct results in the top-K retrieved results
divided by K. Since K is ﬁxed for all competitors, the recall value is directly
related to the precision, i.e., if precision is high then the recall is also high and
vice versa. Hence, we use precision as the only evaluation metric.

Multi-Manifold Ranking: Using Multiple Features for Better Image Retrieval

457

Recall that our algorithm (MMR) samples m anchor points and, for each
image xi, xi is connected to its d nearest neighbors. We set m to 500 and d to 5
because our preliminary experimental evaluation demonstrated that these values
of m and d give a reasonable trade-oﬀ between the precision and eﬃciency of
the algorithm.

4.2 Performance Comparison

In this section, we compare the performance (precision and eﬃciency) of our
algorithm with the other competitors. At the end, we present a case study where
we show the top-10 results returned by MMR, EMR and ADF for three queries.

Precision. In Fig. 2, we increase the number of features used by each algorithm
and study its aﬀect on the precision. Note that the performance of each algo-
rithm improves as it uses more features. However, the precision obtained by our
algorithm (MMR+N ) is the highest. This is because our algorithm constructs
multiple manifolds and minimizes the cost function to obtain the ranking scores
in contrast to the other algorithms that use multiple features (manifolds) some-
what trivially. Note that the improvement in precision is less signiﬁcant when
N > 3. Since the running time increases with the increase in N , we choose N = 3
for rest of the experiments (unless mentioned otherwise).

i

i

n
o
s
c
e
r
P

 1

 0.9

 0.8

 0.7

 0.6

 0.5

 0.4

 0.3

MR+N
EMR+N
ADF+N
MMR+N

1

2

3

4

5

Number of features

i

i

n
o
s
c
e
r
P

 1

 0.9

 0.8

 0.7

 0.6

 0.5

 0.4

 0.3

 10

EMR+1
EMR+3
ADF+3
MMR+3

 20

 30

 40

 50

 60

 70

Number of retrieved results

(a) Eﬀect of number of features on precision

(b) Eﬀect of K on precision

Fig. 2. Eﬀect of number of features and K on precision.

As noted in [18] and observed from Fig. 2 (a), the precision of EMR+N and
MR+N is quite similar. Furthermore, EMR+N is more eﬃcient than MR+N as
we demonstrate later. Therefore, for a clearer illustration of results, in the rest
of the experiments we exclude MR+N . In Fig. 2 (b), we issue top-K queries and
vary K from 10 to 70 and study its aﬀect on the precision. We observe that the
precision of each of the algorithms remain unaﬀected with the increase in K.
Also, note that our algorithm consistently gives better results than the other
competitors.

In Fig. 3, we study the precision at a more detailed level. More speciﬁcally, we
randomly choose 90 categories from the three image databases. For each category,
we randomly choose one image as the query. For each query, we obtain top-10
results and record the precision. Fig. 3 shows the precision of each algorithm
for the queries selected from each of the 90 categories. It can be observed that

458

Y. Wang et al.

i

i

n
o
s
c
e
r
P

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1
 
0

EMR+1
EMR+3
ADF+3
MMR+3

 

5

10

15

20

25

30

35

40

45

Category

50

55

60

65

70

75

80

85

90

Fig. 3. Precision of top-10 images for randomly selected queries from each category

our approach MMR+3 consistently performs better than the other methods.
The EMR proposed in [18] (shown as EMR+1) has the lowest precision. However,
EMR+3 that uses three manifolds has better retrieval performance than ADF+N .

Running Time. In Fig. 4(a), we increase the number of features used by each
algorithm and study its aﬀect on the running time. Note that the running times
of ADF+N and MR+N are much higher than the running time of our algorithm
(MMR+N ) and EMR+N . This is because MMR+N and EMR+N present eﬃcient
techniques for matrix inversion and use the anchor graphs to approximate the
large image graphs. Also, note that EMR+N and MMR+N scale better as the
number of features increases. The cost of MR+N is the highest. In order to
better illustrate the performance of other approaches, we do not display the cost
of MR+N when N > 2.

In Fig. 4(b), we increase the size of image databases and study its aﬀect
on the running times of all algorithms. It can be observed that ADF+N and
MR+N cannot handle large scale databases (e.g., the running time is more than
80 seconds when the image database contains 8000 images). On the other hand,

)
s
d
n
o
c
e
S

i

(
 
e
m
T
 
g
n
n
n
u
R

i

80

70

60

50

40

30

20

10

0
 
1

 

MMR+N
EMR+N
MR+N
ADF+N

2

3

Number of Features

4

5

)
s
d
n
o
c
e
S
(
e
m
T
g
n
n
n
u
R

 

i

i

100

90

80

70

60

50

40

30

20

10

0

+3

ADF
MR
+1
EMR
MMR

+1

+3

0.2

0.4

0.6

0.8

1

1.2
Image Scale

1.4

1.6

1.8

2
x 104

(a)

(b)

Fig. 4. Eﬀect of number of features and image database size on running time

Multi-Manifold Ranking: Using Multiple Features for Better Image Retrieval

459

+3

MMR

+3

ADF

EMR +3

+3

MMR

+3

ADF

EMR+3

+3

MMR

+3

ADF

EMR +3

Fig. 5. Three queries are issued and top-10 results returned by MMR+3, ADF+3 and
EMR+3 are displayed. The irrelevant images retrieved by our algorithm are marked
with red square. It can be noted that MMR+3 returns more relevant results than the
other two algorithms.

our proposed algorithm scales better and can handle large scale image databases.
The cost of EMR+1 is the lowest. This is because it uses a single image manifold
whereas our algorithm MMR+3 uses three image manifolds. Nevertheless, the
running times of both of the algorithms are quite close to each other.

A case study. In this section, we display the top-10 results returned by MMR+3,
ADF+3 and EMR+3 for three diﬀerent queries. Fig. 5 displays the results re-
turned by each of the algorithms. Irrelevant results returned by our algorithm
are denoted by red square. Note that our algorithm returns more relevant results
than the other two algorithms.

5 Conclusion

In this paper, we propose a novel method name multi-manifold ranking (MMR)
which uses multiple image manifolds for image retrieval. We conduct extensive
experimental study on real world image databases and demonstrate that MMR
provides better retrieval results than state of the art techniques. Our experi-
mental results demonstrate that our algorithm is much more eﬃcient than two
existing algorithms and is comparable to the most eﬃcient existing approach.

Acknowledgments. Muhammad Aamir Cheema is
supported by AR-
CDP130103405 and ARCDE130101002; Xuemin Lin is supported by ARC
DP0987557, ARC DP110102937, ARC DP120104168 and NSFC61021004.

460

Y. Wang et al.

References

1. Christopher, P.R., Manning, D., Sch¨utze, H.: An introduction to information Re-

trieval. Cambridge University Press (2009)

2. Dalal, N., Triggs, B.: Histogram of oriented gradients for human detection. In:

CVPR, pp. 886–893 (2005)

3. Wang, M., et al.: Uniﬁed video annotation via multigraph learning. IEEE Trans.

Circuits Syst. Video Techn. 19(5), 733–746 (2009)

4. He, J., Li, M., Zhang, H., Tong, H., Zhang, C.: Manifold-ranking based image

retrieval. In: ACM Multimedia, pp. 9–16 (2004)

5. Huang, J., Kumar, S.R., Mitra, M., Jing Zhu, W.: Spatial color indexing and

applications. International Journal of Computer Vision 35(3), 245–268 (1999)

6. Huang, Y., Liu, Q., Zhang, S., Metaxas, D.N.: Image retrieval via probabilistic

hypergraph ranking. In: CVPR, pp. 3376–3383 (2010)

7. Liu, D., Hua, X.-S., Yang, L., Wang, M., Zhang, H.-J.: Tag ranking. In: ACM

WWW, pp. 351–360 (2009)

8. Liu, W., He, J., Chang, S.-F.: Large graph construction for scalable semi-supervised

learning. In: ICML, pp. 679–686 (2010)

9. Lowe, D.G.: Distinctive image features from scale-invariant keypoints. International

Journal of Computer Vision 60(2), 91–110 (2004)

10. Manjunath, B.S., Rainer Ohm, J., Vasudevan, V.V., Yamada, A.: Color and texture
descriptors. IEEE Transactions on Circuits and Systems for Video Technology 11,
703–715 (1998)

11. Ojala, T., Pietikainen, M., Maenpaa, T.: Multiresolution gray-scale and rotation
invariant texture classiﬁcation with local binary patterns. IEEE Transactions on
Pattern Analysis and Machine Intelligence 24(7), 971–987 (2002)

12. Swain, M.J., Ballard, D.H.: Color indexing. International Journal of Computer

Vision 7(1), 11–32 (1991)

13. Ulges, A., Worring, M., Breuel, T.M.: Learning visual contexts for image annota-
tion from ﬂickr groups. IEEE Transactions on Multimedia 13(2), 330–341 (2011)
14. van de Sande, K.E.A., Gevers, T., Snoek, C.G.M.: Evaluating color descriptors for
object and scene recognition. IEEE Transactions on Pattern Analysis and Machine
Intelligence 32(9), 1582–1596 (2010)

15. Wan, X., Yang, J., Xiao, J.: Manifold-ranking based topic-focused multi-document

summarization. In: IJCAI, pp. 2903–2908 (2007)

16. Williams, C.K.I., Seeger, M.: Using the nystr¨om method to speed up kernel ma-

chines. In: NIPS, pp. 682–688 (2000)

17. Wu, J., Rehg, J.M.: Centrist: A visual descriptor for scene categorization. IEEE
Transactions on Pattern Analysis and Machine Intelligence 33(8), 1489–1501 (2011)
18. Xu, B., Bu, J., Chen, C., Cai, D., He, X., Liu, W., Luo, J.: Eﬃcient manifold

ranking for image retrieval. In: ACM SIGIR, pp. 525–534 (2011)

19. Yuan, X., Hua, X.-S., Wang, M., Wu, X.: Manifold-ranking based video concept
detection on large database and feature pool. In: ACM Multimedia, pp. 623–626
(2006)

20. Zhou, D., Bousquet, O., Lal, T.N., Weston, J., Sch¨olkopf, B.: Learning with local

and global consistency. In: NIPS, pp. 592–602 (2003)

21. Zhou, D., Weston, J., Gretton, A., Bousquet, O., Sch¨olkopf, B.: Ranking on data

manifolds. In: NIPS (2003)


