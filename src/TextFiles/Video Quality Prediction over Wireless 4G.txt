Video Quality Prediction over Wireless 4G

Chun Pong Lau, Xiangliang Zhang, and Basem Shihada

CEMSE, King Abdullah University of Science and Technology, Saudi Arabia

{lau.pong,xiangliang.zhang,basem.shihada}@kaust.edu.sa

Abstract. In this paper, we study the problem of video quality predic-
tion over the wireless 4G network. Video transmission data is collected
from a real 4G SCM testbed for investigating factors that aﬀect video
quality. After feature transformation and selection on video and network
parameters, video quality is predicted by solving as regression problem.
Experimental results show that the dominated factor on video quality is
the channel attenuation and video quality can be well estimated by our
models with small errors.

Keywords: Video Quality Prediction, Wireless 4G, Superposition Coded
Multicasting.

1

Introduction

Fourth generation (4G) of mobile communication standards, such as Long Term
Evolution Advanced (LTE-Advanced) and Worldwide Interoperability for Mi-
crowave Access Release 2 (WiMAX2), provide high speed and large range of
wireless connectivity. Because of the large coverage of a base station (BS), users
within the coverage area result in diﬀerent channel quality causing the multi-
users diversity problem. In order to provide a reliable video multicast/broadcast
service by high speed wireless channels, She et al. proposed Superposition Coded
Multicasting (SCM) method in [1]. In this scheme, a scalable video bitstream
consists of two diﬀerent quality layers that are modulated into two signals by
two diﬀerent modulations. These two signals are then superimposed into one
broadcasting signal for all receivers under the BS coverage. Since the transmis-
sion of superimposed signal can be aﬀected by wireless channel conditions, the
quality of received video is key concern for both the providers and receivers.

From the video providers’ point of view, the Quality of Service (QoS) is
determined by the quality of video that customers will receive. If the quality
of video can be predicted according to network conditions and video parame-
ters, providers can guarantee certain level of service by taking eﬀective actions.
On the one hand, before broadcasting a video, providers can set the input fea-
tures/parameters to achieve the targeted video quality. On the other hand, dur-
ing video transmission, operators can adjust the video and network parameters
according to this prediction model for various conditions.

There are three main challenges facing the accurate prediction of video quality
over wireless channels. First, the behavior of wireless signal is diﬃcult to predict
and measure, since it ﬂuctuates and can be signiﬁcantly aﬀected by complex

J. Pei et al. (Eds.): PAKDD 2013, Part II, LNAI 7819, pp. 414–425, 2013.
c(cid:2) Springer-Verlag Berlin Heidelberg 2013

Video Quality Prediction over Wireless 4G

415

and mixed factors, such as attenuation, fading, and interference [2]. Attenuation
happens due to the distance between transmitter and receiver. Fading may vary
over time, position or radio frequency due to multi-path propagation. Second,
multi-user channel diversity challenge where users at diﬀerent geographic loca-
tions within the same BS coverage area have diﬀerent channel quality [3]. Third,
collecting data for analysis and prediction is expensive. In order to accurately
predict the video quality, all possible conditions that may aﬀect video quality
must be considered, and all corresponding data should be collected. Construct-
ing an emulation testbed with implementation of SCM is often expensive. To
the best of our knowledge, the testbed used in this paper is the ﬁrst built emula-
tion testbed on this research area. This work assists research work without real
testbed by building a practical prediction model. It helps to reduce the depen-
dence on the expensive testbed system through estimating transmission results,
instead of conducting real experiments.

Video quality prediction can be formalized as a regression problem. Video trans-
mission is described by a set of features, including video and network parameters.
Video quality, measured by a common quality metric called Peak Signal-to-Noise
Ratio (PSNR), is the target for prediction [4]. Given a raw data, feature selection is
ﬁrst used for selecting the useful features from the data set. Three popular regres-
sion approaches, k -nearest neighbor algorithm (k -NN), Support Vector Machines
(SVM) and Neuron Network (NN) are employed for prediction. Nominal type fea-
ture (modulation) and a ratio type feature (power boosting) are transformed to-
gether into one ratio type feature. The improved results from advance approaches
including the transformed feature demonstrate the main factors aﬀecting video
quality and should gain more attention in video transmission.

The rest of this paper is organized as follows. Section 2 introduces the back-
ground and related work of video quality prediction problem. Section 3 describes
the methodology for prediction, which consists of data collection on real testbed,
feature transformation and selection, and employed prediction techniques. Section
4 reports experimental results. Section 5 ﬁnally concludes and gives perspectives.

2 Background

Researchers face many challenges on video quality prediction. One of the diﬃcul-
ties is the videos are aﬀected by numerous parameters. Through collecting data
from simulations of 3G and WLAN network, Khan et al. predicted the video
quality with both application and network level parameters [5]. However, this
was limited to four parameters, which are frame rate, send bitrate, packet error
rate, and link bandwidth. These limited number of features cannot represent the
network condition well especially when network condition becomes complex in
the wireless 4G.

Garcia et al. proposed a framework to ﬁnd a parametric content description
of videos [6]. Assuming that video content inﬂuences the video quality, they
proposed to decompose the input video to spatial and temporal features which
highlight a strong adequation with the perceived video quality. However, predic-
tion of video quality was not quantiﬁed in their approach.

416

C.P. Lau, X. Zhang, and B. Shihada

Dalal et al. investigated the feature selection for predicting video quality after
network transmission [7]. Network statistic such as packet lost rate and error
rate were considered as features. Two methods correlation ranking and principal
component analysis (PCA) were investigated. However, video they studied were
collected from a wired network.

Liu et al. proposed a framework for video prediction after encoding process,
which can reduce time cost for choosing correct parameters for video encod-
ing process [8]. Their approach was simple and eﬃcient. However, they did not
consider the parameters of network transmission for the prediction.

All of the above reported studies omitted the wireless network characteristics
and assumed a simulation based data. Therefore, we attempt to collect real-
life data and perform more accurate prediction considering the wireless network
characteristics. In the next section, we introduce our methodology.

3 Methodology

This section introduces our proposed approach of video quality prediction. We
ﬁrst introduce the testbed for data collection. Then, as pre-processing is a cru-
cial part of prediction, we introduce feature transformation, normalization and
ranking mechanisms. Finally, k -NN, SVM and NN are introduced to build the
regression models for video quality prediction.

3.1 Testbed Description and Data Collection

Video data in this paper is collected by a real-time SCM testbed, which con-
sists of two network emulators, two personal computers (PC) and one variable
attenuator. In the transmitter side, one PC is connected to one network emula-
tor acted as the video server and BS. The other PC is connected to the second
emulator acted as the mobile receiver and mobile device. Videos are transmitted
over the emulators connected by coaxial radio frequency cables through the vari-
able attenuator acting as the wireless channel with diﬀerent values of channel
attenuation. The emulators are implemented by National Instruments NI PXIe-
1062Q chassis with embedded controller PXIe-8130, IF transceiver PXIe-5641R,
RF Up converter PXIe-5610 and RF Down converter PXIe-5600. Figure 1 shows
the system architecture of SCM with transmitter on the top. The video data
passes through all layers and become superposition coded signal broadcast over
the emulated wireless channel. Receiver receives the broadcasting signals that
go through all the layers to reconstruct the video data.

Video streams are encoded as H.264-SVC [9] bitstream, and are stored in
the video server. Each video sequence consists of two layers, base layer and
enhancement layer. Base layer contains most of the important information of
the video and should be correctly received and decoded in order to reconstruct
the video after transmission. Enhancement layer is additional information of
the base layer to improve the video quality when successfully decoded. It is
expected that enhancement layer bitrate is higher than base layer bitrate since

Video Quality Prediction over Wireless 4G

417

Fig. 1. SCM System Architecture

the encoding quantization parameters (QP) of enhancement layer is lower than
the base layer QP. Diﬀerent number of group of pictures (GOP) and intra period
are considered as the video features/parameters in the system.

From the network prospective, transmission power, and reception power sensi-
tivity are controlled by the transmitter and receiver emulators in physical layer.
Channel attenuation is controlled manually by the variable attenuator. Assume
that during each of the transmission, the attenuation value is constant to re-
main a static transmission environment to reduce complexity. Carrier frequency,
modulation, power boosting, cyclic preﬁx and bandwidth are selected from the
MAC layer control software.

A video transmission, when completed, is described by a set of video and
network features. The ﬁrst three columns of Table 1 show the features considered
in this work. The last row is the prediction target PSNR, which is commonly used
to measure the quality of the reconstructed video after network transmission. It
is calculated by comparing the video frame by frame and pixel by pixel between
the received video and the original video before encoding and transmission. A
higher PSNR value introduces a higher video quality received. Given a video with
its known feature values, our target is to predict the PSNR after it is received.
In our experiments throughout the paper, the video transmitted is a 40 sec-
onds length movie trailer, which is a standard video provided by Durian Open
Movie project named as “Sintel” [10]. Each test of experimental operation takes
around 2 minutes. In addition, calculating the PSNR value between received
video with original video requires 1 to 2 minutes. 985 testes were conducted in
total. Ten random chosen examples are shown in Table 2.

3.2 Feature Transformation

Two network features called Base Layer Modulation and Enhancement Layer
Modulation are of our interest while predicting video quality. The possible values
of these two features are BPSK, QPSK, 16QAM and 64QAM, which are diﬃcult
to be directly used for prediction. Therefore, Base Layer Modulation and Base
Layer Power Boosting are transformed to Base Layer Probability of transmitted

418

C.P. Lau, X. Zhang, and B. Shihada

Table 1. Video and network features, with statistic, Pearson correlation coeﬃcient
and P-value w.r.t. target PSNR

Features

Type Min

Max

Range Co- Pearson

P-value

unt Corr. Coef.

Video

Network

399.5
777.88
1189.3

0.116650
0.101631
0.109720
-0.107587
0.028953
-0.074944
-0.114500

739
339.5 7
3074.25 2296.4 7
3473.7 2284.3 6
3
28
2
40
3
8
32
5
1 NaN
0
2
0
-0.028953
18 -0.502685
21
2.51
1
0.000000

Ratio
Base bitrate
Ratio
Enh. bitrate
Ratio
Overall bitrate
Interval 20
Base Encoding QP
Interval 35
Enh. Encoding QP
Interval 2
Group of Pictures
Interval 2
Intra Period
0
Ratio
Transmission Power
-10
Ratio
Reception Power Sen.
2
Ratio
Attenuation
Ratio
2.51
Carrier Frequency
Nominal BPSK BPSK N/A 1 Transformed Transformed
Base Modulation
Base Power Boosting
4 Transformed Transformed
Ratio
Base Prob. of Tx Sym. Err Ratio
Nominal QPSK 16QAM N/A 2 Transformed Transformed
Enh. Modulation
Enh. Power Boosting
Ratio
7 Transformed Transformed
Enh. Prob. of Tx Sym. Err Ratio
Cyclic Preﬁx
Bandwidth

2.4360e-4
1.4037e-3
5.6144e-4
7.1926e-4
3.6404e-1
1.8652e-2
3.1721e-4
NaN
3.6404e-01
3.3726e-64
1

-3
2.328e-4 0.8858 0.0884 9

1.7421e-6
NaN
4.2871e-6

8
5
6
30
0
10
19
0

1 NaN
2

-11
0.0789

-0.190526

1.6672e-9

0.151654

2

5

0.145872

Interval 0.25
Interval 5
Ratio

25.26

11

0
0.5253 0.4465 9
0.25
10
66.91

0
5
41.64 461

Target PSNR

Table 2. Examples of video records
B. E.

Mod PB Mod

Base Enh. Overall B. E. GOP I. Tx Rx At. Freq. B.
Bitrate Bitrate Bitrate QP QP
25 35 2
520.63 1686.87 2207
25 35 2
520.63 1686.87 2207
25 35 2
739.
1634.75 2373
442.
25 35 4
1201.25 1643
415.13 991.62 1406.75 25 35 8
28 35 4
411.5
777.88 1189
25 35 4
410.63 1221.5 1189
411.5
777.88 1189
28 35 4
28 35 4
777.88 1189
411.5
399.5
3074.25 3473
20 40 4

2.51 BPSK -1 QPSK -7 1/4 10
2.51 BPSK -1 QPSK -11 1/4 10
2.51 BPSK 2
1/4 10
1/4 10
2.51 BPSK 2
2.51 BPSK 2
1/4 10
2.51 BPSK -1 QPSK -7 1/4 5
2.51 BPSK -1 QPSK -7 1/4 10

P. P. P.
0
4 0
0
4 0
2 0
0
0
8 0
0
32 0
0
16 0
0
16 0
16 0
0
0
16 0
4 0
-10 10 2.51 BPSK -1 16QAM -5 1/4 10

2
9
7
7
4
2
2
11 2.51 BPSK -1 QPSK -11 1/4 5
2.51 BPSK -1 QPSK -5 1/4 5
5

16QAM 0
16QAM 0
16QAM 0

58.5195
55.2172
58.9206
58.9995
56.7126
56.3021
55.9479
47.0903
55.5979
52.9213

E. CP BW PSNR
PB

symbol error. Similarly for Enhancement layer, Enhancement Layer Modulation
and Enhancement Layer Power Boosting are transformed to Enhancement Layer
Probability of transmitted symbol error. The idea of the transformation is con-
sidering the transmitted symbol energy and the receiver symbol decision area.
Probability of symbol error means a transmitted symbol falls into other symbols
decision area with the amount of Gaussian noise added onto it. The probability of
symbol error is calculated as follows according to [11]. Assuming that base layer
modulation is always BPSK, the probability of correctly detecting the abscissa
of each SPC symbol in the ith region is:

(cid:2)−μyi

(cid:3)

σyi

Pi,1 = Q

(1)

Video Quality Prediction over Wireless 4G

419

where μyi is the mean for received symbol abscissa coordination and σyi is the
variance. Base layer probability of transmitted symbol error is:

Pb = 1 − 2

m2−1(cid:4)
√

√
m2

M

Pi,1

(2)

where M = m1 × m2, m1 is the base layer modulation number and m2 is the

i=0

enhancement layer modulation number.

After the symbol is decoded on base layer by successive interference cancel-
lation (SIC), the remained symbol will be decoded by enhancement layer de-
modulator. The standard symbol error equation for m2-QAM demodulation is
expressed as follow:

(cid:5)

(cid:3)

(cid:2)
1 − 1√
m2

Q

Pm2QAM = 2

2

(cid:8)(cid:9)

(cid:6)(cid:7)
(cid:5)

−

3

E2
m2 − 1
N0
(cid:2)
1 − 1√
m2

2

(cid:3)

(cid:6)(cid:7)

Q

(cid:8)(cid:9)2

(3)

3

m2 − 1

E2
N0

where Q(.) is known as Q-function, E2 is the remained energy after SIC of symbol
for enhancement layer decoding process, N0 is the Gaussian noise power.

Finally the probability of enhancement symbol error is calculated as follow:

Pe = 1 − (1 − Pm2QAM )(1 − Pb)

(4)

Transformed feature Pb and Pe range from 0.00024 to 0.08858 for base layer and
0.0789 to 0.5253 for enhancement layer.

3.3 Feature Normalization

Since values of raw video features are on diﬀerent scale, normalization is per-
formed to linearly scale them to unit range. An original value x of a feature is
normalized to be x∗

:

x∗
i =

xi − xmin
xmax − xmin

(5)

where xmin is the smallest value and xmax is the largest value of the feature. To
further investigate the improvement that can be made by normalization, original
and normalized data are compared in the experimental results.

3.4 Feature Ranking

In order to eliminate irrelevant and redundant features in the raw data, supervised
feature selection is performed in data preprocessing phase. Features are ranked
by their Pearson correlation coeﬃcients Rf with respect to the target PSNR in
training data. As a measure of the linear dependence of a feature and the target,

420

C.P. Lau, X. Zhang, and B. Shihada

Rf = +1 indicates a strong linear relationship between them, Rf = −1 represents
a negative linear relationship and Rf = 0 shows the independence of them. For a
feature Xf , its coeﬃcient w.r.t. target Y is deﬁned as:

Rf =

(cid:10)
cov(Xf , Y )
var(Xf )var(Y )

(6)

Features with Rf close to 0 will be eliminated when learning a prediction model.

3.5 Regression Models

Three regression algorithms are employed in this paper for predicting video
quality, k -Nearest Neighbor, Support Vector Machine and Neural Network.

k -Nearest neighbor algorithm (k -NN) is a lazy learning method. The quality
of a testing video is estimated based on its k nearest neighbors in training data,
which have similar feature values to the testing video. Assuming that its k most
similar videos have PSNR value Tj, j = 1...k, the quality of the video i is

(cid:11)k
(cid:11)k

j=1

Ti =

wi,j × Tj

wi,j

j=1

(7)

where wi,j is the weight function inversely proportional to the distance of the
c+(di,j)2 where c is the kernel width
training object j. It is deﬁned as: wi,j =
parameter and di,j is the distance between video i and j. Considering the feature
f Rf × (xi,f − xj,f )2
correlation coeﬃcients, we deﬁne distance di,j by di,j =
where xi,f and xj,f is the value of feature f in video i and j.

(cid:12)(cid:11)

1

−4− 10

−3] stepped by 5× 10

10, and the parameter c is tested by values in [10

To acquire the best results, the number of nearest neighbors k is set from 1 to
−5.
Support Vector Machine (SVM) is considered as one of the most robust and
powerful algorithms for classiﬁcation and regression. In this work, Epsilon-SVR,
the regression model of LIBSVM 3.12 [12], is employed for video quality pre-
diction. After testing of various kernel functions, Radial Basis Function (RBF)
kernel is selected for its best performance: φ(x, xi) = e−γ(cid:5)x−xi(cid:5)2
. The setting
of SVM parameters C (cost ) and kernel parameter γ (gamma) are explored
by searching in [1 − 100] for C and in [10 − 400] for γ. Experimental results
on diﬀerent settings of C and γ will be demonstrated in Figure 3 of the next
section.

Neural Network (NN) has been widely used in predicting video quality based
on application and network parameters [5,13,14]. Given enough hidden units,
any continuous function can be uniformly approximated to arbitrary accuracy
[15]. We applied two to three hidden layers NN with back-propagation learning
algorithm. Diﬀerent numbers of hidden neurons are evaluated ranged from 1× F
to 3×F , where F is the number of features. Results of NN with diﬀerent topology
settings will be reported in next section.

Video Quality Prediction over Wireless 4G

421

4 Experimental Results

This section presents the experimental results on 985 video testings. 5-fold cross
validation is applied for reliable evaluation reason. In order to investigate the
impact of feature normalization and transformation introduced in last section,
four diﬀerent cases summarized in Table 3 are evaluated and compared.

Table 3. Experimental Evaluation Cases

Modulation and boosting
Excluded Transformed

Normalization

Without Case 1
Case 2

With

Case 3
Case 4

Root Mean Squared Error (RMSE) and Coeﬃcient of Determination (R2) are
considered as the criteria to evaluate the performance of the prediction methods.
RMSE is used to quantify the diﬀerence between the predicted and actual PSNR
value. A smaller value indicates a better result with higher accuracy. RMSE is

(cid:12)(cid:11)N

i=1(Ti − Ti−act)2/N , where Ti and Ti−act are the predicted
R2 is another performance measurement of prediction. It is calculated by R2 =
(cid:11)N
Ti−act)2
i=1(Ti−act − Ti)2. R2 is in [0 1], where the

calculated as
and actual PSNR respectively, and N is the number of testing videos.
1 − SSE
and sum of squares error SSE =
maximum value 1 indicates the best prediction model.

SST , where the total sum of square SST =

(cid:11)N
i=1(Ti−act − 1

N

(cid:11)N

i=1

4.1 Feature Ranking

As introduced in section 3.4, each feature is ranked by its Pearson correlation
coeﬃcient Rf . The last two columns of Table 1 show the Rf and corresponding
P-values of all features. Those features with −0.03 < Rf < 0.03 or N aN 1 are
eliminated, such as Enhancement Encoding QP (0.028953), Transmission Power
(NaN), Reception Power Sensitivity (-0.028953), Carrier Frequency (0.000000),
and Cyclic Preﬁx (NaN). Their large P-values (> 0.05) also conﬁrm that these
feature and the target value have no signiﬁcant correlation.

4.2 Importance of Transforming Modulation and Power Boosting

To investigate the importance of transforming modulation and power boosting
features presented in Section 3.2, we compare results of Case 1 and 2 with that
of Case 3 and 4.

Figure 2a and 2b show the RMSE and R2 of k -NN on each case. The best
setting of kernel parameter c when calculating wi,j was exhaustively explored.
Figure 2 presents the results with the best setting. As we can see for all values

1 The 0 or NaN of Rf for some features is caused by their single distinct value, as

given in the 7th column (Count) of Table 1.

422

C.P. Lau, X. Zhang, and B. Shihada

r
o
r
r

 

E
d
e
r
a
u
q
S
n
a
e
M

 

 
t

o
o
R

6.5

6

5.5

5

4.5

4

3.5

3
 
0

 

Case 1, c=0.001
Case 2, c=0.00015
Case 3, c=0.0001
Case 4, c=0.0002

2
R

2

4

k

6

8

10

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1
 
0

 

Case 1, c=0.001
Case 2, c=0.00015
Case 3, c=0.0001
Case 4, c=0.0002

2

4

k

6

8

10

(a) k -NN - Root Mean Square Error

(b) k -NN - Coeﬃcient of determination

Fig. 2. Prediction performance of k -NN on each case with the best setting of c

of k, Case 3 and 4 are signiﬁcantly better than Case 1 and 2 with lower RMSE
values and higher R2. We can then conclude that feature transformation plays
a very important role on correctly predicting video quality.

Figure 3 presents the prediction performance of SVM. As observed in k -NN,
better results are obtained from Case 3 and 4 rather than Case 1 and 2. The
setting of SVM parameter C and γ is tested by combinations of values indexed
by k on x-axis. The best prediction is on Case 4 when C = 9 and γ = 120 (k =
332) resulting RMSE = 3.218 and R2 = 0.7669.

r
o
r
r

 

E
d
e
r
a
u
q
S
n
a
e
M

 

 
t

o
o
R

6.5

6

5.5

5

4.5

4

3.5

3
 
0

 

Case 1
Case 2
Case 3
Case 4

2
R

1000

2000

k

3000

4000

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1
 
0

 

Case 1
Case 2
Case 3
Case 4

1000

2000

k

3000

4000

(a) SVM - Root Mean Square Error

(b) SVM Coeﬃcient of determination

Fig. 3. Prediction performance of SVM on each case (sampled C and γ setting combi-
nations)

Figure 4 shows the results of NN with diﬀerent network topology setting
indexed by k, e.g., k = 1 when NN has F × F neurons (2 hidden layers, each of
which has F hidden neurons), k = 5 when NN has F × F × F neurons (3 hidden
layers), where F is the number of features after selection. The same observation
can be found that Case 3 and 4 perform better than Case 1 and 2. The best
prediction results with lowest RMSE and highest R2 happened on Case 3 when
NN has 3F × 3F neurons (k = 4).

5.5

r
o
r
r

5

Case 1
Case 2
Case 3
Case 4

4.5

4

 

E
d
e
r
a
u
q
S
n
a
e
M

 

 
t

o
o
R

3.5

3

 

Video Quality Prediction over Wireless 4G

423

 

 

0.8

0.7

0.6

0.5

0.4

2
R

Case 1
Case 2
Case 3
Case 4

1

2

3

4

5
k

6

7

8

9

10

 

1

2

3

4

6

7

8

9

10

5
k

(a) NN - Root Mean Square Error

(b) NN Coeﬃcient of determination

Fig. 4. Prediction performance of NN with diﬀerent combination of hidden layers and
neurons

Results of k -NN, SVM and NN consistently show that prediction excluding
modulation and power boosting features (Case 1 and 2) gives worse results than
transforming them into probability of symbol errors (Case 3 and 4). In other
words, transformation of modulation and power boosting is essential.

4.3 Eﬀects of Normalization of Data

Since Case 3 and 4 achieve better prediction results, we study the normalization
eﬀect on these two cases in this subsection (Case 1 and 2 are exempted). In
k -NN, normalization does not make signiﬁcant eﬀect. In Figure 2, normalized
data (Case 4) performs exactly the same as original data (Case 3) when k is
less than 4. Normalized data (Case 4) leads to better results than original data
(Case 3) when k increases.

Normalization stabilized the performance of SVM when varying parameter
setting. Fluctuating curves of Case 3 and smoothing curves of Case 4 in Figure
3 indicate that normalized data can produce better (lower RMSE and higher
R2) and more stable results. However, NN does not signiﬁcantly beneﬁt from
normalization.

In summary, normalization can generally further improve the prediction per-

formance.

4.4 Comparison of Regression Models

Table 4 compares the prediction performance of k -NN, SVM, and NN on Case 3
and Case 4. Case 1 and 2 are excluded because their prediction results are much
worse than that of Case 3 and 4. The best RMSE and R2 value of each model
were presented when its model parameters are set appropriately. In general, three
models give similar results, and they all produce small RMSE and high R2. SVM
on Case 4 can lead to the smallest RMSE and the highest R2.

Figure 5 shows the predicted and actual PSNR values for the best prediction
of all models, k-NN on Case 4 when k=10,c=0.0002, SVM on Case 4 when C=9,

424

C.P. Lau, X. Zhang, and B. Shihada

Table 4. The best predictions of k -NN, SVM, and NN on Case 3 and 4

k-NN SVM

NN

RMSE

R2

Case 3 3.32864 3.27009 3.34251
Case 4 3.30163 3.21764 3.36173
Case 3 0.75914 0.75922 0.75707
Case 4 0.76283 0.76689 0.75371

γ=120, and NN on Case 3 when topology is 3F × 3F = 30 × 30, where F is the
number of features after feature transformation and selection. Videos on x-axis
are ordered by their actual PSNR values. We can observe that all prediction
methods can give good prediction when actual PSNR is high. Especially, the
prediction of SVM is more accurate when actual PSNR is larger than 54dB. The
prediction deviates more from the true target when actual PSNR is relatively
low. However, the deviation is only around 5% of the target on average. These
less accurate predictions are due to the lack of eﬀective learning examples. Videos
with low PSNR have worse quality. In a well-developed transmission system, the
number of damaged videos is smaller than the number of undamaged videos.

70

60

)

B
d
(
 

R
N
S
P

50

40

30

20
 
0

 

Actual Value
Predicted Value

200

400
600
Data Index

800

1000

70

60

)

B
d
(
 

R
N
S
P

50

40

30

20
 
0

 

Actual Value
Predicted Value

200

400
600
Data Index

800

1000

(a) k -NN at k=10,c=0.0002

(b) SVM at C=9, γ=120

70

60

)

B
d
(
 

R
N
S
P

50

40

30

20
 
0

200

 

800

1000

Actual Value
Predicted Value

400
600
Data Index

(c) NN with 30 × 30

Fig. 5. Comparison of predicted PSNR and actual PSNR

5 Conclusion

This paper studies the problem of video quality prediction in wireless 4G net-
work transmission. A real testbed is built for collecting videos transmitted under
various network conditions. The raw transmission data is pre-processed by fea-
ture transformation, normalization and ranking. Regression models are learned
by three diﬀerent algorithms and used for predicting the quality of video.

The ﬁrst motivation of this work is to investigate which features are strongly
correlated to video quality. From the feature ranking results, we ﬁnd that atten-
uation and base layer probability of symbol error are the two important features
that highly correlated to the PSNR (target of prediction) with the correlation
coeﬃcient Rf = -0.5027 and -0.1905, P-value = 3.372e-64 and 1.667e-9, respec-
tively. In addition, according to the evaluation results, we observe that feature
transformation of modulation and power boosting for both base layer and en-
hancement layer signiﬁcantly aﬀected the prediction accuracy of video quality.
Through pre-processing raw data and exploring the most suitable parameter
setting, we built prediction models based on three diﬀerent regression algorithms.

Video Quality Prediction over Wireless 4G

425

The experimental results demonstrate that these models can accurately predict
video quality with small errors and high relevance with target values.

This ﬁrst attempt of video quality prediction in wireless 4G opens several
perspectives for further research. First, the models are useful to reduce the time
spent on running real experiments. As we mentioned in the introduction, imi-
tating all of the diﬀerent channel conditions and conducting video transmitting
experiments are very time consuming. Our discovery of key features and pre-
diction model can be used to guide the design of experiments. Second, we will
enhance the prediction models to make them perform well on more complex
channel conditions.

References

1. She, J., Yu, X., Hou, F., Ho, P.H., Yang, E.H.: A Framework of Cross-Layer Superpo-
sition Coded Multicast for Robust IPTV Services over WiMAX. In: IEEE Wireless
Communications and Networking Conference WCNC, pp. 3139–3144. IEEE (2008)
2. Judd, G., Steenkiste, P.: Characterizing 802.11 wireless link behavior. Wireless

Networks 16(1), 167–182 (2008)

3. Knopp, R., Humblet, P.: Information capacity and power control in single-cell
multiuser communications. In: IEEE International Conference on Communications
ICC 1995 Seattle, Gateway to Globalization, vol. 1, pp. 331–335 (1995)

4. Huynh-Thu, Q., Ghanbari, M.: Scope of validity of PSNR in image/video quality

assessment. Electronics Letters 44, 9–10 (2008)

5. Khan, A., Sun, L., Ifeachor, E.: Content-based video quality prediction for MPEG4
video streaming over wireless networks. Journal of Multimedia 4(4), 228–239 (2009)
6. Garcia, M.N., Raake, A.: Towards Content-related Features for Parametric Video
Quality Prediction of IPTV Services. In: IEEE International Conference on Acous-
tics Speech and Signal Processing, ICASSP 2008, pp. 757–760 (2008)

7. Dalal, A., Olson, J.: Feature Selection for Prediction of User-Perceived Stream-
ing Media Quality. In: Preoceedings of International Symposium on Performance
Evaluation of Computer and Telecommunication Systems SPECTS, pp. 285–294
(2007)

8. Liu, Y.X., Kurceren, R., Budhia, U.: Video classiﬁcation for video quality predic-

tion. Journal of Zhejiang University SCIENCE A 7(5), 919–926 (2006)

9. Schwarz, H., Marpe, D., Wiegand, T.: Overview of the Scalable Video Coding
Extension of the H.264/AVC Standard. IEEE Transactions on Circuits and Systems
for Video Technology 17(9), 1103–1120 (2007)

10. Roosendaal, T.: Sintel. In: ACM SIGGRAPH 2011 Computer Animation Festival,

SIGGRAPH 2011, p. 71. ACM, New York (2011)

11. Ho, J.C.C.: Logical superposition coded modulation for wireless video multicasting.

Master’s thesis, Univ. of Waterloo, Waterloo, Canada (2009)

12. Chang, C., Lin, C.: LIBSVM: a library for support vector machines. ACM Trans-

actions on Intelligent Systems and Technology (TIST) 2(3), 27 (2011)

13. Mohamed, S., Rubino, G.: A study of real-time packet video quality using random
neural networks. IEEE Transactions on Circuits and Systems for Video Technol-
ogy 12(12), 1071–1083 (2002)

14. Callet, P.L.: A convolutional neural network approach for objective video quality

assessment. IEEE Transactions on Neural Networks 17(5), 1316–1327 (2006)

15. Bishop, C.M.: Pattern recognition and machine learning. Springer, New York (2006)


