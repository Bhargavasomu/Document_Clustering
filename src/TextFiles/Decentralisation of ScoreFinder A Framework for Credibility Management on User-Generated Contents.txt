Decentralisation of ScoreFinder: A Framework for

Credibility Management on User-Generated Contents

Yang Liao, Aaron Harwood, and Kotagiri Ramamohanarao

Computer Science and Software Engineering,

The University of Melbourne, Victoria, Australia

{liaoy,aaron,rao}@csse.unimelb.edu.au

Abstract. User-generated content (UGC) from Internet users has signiﬁcant
value only when its credibility can be established. A basic approach to estab-
lishing credibility is to take an average of scores from annotators, while more so-
phisticated approaches have been used to eliminate anomalous scoring behaviour
by giving different weights to scores from different annotator proﬁles. A number
of applications such as ﬁle sharing and article reviewing use a decentralised archi-
tecture. While computing a weighted average of static values in a decentralised
application is well studied, sophisticated UGC algorithms are more complicated
since source values to be aggregated and their weights may change in time. In
our work we consider a centralised credibility management algorithm, Score-
Finder, as an example, and show both structured and unstructured approaches for
computing time-dependent weighted average values in peer-to-peer (P2P) net-
works. Experimental results on two real data sets demonstrate that our approaches
converge and deliver results comparable to those from the centralised version of
ScoreFinder.

1 Introduction

User-Generated Content (UGC) is an increasingly important information source on the
Web. UGC applications process individual data streams from a large number of Internet
users and make this information available globally, e.g. Social Networking, Collabora-
tive Content Publishing, File Sharing, Virtual Worlds and other collaborative activities.
Examples of UGC include purported factual information, user opinions or reviews on
public events and issues, ﬁles and documents. The value of the information from these
applications is proportional to the information credibility – users need to be able to
ascertain the credibility of the information in the UGC.

Conﬁrming the credibility of a given content item using a centralised authority is
infeasible due to the scale of UGC, and so most systems allow the users themselves
to provide feedback, or score the content items that other users have provided. Score-
Finder [4] was proposed addressing the problem of aggregating feedback.

Not all UGC applications can be hosted centrally. For example, ﬁle sharing applica-
tions are more effective when they are decentralised, using a peer-to-peer (P2P) model,
and it is widely accepted that the P2P model is applicable to a large range of UGC appli-
cations. Such applications are emerging, and they do not have a central trusted authority
that will undertake the computations in a secure way. Indeed one of the motivations for

M.J. Zaki et al. (Eds.): PAKDD 2010, Part II, LNAI 6119, pp. 272–282, 2010.
c(cid:2) Springer-Verlag Berlin Heidelberg 2010

Decentralisation of ScoreFinder: A Framework for Credibility Management on UGC

273

these applications is to the contrary that there is no central authority in which trust must
be placed. The distribution of trust therefore removes the so called “trust bottleneck”
but creates a different problem of distributed trust. Furthermore, distributed functional-
ity that beneﬁts the majority of peers in a peer-to-peer system, such as UGC scoring,
is likely to be supported in the sense that the required computational load put onto the
peers will be accepted. As a result, sophisticated UGC credibility methods are very
desirable but signiﬁcantly challenging to apply in a decentralised system.

Both structured and unstructured peer-to-peer networks are considered in this pa-
per, and different strategies are accordingly used. Structured networks provide uniﬁed
access to each shared resource, namely all peers in a structured network can map an
arbitrary resource identiﬁer – usually ﬁle names or hash values of the ﬁle content – to
a certain host. On the other hand, each peer in an unstructured peer-to-peer network
sees only a local area of the network, and searches intended resources by propagating
request messages.

In this paper we consider the problem of aggregating users’ feedback for both a
structured and an unstructured P2P architecture, and we use ScoreFinder as an instance
of sophisticated credibility management algorithms. We provide a structured P2P ap-
proach for implementing ScoreFinder, and show how is it implemented on a structured
peer-to-peer platform. We also provide an unstructured P2P approach for implementing
ScoreFinder, based on gossiping. Particularly, the method of using time-slots deﬁned
on the Real-Time Clock to synchronise decentralised computation is novel and useful
in other gossiping protocols where restricted synchronisation is required. We simulate
network topology and churn to show its affect, as compared to a centralised or ideal
computation.

2 Related Work

2.1 Article-Annotator Model and ScoreFinder

We in [4] introduce a model of credibility management, called the Article-Annotator (A-
A) model and a comprehensive framework for Credibility Management, called Score-
Finder. The participants and shared content items are named Annotators and Articles
respectively, and the evaluations made by annotators are called Scores, which are num-
bers between 0 and 1.

The key operation of ScoreFinder, denoted as ExpertnessEstimation, is to
iteratively calculate the weight of each score contributed by annotators to articles,
and accordingly calculate the weighted average of scores to an article as the infer-
ence of the value or quality of the article, denoted as AggregateResult. An ad-
ditional operation is to shift scores from each user to remove general biases, denoted as
ScoreShifting.

2.2 Decentralised Frameworks

There are decentralised frameworks for implementing algorithms in structured and un-
structured peer-to-peer networks. In unstructured p2p networks, there are algorithms

274

Y. Liao, A. Harwood, and K. Ramamohanarao

employing ﬂood or gossip messages to gradually aggregate values distributed over all
peers. In [5], the authors proposed an approach to compute an overall average of values
on each peer by continuously exchanging the status in each small-scaled sub-network
(particularly, between the direct neighbourhoods). Similar approaches are adopted in
GossipTrust [11], where opinions are uninterruptedly exchanged between each peer
and a randomly selected peer (or all other peers) to reach the commonly agreed values.
In [1], a general model of such problems is established for computing a linear combina-
tion of values distributed in peer-to-peer networks. More emphasis in the paper is placed
on privacy of participants. On the other hand, most structured networks maintain a Dis-
tributed Hash Table (DHT) among peers. A DHT provides a many-to-one map between
keys and peers; in most cases the distribution of keys over peers is uniformly random. It
can be used for distributing data or for assigning logical roles over peers. Upon a given
set of peers, a search to a given key always hits the same peer. These characteristics
are employed in our framework, among other things, to map each of items to a peer
that is in charge of organising the computation. Sophisticated frameworks also provide
the ability of maintaining integrity of the Hash Table, by duplicating and/or migrating
data items from left peers to other available peers. In practice, we used Pastry [9] as the
DHT in our experiments; other DHT platforms like CAN [7] and Chord [10] provide
the same function.

3 Decentralisation of ScoreFinder

3.1 Decentralisation in Structured Peer-to-Peer Networks

In this section we explain how we implemented a structured P2P application that uses
ScoreFinder to rank articles. A decentralised architecture is proposed in Figure 1. The
centralised ScoreFinder algorithm is simply split into two parts, the annotator compo-
nent and the tracker component that could run on each peer; data exchange between
such peers is through the underlying structured peer-to-peer network. The principles in
splitting the centralised algorithm are: (1) to minimise the network transfer, and (2) to
minimise computation on the tracker side because trackers are likely to become bottle-
necks in the system. Thereby, the annotator component provides its expertness estimate
and score shifting factor (respectively e and b) to each related tracker (i.e. trackers host-
ing articles that this annotator has read) and the tracker component provides the most
recent results (r = {rj}) on hosted articles to the annotators that have read them.

Algorithm 1 and Algorithm 2 outline the computation in the tracker component and
the annotator component, respectively. ST , ET and rT denote the relevant part (i.e.
those for articles hosted in this peer) of S, E and r in each tracker peer, while SA and
rA denote the relevant part of S and r in each annotator peer. In particular, rAT denotes
the set of temporary results in the intersection of the corresponding rA and rT . We
use BT to denote the score shifting vector (i.e. bi) from annotators who gave scores to
articles that are hosted by this tracker.

These two algorithms continue to iterate for the lifetime of the objects which instan-
tiate them. We consider that in a peer-to-peer network, there are always new peers, new
content items and new annotations to be included, so the process of reﬁning the ranking

Decentralisation of ScoreFinder: A Framework for Credibility Management on UGC

275

Fig. 1. Decentralising ScoreFinder on structured peer-to-peer networks

Algorithm 1. Process on Each Tracker
Require: All sij and score shifting factors
Ensure: Temporary result of each content item hosted by this tracker

1: loop
2:
3:
4:
5:
6:
7:
8: end loop

ST(cid:2) ← ScoreShifting(ST, BT)
rT ← AggregateResult(ST(cid:2)
, ET)
for all connected annotators do

SendToAnnotator(rAT)

end for
Wait A Random Period

Algorithm 2. Process on Each Annotator (i)
Require: All sij and the temporary result vector r
Ensure: The expertness and score shifting factor of this annotator

1: loop
2:
3:
4:
5:
6:
7:
8: end loop

e ← ExpertnessEstimation(rA, SA)
b ← ScoreShiftingFactor(rA, SA)
for all connected trackers do
SendToTracker(e, b)

end for
Wait A Random Period

is continuously running across the life cycle of the peer-to-peer application. Further-
more, there is no synchronisation between peers, i.e. every peer arbitrarily sends its
most recent data at any time, and is always ready to receive messages from others. Af-
ter receiving an update message, e.g. updating e or ri, the peer updates its local cache,
and uses the cache to continue with the next round of computation. Between each loop,
the algorithm pauses for a short period. Network conditions largely inﬂuence the selec-
tion of this period. In our experiment, the period is set to 4 seconds since messages are
delivered through an application level route, which usually consists of 2 or 3 hops.

276

Y. Liao, A. Harwood, and K. Ramamohanarao

3.2 Decentralisation in Unstructured Peer-to-Peer Networks
The ScoreFinder algorithm is also implemented in unstructured peer-to-peer networks
using a gossip-based approach. We note that peers in unstructured peer-to-peer net-
works do not have a global perspective to the whole network, instead each peer sees a
relatively small set of peers, called its neighbours. Therefore, there is no well-known
peers, like trackers in a structured peer-to-peer network, which can be in charge of or-
ganising computation for each article; instead peers continuously exchange information
with neighbours to propagate the inﬂuence of each original value to the whole network.
Also considered is the time-dependent change of values and their weights. Because
of our expertise and score adjustment operations, the shifted scores (ST(cid:2)
) and the ex-
pertise estimates for each annotator (e) change in time. We need to compute time-
dependent weighted average values, as shown in the following formula, for coping such
changes:

(cid:3)

(1)
where v = {vi(t)} and w(t) = {wi(t)} are two sets of time-depending functions. We
i wi(t) = 1 for any t. A number of studies have focused on computing time-
deﬁne
dependent weighted average values (as shown in Formula 1) in peer-to-peer networks
using gossiped messages. The algorithm introduced in [3] uses epochs to divide the
continuous computation into segments, in each segment the computation is restarted to
validate changed values on each peer or values from new joiners. Peers in the network
are synchronised by a broadcasting protocol.We then implemented ScoreFinder based
on our time-slot based protocol.

f(v, w, t) =

wi(t)vi(t),

(cid:2)

i

Article Overlay Network. Considering the very large number of articles that are
shared in current Internet applications, it is infeasible to store the status for all arti-
cles in each peer. In our approach, each node maintains a separate neighbour set for
each annotated article, and exchanges messages only with peers that have the same an-
notated articles. This is equivalent to building an overlay network for each article over
the original peer-to-peer network, and computing the weighted average score for the
article on this overlay network. Figure 2(a) shows two overlay networks for article 101
and article 102 resp., built upon the original peer-to-peer network. Each contains all the
peers giving scores to the article. Each peer ﬁnds peers that annotated same articles by
ﬂooding search messages.

Time-slots and Gossip Messages. To compute average values that always reﬂect the
recent status of the peer-to-peer system, we use time-slots to synchronise the computa-
tion between peers. Time slots are periods that are predeﬁned on the Real-Time Clock
(RTC) and known by all peers. For example, the application could deﬁne every 5 min-
utes from 0:00 o’clock to be a time-slot, i.e. there are 288 slots in 24 hours. Nowadays, a
large number of computers, including desktop computers, servers, mainframes and even
mobile devices, could maintain a precise Real-Time Clock by frequently synchronising
their local clock with Network Time Protocol (NTP) servers. Therefore, a time-slot is
started and terminated nearly simultaneously on all such peers. In the beginning of each
time-slot, computation is restarted from a new status, in which scores and weights are

Decentralisation of ScoreFinder: A Framework for Credibility Management on UGC

277

X

i=101, w=0.9, v = 0.6
tau="20/07/09 18:30"

i=101, w=0.9, v = 0.6
tau="20/07/09 18:30"

i=101, w=0.9, v=0.6
tau="20/07/09 18:30"

Y

 X

(a) Overlay networks for articles are built
upon the unstructured peer-to-peer net-
work. It is shown that peer x and peer y
have annotated both article 101 and article
102, hence they are in both overlay net-
works

The overlay network for article 101

(b) Gossip messages are sent between
each pair of directly connected peers. The
ID of the current time-slot is sent in each
message along with i, w and v. It is shown
that before sending the three messages,
peer x has v101 = 1.8 and w101 = 2.7

Fig. 2. Unstructured network overlay

both updated based on the recent results from the last time-slot, and weighted average
values reﬂecting those updated parameters are reached in the end of the time-slot.

Figure 2(b) shows an example of three gossip messages exchanged between peers.
Each node maintains two values for each annotated articles (identiﬁed by i): the summed
weights, wi, and the summed product of weights and scores, vi. Assuming that a node
is directly connected to k peers for article i, in each step (the length of which is ran-
domly determined by the node, usually 3-5 seconds) this node sends a message to each
of the k peers as well as to itself. Each message consists of i, v
k+1 and the ID of the
current time-slot (τ). Afterwards, this peer re-compute its wi and vi by adding v and
w in all messages received in the past step that have the correct slot ID. It is noticeable
that there could be zero or multiple messages from the same peer that are received in
a step, which does not inﬂuence the validity of the algorithm. This cycle is repeated
until the end of the current time-slot, then all peers update the result of each annotated
article by computing rτ
wi , and update their expertness (eτ ). Before starting the new
time-slot, each peer re-evaluate its vi and wi by (eτ sτ
ij) and eτ . This process is shown
in Algorithm 3.

k+1 , w

i = vi

4 Experiments

4.1 Outline of Experiment

In evaluating ScoreFinder, we implemented a simulator to imitate the scenario that con-
tent items are shared and annotated in peer-to-peer networks, including structured and
unstructured models. In our experimental unstructured peer-to-peer network, the boot-
strap is done by propagating messages in a ﬂooding way to ﬁnd peers that annotated
same articles. Each peer keeps at least 5 neighbours for each overlay network (i.e. for

278

Y. Liao, A. Harwood, and K. Ramamohanarao

Algorithm 3. The Algorithm in each peer in a unstructured peer-to-peer network

τ ← NewTimeSlotID(); eτ ← 0.5; Sτ ← S; rτ ← S
loop

for all annotated articles : i do

vi ← eτ × sτ
wi ← eτ

i

end for
repeat

for all annotated articles : i do

if there are peers connected for i then

for all connected peers and this peer do
, τ )

SendMessage(i, vi
k+1

, wi
k+1

end for
vi ←sum of received v
wi ←sum of received w

end if

end for
Clear Received Messages
Wait A Random Period

until the end of the time-slot
τ ← NewTimeSlotID()
for all annotated articles : i do

if wi > 0 then
i ← vi
rτ

wi

end if

end for
Sτ ← ScoreShifting(S, rτ )
eτ ← ExpertnessEstimation(Sτ, rτ )

end loop

each annotated article, a peer connects to 5 other peers giving scores to this article too),
and propagates search messages through the p2p network in bootstrap or when a neigh-
bour is found to be unavailable. Each search message has a Time-to-live (TTL) ﬁeld to
limit the diameter of the propagation. Each peer receiving the message retransmits the
message to a limited number of neighbours until a peer annotating the same article is
found or the TTL is exhausted. The targeted peer then sends back an acknowledgement
message to the inquirer establishing a connection with it. We used the MovieLens data
set [8], containing 10 million ratings for 10681 movies from 71567 volunteers,to evalu-
ate our algorithms; the data set was shufﬂed and randomly re-sampled to a smaller data
set in each trial. The two decentralised variants of ScoreFinder were examined in the
experiment.

4.2 Evaluation Method

We evaluated our results with a supervised approach. In contrast of the size of our
samples (150 annotators), we chose movies that received more than 2000 scores in each
of the two data sets, so the average scores from such a large number of annotators could

Decentralisation of ScoreFinder: A Framework for Credibility Management on UGC

279

l

s
a
i
r
T

 
f
o
 
r
e
b
m
u
N

20

15

10

5

0

-20% -10%

Structured P2P (Average=13.7%)
Unstructured P2P (Average=12.0%)
Centralised (Average = 17.4%)

0.03

0.025

0.02

0.015

0.01

0.005

l

s
n
o
i
t
a
u
a
v
e
 
r
o
r
r

E

MovieLens
Netflix

l

s
n
o
i
t
a
u
a
v
e
 
r
o
r
r

E

0.03

0.025

0.02

0.015

0.01

0.005

MovieLens
Netflix

10%

0
Improvement on Accuracy

20%

30%

40%

50%

1

2

3

4

5

6

7

8

1

2

3

4

5

6

Minutes

Time slots (6 mins each)

(a) Distribution of
improve-
ment on accuracy to the base-
line (on the MovieLens data
set, in 60 trials)

(b) Convergence
structured
works

peer-to-peer

speed

in
net-

(c) Convergence
unstructured
networks

speed

in
peer-to-peer

Fig. 3. Performance evaluation on improvements to the baseline

be regarded as the common agreed opinion, and used as the reference. The evaluation
function used in the experiment was the Mean Squared Error (MSE) between inferred
credibility values and the reference; a smaller evaluation value denotes a more accurate
result. In peer-to-peer networks, results on each peer could be different to each other,
so we accumulated errors along each annotation, i.e. if an article is annotated by two
peers, the error between the oracle score and the ﬁnal result on each of the two peers is
taken into the MSE.

4.3 Results and Discussion

Accuracy. Figure 3(a) shows the distribution of accuracy improvement in 60 trials,
each was on a randomly re-sampled data set from respectively the MovieLens data set
and the Netﬂix data set. There were 150 annotators and 2000 content items selected
for building each re-sampled data set, as well as all scores between those selected enti-
ties. In this ﬁgure, our algorithms have a general better performance than the baseline.
The performance of the unstructured peer-to-peer implementation stably follows the
centralised implementation, where the performance of the structured peer-to-peer im-
plementation has a larger variance to the centralised implementation. This could be
explained by the difference on the extents of synchronisation of the two decentralised
implementations. In the unstructured network, the algorithm closely follow the steps
of the centralised ScoreFinder, namely each iteration is strictly synchronised by time-
slots; whereas in the structured network, it does not follow the steps of the centralised
ScoreFinder, namely all peers arbitrarily change their scores and weights any time, and
the scores are gradually injected from the annotators to the trackers. This inconsistency
made the latter one may have larger variance than the centralised algorithm. We also
note that there is difference between average values calculated on different peers in the
end of each time-slot, this led the accuracy of ScoreFinder in unstructured peer-to-peer
networks consistently lower than the centralised implementation.

Looking into a single trial, the speed of convergence of the two ScoreFinder variants
is analysed in Figure 3(b) and Figure 3(c). Both variants converged in the trial, nonethe-
less the unstructured variant consumed more time to reach convergence. This is because
agreed weighted average values are reached after a round of exchanging messages in

280

Y. Liao, A. Harwood, and K. Ramamohanarao

structured networks, but in unstructured networks it needs a whole time-slot to reach
the agreed average values.

Robustness. To reveal the robustness of ScoreFinder in a variable network circum-
stance, we simulated two types of network conditions with different strengths. First,
we randomly discarded messages between peers to examine the inﬂuence from packet
loss. Second, we randomly shut down a number of peers in every 10 seconds to see
how our algorithms reacted to variance on availability of peers. The same data set was
used in the two simulations to facilitate comparison. Figure 4(a) and Figure 4(b) show
the results in different packet loss rates and invalid peer ratios; in each condition the
experiment was run 5 times. It is showed that the variant for unstructured networks is
more sensitive to packet loss, whereas that for structured networks is more sensitive to
churn.

e
n

i
l

e
s
a
b

o
t

o
i
t
a
r

r
o
r
r
E

Structured

Unstructured

Centralised

e
n

i
l

e
s
a
b

o
t

o
i
t
a
r

r
o
r
r
E

Structured

Unstructured

Centralised

Rate of lost packets

Rate of online peers

Fig. 4. Robustness testing; the error evaluations are showed by the relative ratios to the re-
sults from the baseline; the error-bars show the maximum and minimum relative errors in each
condition

5 Conclusion

We introduced two decentralised variants of ScoreFinder, a credibility management
framework, for respectively structured and unstructured peer-to-peer network applica-
tions. The performance of our algorithm is examined in an experiment using two real
world data sets. The results reveal the merit of our approach by comparing to two base-
lines that are widely used in real applications. A number of issues regarding attacks and
misbehaviour of users are discussed in the paper.

The primary challenge to decentralise ScoreFinder is to compute weighted aver-
age scores from parameters that change in time, by this means two approaches are
used in different network models to synchronise distributed computation. In struc-
tured peer-to-peer networks, tracker components are hosted in peers which have
addresses that are closest to the identiﬁcation of articles, whereas globally agreed time-
slots are used to coordinate paces of computation in unstructured peer-to-peer net-
works. The approach of using time-slots to synchronising computation across peers
is equal to building a logic-time framework in a distributed environment, by which
highly synchronised algorithms can be decentralised. Inﬂuence from churn and net-
work conditions to the accuracy of the decentralisation methods was examined in the
experiments.

Decentralisation of ScoreFinder: A Framework for Credibility Management on UGC

281

5.1 Future Study

In this paper, no methods for identifying cliques and reducing their inﬂuence are con-
sidered. Annotators in cliques are only penalised by degrading their individual expert-
ness levels considering that their scores may differ from other experts not in the clique.
Nonetheless, unbiased scores from an annotator who gives biased scores to only a small
subset of the content items are all lower weighted, hence we need an approach to say
which part of their scores is unbiased and which part is not. Still, the criteria for clique
identiﬁcation could be closely related to the application, which is need to be further
investigated.

In [6], the authors argue that weighted average values could be computed along span-
ning trees which is formed by multi-casting messages. We noticed that there are two ad-
vantages using spanning trees instead of exchanging gossip messages in implementing
ScoreFinder. First, spanning tree-based algorithms have signiﬁcantly faster convergence
speed than gossip message approaches; furthermore, the upper bound of the number of
messages to be exchanged before all peers reaching to an agreement is deﬁnite in a tree.
Second, a peer in a spanning tree may change its local score and weight at any time,
and the new agreement of weighted average value that reﬂects those changes will be
reached in each peer under the same upper bound; namely no synchronising mecha-
nisms, like time-slots or super peers, are necessary for spanning-tree styled algorithms.
SCRIBE [2], CAN [7] and other multi-casting algorithms are useful platform, whereby
spanning trees are built in unstructured peer-to-peer networks.

References

1. Bickson, D., Dolev, D., Bezman, G., Pinkas, B.: Peer-to-peer secure multi-party numerical
computation. In: P2P ’08: Proceedings of the 2008 Eighth International Conference on Peer-
to-Peer Computing, Washington, DC, USA, pp. 257–266. IEEE Computer Society Press,
Los Alamitos (2008)

2. Castro, M., Druschel, P., Kermarrec, A.M., Rowstron, A.I.T.: SCRIBE: A large-scale and
decentralized application-level multicast infrastructure. IEEE Journal on Selected Areas in
communications 20(8), 1489–1499 (2002)

3. Jelasity, M., Montresor, A., Babaoglu, O.: Gossip-based aggregation in large dynamic net-

works. ACM Trans. Comput. Syst. 23(3), 219–252 (2005)

4. Liao, Y., Harwood, A., Ramamohanarao, K.: Scoreﬁnder: A method for topic sensitive cred-
ibility inference on documents. In: The 26th IEEE International Conference on Data Engi-
neering, Long Beach, CA, USA (2010)

5. Mehyar, M., Spanos, D., Pongsajapan, J., Low, S.H., Murray, R.M.: Asynchronous dis-
tributed averaging on communication networks. IEEE/ACM Trans. Netw. 15(3), 512–520
(2007)

6. Ramabhadran, S., Ratnasamy, S., Hellerstein, J.M., Shenker, S.: Brief announcement: pre-
ﬁx hash tree. In: PODC ’04: Proceedings of the twenty-third annual ACM symposium on
Principles of distributed computing, p. 368. ACM, New York (2004)

7. Ratnasamy, S., Francis, P., Handley, M., Karp, R., Schenker, S.: A scalable content-
addressable network. In: SIGCOMM ’01: Proceedings of the 2001 conference on Applica-
tions, technologies, architectures, and protocols for computer communications, pp. 161–172.
ACM, New York (2001)

282

Y. Liao, A. Harwood, and K. Ramamohanarao

8. Riedl, J., Konstan, J.: Movielens data sets (July 2009),

http://www.grouplens.org/node/73

9. Rowstron, A., Druschel, P.: Pastry: Scalable, decentralized object location, and routing for

large-scale peer-to-peer systems. LNCS, pp. 329–350. Springer, Heidelberg (2001)

10. Stoica, I., Morris, R., Karger, D., Frans Kaashoek, M., Balakrishnan, H.: Chord: A scalable
peer-to-peer lookup service for internet applications. In: SIGCOMM ’01: Proceedings of the
2001 conference on Applications, technologies, architectures, and protocols for computer
communications, pp. 149–160. ACM, New York (2001)

11. Zhou, R., Hwang, K., Cai, M.: GossipTrust for Fast Reputation Aggregation in Peer-to-Peer
Networks. IEEE Transactions on Knowledge and Data Engineering 20(9), 1282–1295 (2008)


