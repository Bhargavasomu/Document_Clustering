Semi-supervised Feature Analysis

for Multimedia Annotation by Mining Label

Correlation

Xiaojun Chang1, Haoquan Shen2, Sen Wang1, Jiajun Liu3, and Xue Li1

1 The University of Queensland, QLD 4072, Australia

2 Zhejiang University, Zhejiang, China

3 CSIRO Brisbane

Abstract. In multimedia annotation, labeling a large amount of train-
ing data by human is both time-consuming and tedious. Therefore, to
automate this process, a number of methods that leverage unlabeled
training data have been proposed. Normally, a given multimedia sam-
ple is associated with multiple labels, which may have inherent correla-
tions in real world. Classical multimedia annotation algorithms address
this problem by decomposing the multi-label learning into multiple in-
dependent single-label problems, which ignores the correlations between
diﬀerent labels. In this paper, we combine label correlation mining and
semi-supervised feature selection into a single framework. We evaluate
performance of the proposed algorithm of multimedia annotation using
MIML, MIRFLICKR and NUS-WIDE datasets. Mean average precision
(MAP), MicroAUC and MacroAUC are used as evaluation metrics. Ex-
perimental results on the multimedia annotation task demonstrate that
our method outperforms the state-of-the-art algorithms for its capability
of mining label correlations and exploiting both labeled and unlabeled
training data.

Keywords: Semi-supervised Learning, Multi-label Feature Selection,
Multimedia Annotation.

1

Introduction

With the booming of social networks, such as Facebook and Flickr, we have
witnessed a dramatical growth of multimedia data, i.e. image, text and video.
Consequently, there are increasing demands to eﬀectively organize and access
these resources. Normally, feature vectors, which are used to represent afore-
mentioned resources, are usually very large. However, it has been pointed out
in [1] that only a subset of features carry the most discriminating information.
Hence, selecting the most representative features plays an essential role in a
multi-media annotation framework. Previous works [2,3,4,5] have indicated that
feature selection is able to remove redundant and irrelevant information in the
feature representation, thus improves subsequent analysis tasks.

Existing feature selection algorithms are designed in various ways. For exam-
ple, conventional feature selection algorithms, such as Fisher Score [6], compute

V.S. Tseng et al. (Eds.): PAKDD 2014, Part II, LNAI 8444, pp. 74–85, 2014.
c(cid:2) Springer International Publishing Switzerland 2014

Semi-supervised Feature Analysis for Multimedia Annotation

75

weights of all features, rank them accordingly and select the most discriminating
features one by one. While dealing with multi-label problems, the conventional
algorithms generally transform the problem into a couple of binary classiﬁcation
problems for each concept respectively. Hence, feature correlations and label
correlations are ignored [7], which will deteriorate the subsequent annotation
performance.

Another limitation is that they only use labeled training data for feature se-
lection. Considering that there are a large number of unlabeled training data
available, it is beneﬁcial to leverage unlabeled training data for multimedia an-
notation. Over recent years, semi-supervised learning has been widely studied
as an eﬀective tool for saving labeling cost by using both labeled and unlabeled
training data [8,9,10]. Inspired by this motivation, feature learning algorithms
based on semi-supervised framework, have been also proposed to overcome the
insuﬃciency of labeled training samples. For example, Zhao et al. propose an
algorithm based on spectral analysis in [5]. However, similarly to Fisher Score
[6], their method selects the most discriminating features one by one. Besides,
correlations between labels are ignored.

Our semi-supervised feature selection algorithm integrates multi-label feature
selection and semi-supervised learning into a single framework. Both labeled and
unlabeled data are utilized to select features while label correlations and feature
correlations are simultaneously mined.

The main contributions of this work can be summarized as follows:

1. We combine joint feature selection with sparsity and semi-supervised learn-
ing into a single framework, which can select the most discriminating features
with an insuﬃcient amount of labeled training data.

2. The correlations between diﬀerent labels are taken into account to facilitate

the feature selection.

3. Since the objective function is non-smooth and diﬃcult to solve, we propose
a fast iteration algorithm to obtain the global optima. Experimental results
on convergence validates that the proposed algorithm converges within very
few iterations.

The rest of this paper is organized as follows. In Section 2, we introduce
details of the proposed algorithm. Experimental results are reported in Section
3. Finally, we conclude this paper in Section 4.

2 Proposed Framework

To mine correlations between diﬀerent labels for feature selection, our algorithm
is built upon a reasonable assumption that diﬀerent class labels have some in-
herent common structures. In this section, our framework is described in details,
followed by an iterative algorithm with guaranteed convergence to optimize the
objective function.

76

X. Chang et al.

2.1 Formulation of Proposed Framework

R

Let us deﬁne X = {x1, x2,··· , xn} as the training data matrix, where xi ∈
d(1 ≤ i ≤ n) is the i-th data point and n is the total number of training data.
Y = [y1, y2,··· , ym, ym+1,··· , yn]T ∈ {0, 1}n×c denotes the label matrix and c
c (1 ≤ i ≤ n) is the label vector with c classes. Yij
is the class number. yi ∈ R
indicates the j-th element of yi and Yij := 1 if xi is in the j-th class, and Yij := 0
otherwise. If xi is not labeled, yi is set to a vector with all zeros. Inspired by [11],
we assume that there is a low-dimensional subspace shared by diﬀerent labels.
We aim to learn c prediction functions {ft}c
t=1. The prediction function ft can
be generalized as follows:

ft(x) = vT

t x + pT

t QT x = wT

t x,

(1)

Suppose there are mt training data {xi}mt

where wt = vt +Qpt. v and p are the weights, Q is a transformation matrix which
projects features in the original space into a shared low-dimensional subspace.
i=1 belonging to the t-th class labeled
as {yi}mt
i=1. A typical way to obtain the prediction function ft is to minimize the
following objective function:

arg min

ft,QT Q=I

c(cid:2)

t=1

(

1
mt

mt(cid:2)

i=1

loss(ft(xi), yi) + βΩ(ft))

(2)

Note that to make the problem tractable we impose the constraint QT Q = I.
Following the methodology in [2], we incorporate (1) into (2) and obtain the
objective function as follows:

min

{vt,pt},QT Q=I

c(cid:2)

t=1

(

1
mt

mt(cid:2)

i=1

loss((vt + Qpt)T xi, yi) + βΩ({vt, pt}))

(3)

By deﬁning W = V + QP , where V = [v1, v2,··· , vc] ∈ R

d×c and P =
sd×c where sd is the dimension of shared lower dimensional

[p1, p2,··· , pc] ∈ R

subspace, we can rewrite the objective function as follows:

min

W,V,P,QT Q=I

loss(W T X, Y ) + βΩ(V, P )

(4)

Note that we can implement the shared feature subspace uncovering in diﬀer-
ent ways by adopting diﬀerent loss functions and regularizations. Least square
loss is the most widely used in research for its stable performance and simplicity.
By applying the least square loss function, the objective function arrives at:

arg min

W,P,QT Q=I

(cid:4)X T W − Y (cid:4)2

F + α(cid:4)W(cid:4)2

F + β(cid:4)W − QP(cid:4)2

F

(5)

As indicated in [12], however, there are two issues worthy of further consid-
eration. First, the least square loss function is very sensitive to outliers. Second,
it is beneﬁcial to utilize sparse feature selection models on the regularization

Semi-supervised Feature Analysis for Multimedia Annotation

77

term for eﬀective feature selection. Following [12,13,14], we employ l2,1-norm to
handle the two issues. We can rewrite the objective function as follows:

arg min

W,P,QT Q=I

(cid:4)X T W − Y (cid:4)2

F + α(cid:4)W(cid:4)2,1 + β(cid:4)W − QP(cid:4)2

F

(6)

Meanwhile, we deﬁne a graph Laplacian as follows: First, we deﬁne an aﬃnity
n×n whose element Aij measures the similarity between xi and xj

matrix A ∈ R
as:

(cid:3)

Aij =

1, xi and xj are k nearest neighbours;
0, otherwise.

(7)

Euclidean distance is utilized to measure whether two data points xi and xj are
k nearest neighbours in the original feature space. Then, the graph Laplacian,
L, is computed according to L = S − A, where S is a diagonal matrix with
Sii =

(cid:4)n

j=1 Aij .

Note that multimedia data have been normally shown to process a manifold
structure, we adopt manifold regularization to explore it. By applying mani-
fold regularization to the aforementioned loss function, our objective function
arrives at:

arg min

W,P,QT Q=I

T r(W T XLX T W ) + γ[α(cid:4)W(cid:4)2,1
F + (cid:4)X T W − F(cid:4)2
+β(cid:4)W − QP(cid:4)2
F ]

(8)
We deﬁne a selecting diagonal matrix U whose diagonal element Uii = ∞, if xi
is a labeled data, and Uii = 0 otherwise. To exploit both labeled and unlabeled
training data, a label prediction matrix F = [f1,··· , fn]T ∈ R
n×c is introduced
for all the training data. The label prediction of xi ∈ X is fi ∈ R
c. Following [5],
we assume that F holds smoothness on both the ground truth of training data
and on the manifold structure. Therefore, F can be obtained as follows:

tr(F T LF ) + tr((F − Y )T U (F − Y )).

arg min

F

By incorporating (9) into (6), the objective function ﬁnally becomes:

arg

min

tr(F T LF ) + tr(F − Y )T U (F − Y )
F + (cid:4)X T W − F(cid:4)2
F ]

+γ[α(cid:4)W(cid:4)2,1 + β(cid:4)W − QP(cid:4)2

F,W,P,QT Q=I

(9)

(10)

As indicated in [13], W is guaranteed to be sparse to perform feature selection

across all data points by (cid:4)W(cid:4)2,1 in our regularization term.

2.2 Optimization

The proposed function involves the l2,1-norm, which is diﬃcult to solve in a
closed form. We propose to solve this problem in the following steps. By setting
the derivative of (10) w.r.t. P equal to zero, we have

P = QT W

(11)

78

X. Chang et al.

min

By denoting W = [w1, . . . , wd]T , the objective function becomes
tr(F T LF ) + tr(F − Y )T U (F − Y )
F + (cid:4)X T W − F(cid:4)2
F ],
2(cid:3)wi(cid:3)2 .

arg
+γ[αtr(W T DW ) + β(cid:4)W − QP(cid:4)2

where D is a matrix with its diagonal elements Dii = 1
Note that for any given matrix A, we have (cid:4)A(cid:4)2

F,W,P,QT Q=I

in (10) by (11), we can rewrite the objective function as follows:

F,W,QT Q=I

arg min

tr(F T LF ) + tr((F − Y )T U (F − Y ))
+γ[αtr(W T DW ) + βtr((W − QQT W )T (W − QQT W ))
+(cid:4)X T W − F(cid:4)2
F ],

F = tr(AT A). Substituting P

(12)

(13)

(14)

(15)

(16)

(17)

(18)

(19)

(20)

(21)

According to the equation (I − QQT )(I − QQT ) = (I − QQT ), we have:

F,W,QT Q=I

arg min
+γ((cid:4)X T W − F(cid:4)2

tr(F T LF ) + tr((F − Y )T U (F − Y ))
F + tr(W T (αD + βI − βQQT )W ))

By the setting the derivative w.r.t. W to zero, we have:

W = (M − βQQT )

−1XF

where M = XX T + αD + βI.
Then the objective function becomes:

arg min

tr(F T LF ) + tr((F − Y )T U (F − Y ))
−1XF ]

+γ[tr(F T F ) − tr(F T X T (M − βQQT )

F,QT Q=I

By setting the derivative w.r.t. F to zero, we have:

LF + U (F − Y ) + γF − γX T (M − βQQT )

−1XF = 0

Thus, we have

F = (B − γX T R

−1X)

−1U Y,

where

B = L + U + γI
R = M − βQQT .
Then, the objective function can be written as

tr[Y T U (B − μX T R

−1X)

−1U Y ].

max
QT Q=I

According to the Sherman-Woodbury-Morrison matrix identity,
(B − γX T R
−1XB

−1X T (R − γXB

−1 + γB

−1 = B

−1X T )

−1X)

−1.

(22)

Semi-supervised Feature Analysis for Multimedia Annotation

79

Thus, the objective function arrives at

tr[Y T U B

−1X T J

−1XB

−1U Y ],

max
QT Q=I

where

J = (R − μXB

−1X T ) = (M − βQQT − γXB

−1X T ).

(23)

(24)

Theorem 1. The global optimization Q
ratio trace maximization problem:

∗

can be obtained by solving the following

maxQT Q=I tr[(QT CQ)

−1QT DQ],

where

C = I − β(XX T + αD + βI − γXB
−1X T N

−1U Y Y T U B

−1X T )
−1.

D = N

−1XB

−1

(25)

(26)

(27)

Proof. See Appendix.

To obtain Q, we need to conduct eigen-decomposition of C

−1D, which is O(d3)
in complexity. However, as the solution of Q requires the input of D which is
obtained according to W , it is still not straightforward to obtain Q and W . So as
shown in Algorithm 1, we propose an iterative approach to solve this problem.
The proposed iterative approach in Algorithm 1 can be veriﬁed to converge
to the optimal W by the following theorem. Following the work in [12], we can
prove the convergence of Algorithm 1.

3 Experiments

In this section, experiments are conducted on three datasets, i.e. MIML [16],
MIRFLICKR [17] and NUS-WIDE [18] to validate performance of the proposed
algorithm.

3.1 Compared Methods

To evaluate performances of the proposed method, we compare it with the fol-
lowing algorithms:

1. All features [All-Fea]: We directly use the original data for annotation with-

out feature selection as a baseline.

2. Fisher Score [F-score] [6]: This is a classical method, which selects the most
discriminative features by evaluating the importance of features one by one.
3. Feature Selection via Joint l2,1-Norms Minimization [FSNM] [3]: This algo-
rithm utilizes joint l2,1-norm minimization on both loss function and regu-
larization for joint feature selection.

4. Spectral Feature Selection [SPEC] [15]: It employs spectral regression to

select features one by one.

80

X. Chang et al.

Algorithm 1. The algorithm for solving the objective function
Data: The training data X ∈ R

d×n

The training data labels Y ∈ R
Parameters γ, α and β
Optimized W ∈ R

d×c

n×c

Result:

1 Compute the graph Laplacian matrix L ∈ R
2 Compute the selection matrix U ∈ R
3 Set t = 0 and initialize W0 ∈ R
d×c randomly;
4 repeat
5

Compute the diagonal matrix Dt as:

n×n;

n×n ;

⎡
⎢⎢⎣

1
2(cid:2)w1

t (cid:2)2

. . .

Dt =

⎤
⎥⎥⎦

6

7

8

9

10

1
2(cid:2)wd

t (cid:2)2

Compute C according to C = I − β(XX T + αD + βI − γXB−1X T )
Compute D according to D = N−1XB−1U Y Y T U B−1X T N−1.
Compute the optimal Q∗
Compute W according to W = (M − βQQT )

according to Theorem 1.
−1XF .

−1.

11 until Convergence;
12 Return W ∗

.

5. Sub-Feature Uncovering with Sparsity [SFUS] [12]: It incorporates the lat-
est advances in a joint, sparse feature selection with multi-label learning to
uncover a feature subspace which is shared among diﬀerent classes.

6. Semi-supervised Feature Selection via Spectral Analysis [sSelect] [5]: It is

semi-supervised feature selection approach based on spectral analysis.

3.2 Dataset Description

Three datasets, i.e., MIML [16] Mﬂickr [17] and NUS-WIDE [18] are used in the
experiments. A brief description of the three datasets is given as follows.

MIML: This image dataset consists of 2, 000 natural scene images. Each
image in this dataset is artiﬁcially marked with a set of labels. Over 22% of the
dataset belong to more than one class. On average, each image has 1.24 class
labels.

MIRFLICKR: The MIRFLICKR image dataset consists of 25 000 images
collected from Flickr.com. Each image is associated with 8.94 tags. We choose
33 annotated tags in the dataset as the ground truth.

NUS-WIDE: The NUS-WIDE image dataset has 269, 000 real-world images
which are collected from Flickr by Lab for Media Search in the National Univer-
sity of Singapore. All the images have been downloaded from the website, among
which 59, 563 images are unlabeled. By removing unlabeled images, we use the
remaining 209, 347 images, along with ground-truth labels in the experiments.

Semi-supervised Feature Analysis for Multimedia Annotation

81

Table 1. Settings of the Training Sets

Dataset
MIML

Size(n) Labeled Training Data (m) Number of Selected Features
{200, 240, 280, 320, 360, 400}
{240, 280, 320, 360, 400, 440, 480}
{200, 240, 280, 320, 360, 400}

5 × c, 10 × c, 15 × c
5 × c, 10 × c, 15 × c
5 × c, 10 × c, 15 × c

1, 000
NUS-WIDE 10, 000
10, 000

Mﬂickr

3.3 Experimental Setup

In the experiment, we randomly generate a training set for each dataset con-
sisting of n samples, among which m samples are labeled. The detailed settings
are shown in Table 1. The remaining data are used as testing data. Similar to
the pipeline in [2], we randomly split the training and testing data 5 times and
report average results. The libSVM [19] with RBF kernel is applied in the ex-
periment. The optimal parameters of the SVM are determined by grid search
on a tenfold crossvalidation. Following [2], the graph Laplacian, k is set as 15.
Except for the SVM parameters, the regularization parameters, γ, α and β, in
−2, 100, 102, 104}.
the objective funciton (10), are tuned in the range of {10
The number of selected features can be found in Table 1.

−4, 10

3.4 Performance Evaluation

Tables 2, 3 and 4 present experimental results measured by MAP, MicroAUC
and MacroAUC when using diﬀerent numbers of labeled training data (5 × c,
10 × c and 15 × c) respectively.

Taking MAP as an example, it is observed that: 1) The proposed method
is better than All-Fea which does not apply feature selection. Speciﬁcally, the
proposed algorithm outperforms All-Fea by about 5.5% using 10 × c labeled
training data in the MIML dataset, which indicates that feature selection can
contribute to annotation performance. 2) Our method has consistently better
performances than the other supervised feature selection algorithms. When using
5×c labeled training data in the MIML dataset, the proposed algorithm is better
than the second best supervised feature selection algorithm by 3.8%. 3) The
proposed algorithm gets better performances than the compared semi-supervised
feature selection algorithm, which demonstrates that mining label correlations
is beneﬁcial to multimedia annotation.
Table 2. Performance Comparison(±Standard Deviation(%)) when 5 × c data are
labeled

Dataset Criteria

MIML

NUS

Mﬂickr

MAP

MicroAUC
MacroAUC

MAP

MicroAUC
MacroAUC

MAP

MicroAUC
MacroAUC

All-Fea
26.1 ± 0.1
54.6 ± 0.1
52.4 ± 0.3
5.8 ± 0.2
86.4 ± 0.4
64.0 ± 0.4
12.2 ± 0.2
75.2 ± 0.2
50.3 ± 0.3

F-Score
26.9 ± 0.2
54.4 ± 0.2
52.6 ± 0.4
5.4 ± 0.1
86.1 ± 0.1
63.7 ± 0.2
12.2 ± 0.3
75.1 ± 0.3
50.3 ± 0.4

SPEC
26.1 ± 0.2
54.6 ± 0.2
52.4 ± 0.2
5.9 ± 0.2
86.5 ± 0.3
64.2 ± 0.4
12.3 ± 0.2
75.4 ± 0.3
50.4 ± 0.3

FSNM
26.1 ± 0.3
54.6 ± 0.2
52.4 ± 0.2
5.8 ± 0.3
87.2 ± 0.2
64.4 ± 0.3
12.3 ± 0.2
75.3 ± 0.4
50.5 ± 0.2

SFUS

26.2 ± 0.2
54.7 ± 0.1
52.6 ± 0.3
6.0 ± 0.2
87.4 ± 0.4
64.9 ± 0.2
12.4 ± 0.3
75.5 ± 0.2
50.7 ± 0.4

sSelect
28.9 ± 0.3
55.1 ± 0.2
53.1 ± 0.4
6.4 ± 0.3
87.9 ± 0.3
65.5 ± 0.3
13.6 ± 0.2
76.1 ± 0.3
51.3 ± 0.3

Ours

31.4 ± 0.1
55.8 ± 0.2
54.4 ± 0.2
7.1 ± 0.2
89.1 ± 0.2
66.3 ± 0.2
15.8 ± 0.1
77.3 ± 0.1
52.6 ± 0.2

X. Chang et al.

82
Table 3. Performance Comparison(±Standard Deviation(%)) when 10 × c data are
labeled

MIML

NUS

Mﬂickr

Dataset Criteria

SFUS

Ours

MAP

MicroAUC
MacroAUC

MAP

MicroAUC
MacroAUC

MAP

MicroAUC
MacroAUC

All-Fea
31.6 ± 0.3
59.3 ± 0.4
62.0 ± 0.3
6.6 ± 0.2
87.3 ± 0.3
67.5 ± 0.4
12.8 ± 0.3
78.1 ± 0.2
55.1 ± 0.3

37.1 ± 0.1
61.7 ± 0.2
63.7 ± 0.2
8.0 ± 0.2
89.5 ± 0.3
69.4 ± 0.3
16.1 ± 0.2
80.0 ± 0.1
57.3 ± 0.2
Table 4. Performance Comparison(±Standard Deviation(%)) when 15 × c data are
labeled

33.0 ± 0.1
59.8 ± 0.2
62.0 ± 0.2
7.0 ± 0.2
87.6 ± 0.3
67.9 ± 0.3
12.9 ± 0.2
78.4 ± 0.2
55.6 ± 0.2

F-Score
33.0 ± 0.2
58.9 ± 0.3
61.0 ± 0.2
6.0 ± 0.1
87.2 ± 0.2
67.4 ± 0.3
12.6 ± 0.2
78.2 ± 0.3
55.3 ± 0.2

SPEC
31.6 ± 0.2
59.3 ± 0.2
62.0 ± 0.2
6.5 ± 0.2
87.4 ± 0.5
67.7 ± 0.4
12.3 ± 0.2
78.1 ± 0.2
55.2 ± 0.4

sSelect
35.2 ± 0.2
60.4 ± 0.2
62.6 ± 0.2
6.9 ± 0.3
88.2 ± 0.3
68.2 ± 0.4
14.2 ± 0.3
78.8 ± 0.3
56.4 ± 0.4

FSNM
31.6 ± 0.3
59.4 ± 0.3
62.0 ± 0.1
6.4 ± 0.3
87.3 ± 0.2
67.6 ± 0.2
12.4 ± 0.3
78.4 ± 0.3
55.4 ± 0.3

Dataset Criteria

MIML

NUS

Mﬂickr

MAP

MicroAUC
MacroAUC

MAP

MicroAUC
MacroAUC

MAP

MicroAUC
MacroAUC

All-Fea
33.0 ± 0.2
63.4 ± 0.4
62.3 ± 0.3
6.9 ± 0.1
89.4 ± 0.2
69.2 ± 0.3
13.0 ± 0.2
79.2 ± 0.3
58.7 ± 0.4

F-Score
34.7 ± 0.1
63.3 ± 0.3
62.5 ± 0.2
6.5 ± 0.3
89.1 ± 0.3
69.1 ± 0.2
12.9 ± 0.1
79.1 ± 0.3
58.5 ± 0.3

SPEC
33.0 ± 0.2
63.5 ± 0.1
62.3 ± 0.2
6.8 ± 0.2
89.5 ± 0.2
69.3 ± 0.1
12.9 ± 0.1
79.2 ± 0.2
58.8 ± 0.2

FSNM
33.5 ± 0.3
63.4 ± 0.3
62.3 ± 0.4
6.9 ± 0.2
89.8 ± 0.4
69.5 ± 0.3
12.8 ± 0.2
79.2 ± 0.4
59.1 ± 0.3

SFUS

34.1 ± 0.1
63.7 ± 0.2
62.5 ± 0.2
7.3 ± 0.3
90.1 ± 0.3
69.7 ± 0.5
13.1 ± 0.3
79.5 ± 0.2
58.6 ± 0.3

sSelect
35.8 ± 0.2
64.2 ± 0.3
63.1 ± 0.3
7.4 ± 0.3
90.7 ± 0.4
70.2 ± 0.3
14.8 ± 0.2
80.2 ± 0.4
59.9 ± 0.2

Ours

37.9 ± 0.1
65.1 ± 0.2
64.2 ± 0.1
8.5 ± 0.2
91.9 ± 0.4
71.5 ± 0.5
16.7 ± 0.4
81.6 ± 0.2
60.4 ± 0.3

3.5 Convergence Study

In this section, an experiment is conducted to validate that our proposed iterative
algorithm monotonically decreases the objective function until convergence. 10×
c labeled training data in MIML dataset are tested in this experiment. γ, α and
β are ﬁxed at 1 which is the median value of the tuned range of the parameters.

Fig. 1. Convergence

Fig. 2.
number

Inﬂuence of

selected feature

Figure 1 shows the convergence curve of the proposed algorithm w.r.t. the
objective function value in (10) on the MIML dataset. It is observed that the
objective function values converge within 4 iterations.

Semi-supervised Feature Analysis for Multimedia Annotation

83

3.6 Inﬂuence of Selected Features

In this section, an experiment is conducted to study how the number of selected
features aﬀect the performance of the proposed algorithm. Following the above
experiment, we still use the same setting.

Figure 2 shows MAP varies w.r.t. the number of selected features. We can
observe that: 1) When the number of selected features is relatively small, MAP
of annotation is quite small. 2) When the number of selected features rises to
280, MAP increases from 0.269 to 0.284. 3) When we select 280 features, MAP
arrives at the peak level. 4) MAP keeps stable when we increase the number
of selected features from 320 to full features. From this ﬁgure, feature selection
beneﬁts to the annotation performance.

3.7 Parameter Sensitivity Study

Another experiment is conducted to test the sensitivity of parameters in (10).
Among diﬀerent parameter combinations, the proposed algorithm gains the best
performance when γ = 101, α = 104 and β = 102. We show the MAP variations
w.r.t. γ, α and β. From Figure 3, we notice that the performance of the proposed
algorithm changes corresponding to diﬀerent parameters. In summary, better
results are obtained when α, β and γ are in the range of [10

−2,··· , 102].

0.4

P
A
M

0.2

0

10^−4

10^−2

1
10^2
10^4
β

10^−410^−21 10^210^4

α

(a)

0.4

P
A
M

0.2

0

10^−4

10^−2

1
10^2
10^4
α

10^−410^−21 10^210^4

γ

(b)

0.4

P
A
M

0.2

0

10^−4

10^−2

1
10^2
10^4
β

10^−410^−21 10^210^4

γ

(c)

Fig. 3. The MAP variations of diﬀerent parameter settings using the MIML dataset

4 Conclusion

In this paper, we have proposed a novel framework for semi-supervised feature
analysis by mining label correlation. First, our method simultaneously discov-
ers correlations between labels in a shared low-dimensional subspace to improve
the annotation performance. Second, to make the classiﬁer robust for outliers,
l2,1-norm is applied to the objective function. Third, this framework is extended
into a semi-supervised scenario which exploits both labeled and unlabeled data.
We evaluate the performance of a multimedia annotation task on three diﬀer-
ent datasets. Experimental results have demonstrated that the proposed algo-
rithm consistently outperforms the other compared algorithms on all the three
datasets.

84

X. Chang et al.

Appendix

In this appendix, we prove Theorem 1.

To prove Theorem 1, we ﬁrst give the following lemma and prove it.

Lemma 1. With the same notations in the paper, we have the following equation:

(R − γXB

−1X T )

−1 = N

−1 + βN

−1Q(QT (I − βN

−1)Q)

−1QT N

−1,

where

Proof.

N = M − γXB

−1X T .

−1X T )

(R − γXB
−1
=(M − βQQT − γXB
=N

−1 + βN
−1 + βN

=N

−1X T )
−1Q(I − βQT N
−1Q(QT (I − βN

−1
−1Q)
−1)Q)

−1QT N
−1
−1QT N

−1

(28)

(29)

Proof of Theorem 1

Proof. From Eq. (29), we can tell that N is independent from Q. By employing
Lemma 1, the objective function arrives at:

tr[Y T U B

−1X T N

−1Q(QT KQ)

−1QT N

−1XB

−1U Y ],

(30)

max
QT Q=I

where K = I − βN
−1. At the same time, we have:
−1 = (M − γXB
−1.
−1X T )
N
Thus, K = I − βN
−1 = C. According to the property of trace operation that
tr(U V ) = tr(V U ) for any arbitrary matrices U and V , the objective function
can be rewritten as:

−1 = (XX T + (α + β)I − γX(L + U + γI)

−1X T )

tr[QT N

−1XB

−1U Y Y T U B

−1X T N

−1Q(QT KQ)

−1].

max
QT Q=I

The objective function is equivalent to:

tr[(QT CQ)

−1QT DQ].

max
QT Q=I

Acknowledgement. This work was partially supported by the Australian Re-
search Council the Discovery Project DP No. 130104614 and DP No. 140100104.
Any opinions, ﬁndings and conclusions or recommendations expressed in this ma-
terial are those of the author(s) and do not necessarily reﬂect the views of the
Australian Research Council.

Semi-supervised Feature Analysis for Multimedia Annotation

85

References

1. Yang, S.H., Hu, B.G.: Feature selection by nonparametric bayes error minimization.

In: Proc. PAKDD, pp. 417–428 (2008)

2. Ma, Z., Nie, F., Yang, Y., Uijlings, J.R.R., Sebe, N., Hauptmann, A.G.: Discrimi-
nating joint feature analysis for multimedia data understanding. IEEE Trans. Mul-
timedia 14(6), 1662–1672 (2012)

3. Nie, F., Henghuang, C.X., Ding, C.: Eﬃcient and robust feature selection via joint

l21-norms minimization. In: Proc. NIPS, pp. 759–768 (2007)

4. Wang, D., Yang, L., Fu, Z., Xia, J.: Prediction of thermophilic protein with pseudo
amino acid composition: An approach from combined feature selection and reduc-
tion. Protein and Peptide Letters 18(7), 684–689 (2011)

5. Zhou, Z.H., Zhang, M.L.: Semi-supervised feature selection via spectral analysis.

In: Proc. SIAM Int. Conf. Data Mining (2007)

6. Richard, D., Hart, P.E., Stork, D.G.: Pattern Classiﬁcation. Wiley-Interscience,

New York (2001)

7. Yang, Y., Wu, F., Nie, F., Shen, H.T., Zhuang, Y., Hauptmann, A.G.: Web and
personal image annotation by mining label correlation with relaxed visual graph
embedding. IEEE Trans. Image Process. 21(3), 1339–1351 (2012)

8. Cohen, I., Cozman, F.G., Sebe, N., Cirelo, M.C., Huang, T.S.: Semisupervised
learning of classiﬁers: Theory, algorithms, and their application to human-computer
interaction. In: IEEE Trans. PAMI, pp. 1553–1566 (2004)

9. Zhao, X., Li, X., Pang, C., Wang, S.: Human action recognition based on semi-
supervised discriminant analysis with global constraint. Neurocomputing 105,
45–50 (2013)

10. Wang, S., Ma, Z., Yang, Y., Li, X., Pang, C., Hauptmann, A.: Semi-supervised

multiple feature analysis for action recognition. IEEE Trans. Multimedia (2013)

11. Ji, S., Tang, L., Yu, S., Ye, J.: A shared-subspace learning framework for multi-label

classiﬁcation. ACM Trans. Knowle. Disco. Data 2(1), 8(1)–8(29) (2010)

12. Ma, Z., Nie, F., Yang, Y., Uijlings, J.R.R., Sebe, N.: Web image annotation via
subspace-sparsity collaborated feature selection. IEEE Trans. Multimedia 14(4),
1021–1030 (2012)

13. Nie, F., Huang, H., Cai, X., Ding, C.: Eﬃcient and robust feature selection via

joint l21-norms minimization. In: Proc. NIPS, pp. 1813–1821 (2010)

14. Yang, Y., Shen, H., Ma, Z., Huang, Z., Zhou, X.: L21-norm regularization discrim-

inative feature selection for unsupervised learning. In: Proc. IJCAI (July 2011)

15. Zhao, Z., Liu, H.: Spectral feature selection for supervised and unsupervised learn-

ing. In: Proc. ICML, pp. 1151–1157 (2007)

16. Zhou, Z.H., Zhang, M.L.: Multi-instance multi-label learning with application to

scene classiﬁcation. In: Proc. NIPS, pp. 1609–1616 (2006)

17. Huiskes, M.J., Lew, M.S.: The mir ﬂickr retrieval evaluation. In: Proc. MIR, pp.

39–43 (2008)

18. Chua, T.S., Tang, J., Hong, R., Li, H., Luo, Z., Zheng, Y.: Nus-wide: A real-world
web image database from national university of singapore. In: Proc. CIVR (2009)
19. Chang, C.C., Lin, C.J.: LIBSVM: A library for support vector machines.
ACM Transactions on Intelligent Systems and Technology 2, 27:1–27:27 (2011),
http://www.csie.ntu.edu.tw/~cjlin/libsvm


