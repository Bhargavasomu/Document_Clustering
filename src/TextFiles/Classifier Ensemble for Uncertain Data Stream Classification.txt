Classiﬁer Ensemble for Uncertain

Data Stream Classiﬁcation(cid:2)

Shirui Pan1, Kuan Wu2, Yang Zhang1,(cid:2)(cid:2), and Xue Li3

1 College of Information Engineering, Northwest A&F University, China

{panshirui,zhangyang}@nwsuaf.edu.cn

2 School of Information Science and Technology, Northwest University, China

3 School of Information Technology and Electrical Engineering,

wukuan1988@163.com

The University of Queensland, Brisbane, Australia

xueli@itee.uq.edu.au

Abstract. Currently available algorithms for data stream classiﬁcation are all
designed to handle precise data, while data with uncertainty or imperfection is
quite natural and widely seen in real-life applications. Uncertainty can arise in
attribute values as well as in class values. In this paper, we focus on the classi-
ﬁcation of streaming data that has different degrees of uncertainty within class
values. We propose two types of ensemble based algorithms, Static Classiﬁer En-
semble (SCE) and Dynamic Classiﬁer Ensemble (DCE) for mining uncertain data
streams. Experiments on both synthetic and real-life data set are made to compare
and contrast our proposed algorithms. The experimental results reveal that DCE
algorithm outperforms SCE algorithm.

1 Introduction

Mining on streaming data draws more and more attentions in research community in
recent years. One of the most challenge issues for data stream mining is classiﬁca-
tion analysis with concept drift [4,5,6,7,8]. The currently available algorithms for data
stream classiﬁcation are all dedicated to handle precise data, while data with uncertainty
is quite common in real-life applications. Uncertainty can appear in attributes in some
applications. In a sensor network system, the information such as humidity, temperature
and weather usually contains massive uncertainty during the processes of data collect-
ing and transmitting [2]. Uncertainty can also appear in class values. For example, in
medical diagnosis, it’s hard for the doctor to decide the exact disease of a patient. It’s
wise to predict all the possibilities of each candidate diseases rather than give a crisp
result.

In this paper, we study the data stream classiﬁcation tasks with uncertain class val-
ues. Firstly, we extend the NS-PDT algorithm [1], a decision tree algorithm dealing with
categorical attributes and uncertainty in class values, to handle continuous attributes fol-
lowing the scheme of C4.5 [10]. Secondly, we propose two ensemble based algorithms,

(cid:2) This research is supported by the National Natural Science Foundation of China (60873196)

and Chinese Universities Scientiﬁc Fund (QN2009092).

(cid:2)(cid:2) Corresponding author.

M.J. Zaki et al. (Eds.): PAKDD 2010, Part I, LNAI 6118, pp. 488–495, 2010.
c(cid:2) Springer-Verlag Berlin Heidelberg 2010

Classiﬁer Ensemble for Uncertain Data Stream Classiﬁcation

489

Static Classiﬁer Ensemble (SCE) and Dynamic Classiﬁer Ensemble (DCE), to classify
uncertain data streams with concept drift. Experiments on both synthetic data and real-
life data set are made to validate our proposed methods. The experimental results show
that DCE outperforms SCE.

This paper is organized as following: Section 2 reviews the related work on data
streams and uncertainty. Section 3 describes NS-PDT algorithm for data with uncer-
tainty in class values. Section 4 presents our ensemble based algorithms for classifying
uncertain data streams. Section 5 shows our experimental results on both synthetic and
real-life data set. And Section 6 concludes this paper and gives our future work.

2 Related Work

To the best of our knowledge, there is no work so far on classifying uncertain data
streams, while both studies on mining of data stream and uncertain data have been well
investigated in recent years.

At present, the classiﬁcation algorithms for the data stream scenario are all dedicated
to precise data only. A classical approach for data stream classiﬁcation follows ensem-
ble based scheme [4,5,6,7,8], which usually learns an ensemble of classiﬁers from the
streaming data, and then uses all the classiﬁers to predict the newly coming instances.
The way to integrate classiﬁers can be distinguished into two categories:

– Static classiﬁer ensemble. The weight of each base classiﬁer is decided before the

testing phase.

– Dynamic classiﬁer ensemble. The weight of each base classiﬁer is decided by the

testing instance.

It is concluded in [7] that dynamic methods outperform the static methods [4].

For the classiﬁcation task on uncertain data, a few decision tree algorithms have been
proposed [1,2,3]. Both DTU algorithm [2] and UDT algorithm [3] model the uncertainty
in attribute values by probability distribution functions (pdf). This is different from our
algorithm, for our goal is to deal with data uncertainty in class values. NS-PDT [1] is
a decision tree algorithm to handle data with uncertain class values. However, it can
only handle categorical attributes. Hence, in this paper, we ﬁrstly extend the initial NS-
PDT algorithm [1] to handle continuous attributes and then use it as a base classiﬁer for
ensemble classiﬁcation of data streams.

3 NS-PDT for Uncertain Data

We brieﬂy describe NS-PDT algorithm [1] for uncertainty here. Given an uncertain data
set with M classes, the possibility distribution π = {π(L1), π(L2), . . . , π(LM )} rep-
resents how likely an instance belongs to each class. More speciﬁcally, π(Li) accesses
the possibility that an instance belongs to class Li, i ∈ [1, M].

Compared with the state-of-the-art tree building algorithm C4.5 [10], NS-PDT re-
places the Information Gain by the Non-Speciﬁcity Gain (N SG), and uses the maxi-
mum Non-Speciﬁcity Gain Ratio (N SGr) to decide which attribute to be selected as
the next splitting attribute. N SG is deﬁned as [1]:

N SG(T, Ak) = U(πT

Rep

(πT

Rep

)

(1)

) − UAk

490

S. Pan et al.

Here, N SG(T, Ak) represents the amount of information precision obtained after split-
ting the data set T according to attribute Ak; U(·) accesses the information precision of
the data set. Please refer to [1] for more details.

As NS-PDT can only deal with categorical attributes, here we simply follow the
schemes utilized in C4.5 algorithm [10] to extend NS-PDT to handle continuous at-
tributes. The detailed algorithm is omitted here for lack of space.

4 Mining Uncertain Data Streams

In this paper, we follow the assumption that in data stream scenario, data arrives as
batches with variable length [11]:

d1,1, d1,2, ··· , d1,m1;
d2,1, d2,2, ··· , d2,m2;
··· ;
dn,1, dn,2, ··· , dn,mn;
··· ;

(2)

Here, di,j represents the j-th instance in the i-th batch. In our paper, we learn a NS-PDT
classiﬁer from each batch of uncertain data, and then the base classiﬁers are combined
to form an ensemble. To keep the population capacity of the ensemble, following [6],
we delete the oldest classiﬁer when the number of classiﬁers in the ensemble exceeds
a predeﬁned parameter EnsembleSize. In the testing phase, our goal is to output a
possibility distribution of test instance x over all possible classes.

4.1 Static Classiﬁer Ensemble

We proposed a static classiﬁer ensemble algorithm to classify the uncertain data streams,
which is illustrated in algorithm 1.

In algorithm 1, the function Ci.dis(x) in step 3 returns a possibility distribution over
different classes of x. In steps 4-6, the possibility for each class is accumulated. In step
8, we normalize the possibility by formula π(Li) =
π(Li)
i=1{π(Li)} [1], so that the
|M|
maximum possibility in π is 1.
Note that in algorithm 1, weii represents the weight of classiﬁer Ci, and it is decided
in the most up-to-date data batch. Let’s write |N U M| for the total number of testing
instances; D(xi) for the accuracy while predicting instance xi; πres(Lj(xi)) for the
real possibility distribution of instance xi on category j; π(Lj(xi)) for the predicted
resulting possibility distribution of instance xi on category j. Then the weight weii is
computed by the P CC dist metric given by [1]:

max

P CC dist =

(cid:2)|N UM|

i=1 D(xi)
|N U M|

D(xi) = 1 −

(cid:2)|M|
j=1(πres(Lj(xi)) − π(Lj(xi)))2

|M|

(3)

(4)

Classiﬁer Ensemble for Uncertain Data Stream Classiﬁcation

491

Algorithm 1. Classifying Uncertain Data Streams by Static Classiﬁer Ensemble
Input:

En : Ensemble of classiﬁers;
x : Testing instance ;
wei : An array of each classiﬁer’s weight;
π = {π(L1), π(L2) . . . , π(LM )}: The possibility distribution of x;

Output:
1: Initialize π(Li) = 0, i ∈ [1, M ];
2: for each Ci ∈ En do
pre[] = Ci.dis(x);
3:
for j = 1 to M do
4:
5:
6:
7: end for
8: Normalize π;
9: return π;

end for

π(Lj) = π(Lj ) + weii × prej;

Here, P CC dist criterion takes into account the average of the distances between the
resulting possibility distribution and the real possibility distribution. Note that high
value of the P CC dist criterion implies not only that the algorithm is accurate, but
also that the possibility distributions outputted by the algorithm is of high quality and
faithful to the original possibility distribution [1].

4.2 Dynamic Classiﬁer Ensemble

In our DCE algorithm, the weight of each base classiﬁer is decided by test instance x.
The weighted Euclidean distance between two instances with m attributes is given by :

d(x1, x2) =

(cid:3)
(cid:4)
(cid:4)
(cid:5)

m(cid:6)

Ai=1

wAi · dif f(xAi

1 , xAi

2 )2

(5)

Ai

2

2

1

1 , xAi

2 ) =

For a continuous attribute Ai, we have dif f(xAi
1 , xAi
(cid:7)
0 if xAi
ical attribute Ai, we have dif f(xAi
. Here, wAi represents
1 if xAi
the weight of attribute Ai, and it is decided by the non-speciﬁcity gain (N SG) [1] of
the attribute Ai. Algorithm 2 gives the details of our DCE algorithm.

. And for a categor-

1 −x
Ai
2
rangeAi
1 = xAi
(cid:3)= xAi

2 ) = x

In algorithm 2, in step 2 we retrieve Knei neighbors of x from validation data set
V according to formula (5). And the most up-to-date data batch from the stream is
used as V . In steps 3-9, the weight of each base classiﬁer is determined. The function
Ci.Acc(neij) in step 6 returns the accuracy of classiﬁer Ci while predicting the instance
neij, and the accuracy is decided according to formula (4). The function d(neij, x)
in step 7 returns the distance following formula (5). After predicting an instance, the
weight of the corresponding base classiﬁer is accumulated together. Accuracy and dis-
tance are the main factors that affect weii. In steps 10-14, some base classiﬁers with
lower weight are ignored following [6]. The function predict(E, x, wei) in step 14

492

S. Pan et al.

Algorithm 2. Classifying Uncertain Data Streams by Dynamic Classiﬁer Ensemble
Input:

En : Ensemble of classiﬁers;
x : Testing instance ;
V : Validation Set;
π = {π(L1), π(L2) . . . , π(LM )}: The possibility distribution of x;

weii = 0;
for each neij ∈ N ei do
acc = Ci.Acc(neij );
weii = weii + acc/d(neij , x);

Output:
1: Initialize π(Li) = 0, i ∈ [1, M ];
2: Retrieve Knei neighbors from V to form data set N ei;
3: for each Ci ∈ En do
4:
5:
6:
7:
8:
9: end for
10: m1 = max{weii}, i ∈ [1, |En|];
11: m2 = min{weii}, i ∈ [1, |En|];
12: mid = (m1 + m2)/2;
13: E = {ei|weii ≥ mid, ei ∈ En};
14: π = predict(E, x, wei);
15: return π;

end for

returns the predicted result of x by a weighted voting scheme. The weighted voting
scheme is the same as in algorithm 1.

5 Experiments

In this section, we report our experimental results. We deal with the data streams with
uncertain class information and concept drift, which is regarded as an important issue in
mining data streams [4,5,6,7]. Since no benchmark uncertain data set can be found in the
literature, we simulate the uncertain data on synthetic data and real-life data set. Here,
moving hyperplane concept [4,7] was used as the synthetic data set with continuous
attributes, and RCV1-v21 was used as the real-life data set with categorical attributes in
our experiments.

The uncertain data set was generated by using the approach described in [1]. We
simulated various levels of uncertainty (X%) when generating possibilistic training
data. Firstly, we randomly selected X% of instances in each data batch as uncertain
set. Secondly, for each instance in the uncertain set, if the instance belongs to the i-th
class, we set π(ωi) = 1, and π(ωj) = ϕ,∀j (cid:3)= i. Here, ϕ is a random value distributed
uniformly in range of [0, 1]. Thirdly, for each instance of the remaining (100 − X)%
instances, we assigned a certainly sure possibility distribution (if the instance belongs
to the i-th class, we set π(ωi) = 1, and π(ωj) = 0,∀j (cid:3)= i). The data set used for test
in our experiments was also with a certainly sure possibility distribution, following [1].

1 http://jmlr.csail.mit.edu/papers/volume5/lewis04a/lyrl2004 rcv1v2 README.htm

Classiﬁer Ensemble for Uncertain Data Stream Classiﬁcation

493

P CC dist is used as the evaluation metric in our experiments for measuring the
classiﬁcation performance of classiﬁers on uncertain data set. Note that high value of
P CC dist implies not only that the algorithm is accurate, but also that the distribution
possibility is faithful to the original possibility distribution [1] .

In our experiments, we set EnsembleSize=25, following [7]; and we set Knei=5.

Meanwhile, we set ChunkSize, the number of instances in each batch, to 500.

Our experiments were made on a PC with Pentium 4 3.0 GHz CPU and 1G memory.
All of the algorithms were implemented in Java with help of WEKA2 software package.

5.1 Moving Hyperplane Concept with Gradual Concept Drift

Moving hyperplanes have been widely used to simulate time-changing concepts [4]. In
this subsection, we report our experiments on moving hyperplane concept. A moving
hyperplane in d-dimensional space is denoted by:

i=1 aixi = a0.

We followed the same procedure in [4] to simulate concept drift. We used K for the
total number of dimensions whose weights are changing; S for the magnitude of the
change (every N instances) for weights a1,··· , ak. For more detailed descriptions of
moving hyperplanes, please refer to [4].

(cid:2)

d

We set d=10, N =1000 in our experiments. For each parameter setting, we generated

100 batches of data. The averaged results on the 100 batches are reported in Table 1.

From Table 1, it could be concluded that, DCE outperforms SCE in all scenarios,
with averaged improvement being about 2%. It could be also seen that, with the in-
creasing of X, the performances of both SCE and DCE decline. It is shown that the
higher the level of uncertainty in the training set is, the more imprecise the training set
will be, and therefore the more difﬁcult for the classiﬁer to learn an accurate model.

We also study the impact of the parameter Knei. Here, we set S=0.1, X=20 and K
was selected from [1,10] randomly. We conducted 10 trails and the averaged result is
shown in Fig. 1. It can be shown in Fig. 1 that Knei can not be neither too small nor too
large. We set Knei=5 in other experiments as it usually gives us good results.

Table 1. Experiments on Moving Hyperplane
Concept

X% S

K=2

K=5

K=8

SCE DCE SCE DCE SCE DCE
0.1 0.770 0.787 0.768 0.785 0.768 0.783
20 0.5 0.773 0.789 0.764 0.781 0.763 0.778
1.0 0.771 0.790 0.761 0.778 0.762 0.777
0.1 0.749 0.767 0.748 0.766 0.748 0.764
40 0.5 0.749 0.768 0.743 0.760 0.743 0.759
1.0 0.752 0.770 0.738 0.756 0.741 0.758
0.1 0.725 0.744 0.723 0.741 0.720 0.738
60 0.5 0.725 0.744 0.715 0.733 0.717 0.735
1.0 0.726 0.746 0.712 0.732 0.717 0.735

SCE
DCE

 

0.8

0.79

0.78

0.77

0.76

i

t
s
d
_
C
C
P

0.75

 
1 5 10

20

30

40

70
Nunber of neighbors

50

60

80

90 100

Fig. 1. Experiment with Knei

2 http://www.cs.waikato.ac.nz/ml/weka/

494

S. Pan et al.

(A) X=20

(B) X=40

(C) X=60

1

0.9

0.8

0.7

0.6

0.5

i

t
s
d
_
C
C
P

 

SCE
DCE

1

0.9

0.8

0.7

0.6

0.5

i

t
s
d
_
C
C
P

 

SCE
DCE

1

0.9

0.8

0.7

0.6

0.5

i

t
s
d
_
C
C
P

 

SCE
DCE

 

0.4
0

10

20
Batch ID

30

40

 

0.4
0

10

20
Batch ID

30

40

 

0.4
0

10

20
Batch ID

30

40

Fig. 2. Experiments on RCV1 v2 Set for Abrupt Concept Drift

5.2 Experiments on RCV1-v2 Text Data Set

In this section, we report our experimental results on a real-life text dataset. RCV1-v2
is a new benchmark collection for text categorization [9]. The news stories in RCV1-v2
were divided into two datasets, training set and testing set. The training dataset was
used and four largest categories, CCAT, ECAT, GCAT, and MCAT were considered as
the main topics in our experiments to simulate concept drift. After preprocessing, each
document was presented by a binary vector, and information gain algorithm was used
to select 100 most predictive features.

The data set in our experiments was decomposed into 46 batches. We vary uncer-
tainty X% as follow: 20, 40, 60. In each scenario of our experiments, we selected one
category as TopicA and others as TopicB. Concept drift occurs between TopicA and Top-
icB. Therefore, there are 12 possible combination for 4 categories. We experiment 12
trails and the averaged result is reported.

We simulate abrupt drift in our experiments as follows: In the batches 0-24, all the
instances of TopicA were labeled as positive, others were labeled as negative. In batches
25-46, all the instances of TopicB were labeled as positive, others were labeled as neg-
ative. The experimental results for abrupt concept drift are given in Fig. 2.

As expected, from Fig. 2, it could be seem that in batch 25 when abrupt drift occurs,
both DCE and SCE have a dramatic decline in P CC dist. However, DCE recovers
much faster than SCE in the later batches. In all levels of uncertainty, DCE outper-
forms SCE. It reveals that DCE outperforms SCE in handling abrupt concept drift with
uncertainty.

5.3 Time Analysis

Both SCE and DCE consume the same time in training, because the ways to construct
the ensemble is the same. Here we compare the testing time. We generated data streams
with varied ChunkSize on hyperplane concept (K=10, S=1). Consider 100 batches of
data with X=20. Fig. 3 shows that large ChunkSize offers better performances. The
DCE also performs better than SCE. However, the testing time of the two methods on
the whole streams is signiﬁcantly different. From Fig. 4 we can see that with a large
ChunkSize, DCE consumes much more testing time than SCE. It is because when
predicting an instance, DCE needs to traverse the whole validation set to get some
nearest neighbors. So it’s a tradeoff between good performance and faster responding
action.

Classiﬁer Ensemble for Uncertain Data Stream Classiﬁcation

495

SCE
DCE

 

1000

SCE
DCE

 

)
s
d
n
o
c
e
S

(
 

i

e
m
T
g
n

 

i
t
s
e
T

100

10

0.85

0.83

0.81

0.79

0.77

i

t
s
d
_
C
C
P

0.75

 

250 500

1000

1500
ChunkSize

2000

2500

 

1
250 500

1000

1500
ChunkSize

2000

2500

Fig. 3. P CC dist on varying ChunkSize

Fig. 4. Testing time on varying ChunkSize

6 Conclusion and Future Work

In this paper, we propose two types of ensemble based approaches to classify data
streams with uncertainty in class values. We also extend the decision tree (NS-PDT)
approach to handle data with continuous attributes. Experiments on both synthetic and
real-life datasets are made to validate our proposed methods. Our experimental results
show that the dynamic classiﬁer ensemble (DCE) for uncertain data stream outperforms
the static classiﬁer ensemble (SCE).

Attribute uncertainty is also natural and prevalent in many real-life applications, we

plan to study this kind of uncertain data streams in future work.

References

1. Jenhani, I., Amor, N.B., Eluouedi, Z.: Decision trees as possibilistic classiﬁers. International

Journal of Approximate Reasoning 48, 784–807 (2008)

2. Qin, B., Xia, Y., Li, F.: DTU: A Decision Tree for Uncertain Data. In: Theeramunkong,
T., Kijsirikul, B., Cercone, N., Ho, T.-B. (eds.) PAKDD 2009. LNCS, vol. 5476, pp. 4–15.
Springer, Heidelberg (2009)

3. Tsang, S., Kao, B., Yip, K.Y., Ho, W., Lee, S.D.: Decision Trees for Uncertain Data. In: Proc.

of ICDE 2009, pp. 441–444 (2009)

4. Wang, H., Fan, W., Yu, P., Han, J.: Mining concept-drifting data streams using ensemble

classiﬁers. In: Proc. of KDD 2003, pp. 226–235 (2003)

5. Zhu, X., Wu, X., Yang, Y.: Dynamic classiﬁer selection for effective mining from noisy data

streams. In: ICDM 2004, pp. 305–312 (2004)

6. Zhang, Y., Jin, X.: An automatic construction and organization strategy for ensemble learning

on data streams. ACM SIGMOD Record 35(3), 28–33 (2006)

7. Tsymbal, A., Pechenizkiy, M., Cunningham, P., Puuronen, S.: Dynamic integration of clas-

siﬁers for handling concept drift. Information fusion 9, 56–68 (2008)

8. Kolter, J., Maloof, M.: Dynamic weighted majority: a new ensemble method for tracking

concept drift. In: Proc. of ICDM 2003, pp. 123–130 (2003)

9. Lewis, D.D., Yang, Y., Rose, T., Li, F., Zhu, X., Wu, X., Yang, Y.: RCV1: A New Benchmark
Collection for Text Categorization Research. Journal of Machine Learning Research 1(5),
361–397 (2004)

10. Quinlan, J.R.: C4.5: Programs for Machine Learning. Morgan Kaufman Publishers, San

Francisco (1993)

11. Klinkenberg, R., Joachims, T.: Detecting concept drift with support vector machines. In:

Proc. of ICML 2000, pp. 487–494 (2000)


