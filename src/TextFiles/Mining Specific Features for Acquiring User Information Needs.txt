Mining Speciﬁc Features for Acquiring User

Information Needs

Abdulmohsen Algarni1 and Yuefeng Li2,(cid:2)

1 College of Computer Science, King Khalid University

Saudi Arabia, B.O.Box 394, ABHA 61411

2 School of Electrical Engineering and Computer Science

a.algarni@kku.edu.sa

Queensland University of Technology, Brisbane, QLD 4001, Australia

y2.li@qut.edu.au

Abstract. Term-based approaches can extract many features in text
documents, but most include noise. Many popular text-mining strategies
have been adapted to reduce noisy information from extracted features;
however, text-mining techniques suﬀer from low frequency. The key is-
sue is how to discover relevance features in text documents to fulﬁl user
information needs. To address this issue, we propose a new method to
extract speciﬁc features from user relevance feedback. The proposed ap-
proach includes two stages. The ﬁrst stage extracts topics (or patterns)
from text documents to focus on interesting topics. In the second stage,
topics are deployed to lower level terms to address the low-frequency
problem and ﬁnd speciﬁc terms. The speciﬁc terms are determined based
on their appearances in relevance feedback and their distribution in top-
ics or high-level patterns. We test our proposed method with extensive
experiments in the Reuters Corpus Volume 1 dataset and TREC topics.
Results show that our proposed approach signiﬁcantly outperforms the
state-of-the-art models.

Keywords: Feature extraction, Pattern mining, Relevance feedback,
Text classiﬁcation.

1

Introduction

One of the objectives of knowledge extraction is to build user proﬁles by ﬁnding a
set of features from feedback documents to describe user information needs. This
is a particularly challenging task in modern information analysis, empirically and
theoretically [11,13]. This problem has received much attention from the data
mining, web intelligence, and information retrieval communities.

Information retrieval has deployed many eﬀective term-based methods to ﬁnd
popular terms [14]. The advantages of term-based methods include eﬃcient com-
putational performance and mature theories for term weighting. However, many
noisy terms can be extracted from the large-scale feedback documents. Words

(cid:2) Corresponding author.

J. Pei et al. (Eds.): PAKDD 2013, Part I, LNAI 7818, pp. 532–543, 2013.
c(cid:2) Springer-Verlag Berlin Heidelberg 2013

Mining Speciﬁc Features for Acquiring User Information Needs

533

and phrases have also been used as terms in many models. Many researchers
believe phrases are more useful and crucial than words for query expansion in
building eﬀective ranking functions [14,4,22]. However, there are usually many
redundant and noisy phrases [18,19].

Popular terms are useful for describing documents; however, they do not focus
on the interesting topics in these documents. We argue that patterns (itemsets,
or sets of terms) can be a good alternative form of terms for describing interesting
topics in documents.

Data-mining techniques have been developed–e.g., maximal, closed, and mas-
ter patterns–for removing redundant and noisy patterns [27,25]. By using the ad-
vantages of data-mining techniques, pattern taxonomy models (PTM) [24,23,12]
have been proposed for using closed sequential patterns in text classiﬁcation.
These pattern mining-based approaches have improved the eﬀectiveness for rel-
evant (positive) feedback documents, but oﬀer fewer signiﬁcant improvements
compared with term-based methods for using both relevant and irrelevant
feedback.

Existing approaches focus more on extracting general or popular topics from
feedback documents rather than what users really want. Several attempts have
been made to determine terms speciﬁcity regarding to term distribution in docu-
ments. For example, Inverse Document Frequency (IDF ) measures terms speci-
ﬁcity in a set of documents, but much noisy information in text documents aﬀects
IDF for ﬁnding speciﬁc features.

This research proposes a speciﬁcity deﬁnition for mining speciﬁc features for
user information needs. The proposed approach includes two stages. The ﬁrst
stage extracts high-level patterns (or topics) from text documents to focus on
interesting topics in order to reduce the noise. The second stage deploys these
topics (high-level patterns) to lower level terms to address the low-frequency
problem in order to ﬁnd speciﬁc features. The proposed approach can determine
speciﬁc terms based on both their appearances in relevance feedback and their
distribution in interesting topics (or high-level patterns).

The remainder of this paper is organized as follows. Section 2 introduces a
detailed overview of related works. Section 3 reviews concepts of patterns in text
documents. Section 4 proposes a method of mining speciﬁc features from positive
feedback documents. Section 5 shows empirical results; Section 6 reports related
discussions, followed by the ﬁnal sections concluding remarks.

2 Related Work

Scientists have proposed many types of text representation. A well-known one is
the bag-of-words model that uses keywords, or terms, in the vector of the feature
space. In [9], the tf*idf weighting scheme was used for text representation in
Rocchio classiﬁers. Enhanced from tf*idf, the global IDF and entropy weighting
scheme was proposed in [5]. Various weighting schemes for the bag-of-words
representation were given in [1,7].

Bag of words problem is how to select a limited number of feature terms to
increase the system’s eﬃciency and avoid overﬁtting [19]. To reduce the number

534

A. Algarni and Y. Li

of features, many dimensionality reduction approaches have been conducted using
feature selection techniques like information gain, mutual information, chi-square,
and odds ratio [19].

In [2], data-mining techniques analyzed text by extracting co-occurring terms
as descriptive phrases from document collections. However, the eﬀectiveness of
the text classiﬁcation systems using phrases as text representation showed no
signiﬁcant improvement. The likely reason is that a phrase-based method has
lower consistency of assignment and lower document frequency for terms [8].

The data-mining community has extensively studied pattern mining for many
years. Usually, existing data-mining techniques discover numerous patterns (e.g.,
sets of terms) from a training set, but many patterns may be redundant [25].
Nevertheless, the challenge is dealing eﬀectively with the many discovered pat-
terns and terms with much noise.

Regarding to these setbacks, closed patterns present a promising alternative
to phrases [23,6]. Patterns, like terms, enjoy good statistical properties. To use
closed patterns eﬀectively in text mining, patterns have been evaluated by being
deployed into a vector with a set of terms and term-weight distributions. The
pattern-deploying method encouragingly improves eﬀectiveness compared with
traditional probabilistic models and Rocchio-based methods [23,12].

In summary, we can group the existing methods for ﬁnding relevance features
into three approaches. The ﬁrst one is to revise feature terms in both positive and
negative samples, like Rocchio-based models [15]. The second approach is based
on how often terms appear or do not appear in positive and negative samples
like probabilistic-based models [26]. The third approach is to describe speciﬁc
features based on their appearances in both patterns or/and documents [23,10].
In this paper, we further develop the third approach to utilize high-level patterns
(or topics) extracted from only positive samples (relevant documents) for ﬁnding
speciﬁc terms. The major research issue is how to determine the topics speciﬁcity
of terms according their distributions in both documents and topics.

3 Deﬁnition

In this paper, we assume that all documents are split in paragraphs. So a given
document d yields a set of paragraphs P S(d). Let D be a training set of docu-
ments, which consists of a set of positive documents, D+; and a set of negative
. Let T = {t1, t2, . . . , tm} be a set of terms (or keywords) which
documents, D
are extracted from the set of positive documents, D+.

−

3.1 Frequent and Closed Patterns

Let T = {t1, t2, . . . , tm} be a set of terms which are extracted from D+. Given a
termset X, a set of terms, in document d, coverset(X) = {dp|dp ∈ P S(d), X ⊆
dp}. Its absolute support supa(X) = |coverset(X)|; and its relative support
. A termset X is called frequent pattern if its supa (or
supr(X) =
supr) ≥ min sup, a minimum support.

|coverset(X)|

|P S(d)|

Mining Speciﬁc Features for Acquiring User Information Needs

535

Table 1. A set of paragraphs

Table 2. Frequent patterns and cover-
ing sets

P arapgraph

dp1
dp2
dp3
dp4
dp5
dp6

T erms

t1 t2

t3 t4 t6

t3 t4 t5 t6
t3 t4 t5 t6
t1 t2 t6 t7

t1 t2 t7

F req. P attern Covering Set
{t3, t4, t6}
{dp2, dp3, dp4}
{t3, t4}
{dp2, dp3, dp4}
{dp2, dp3, dp4}
{t3, t6}
{t4, t6}
{dp2, dp3, dp4}
{t3}
{dp2, dp3, dp4}
{t4}
{dp2, dp3, dp4}
{dp1, dp5, dp6}
{t1, t2}
{dp1, dp5, dp6}
{t1}
{t2}
{dp1, dp5, dp6}
{t6}
{dp2, dp3, dp4, dp5}

Table 1 lists a set of paragraphs for a given document d, where P S(d) =

rise to ten frequent patterns which are illustrated in Table 2. Normally not all

{dp1, dp2, . . . , dp6}, and duplicate terms are removed. Let min sup = 3 giving
frequent patterns are useful [24,25]. For example, pattern {t3, t4} always occurs
with term t6 in paragraphs (see Table 1); therefore, we want to keep the larger
pattern only.
Given a set of paragraphs Y ⊆ P S(d), we can deﬁne its termset, which satisﬁes

termset(Y ) = {t|∀dp ∈ Y ⇒ t ∈ dp}.

Let Cls(X) = termset(coverset(X)) be the closure of X. We call X closed if
and only if X = Cls(X).

Let X be a closed pattern. We have

for all pattern X1 ⊃ X.

supa(X1) < supa(X)

(1)

3.2 Closed Sequential Patterns

A sequential pattern s =< t1, . . . , tr > (ti ∈ T ) is an ordered list of terms.
A sequence s1 =< x1, . . . , xi > is a sub-sequence of another sequence s2 =<
y1, . . . , yj >, denoted by s1 (cid:8) s2, iﬀ ∃j1, . . . , ji such that 1 ≤ j1 < j2 . . . < ji ≤ j
and x1 = yj1 , x2 = yj2 , . . . , xi = yji . Given s1 (cid:8) s2, we usually say s1 is a
sub-pattern of s2, and s2 is a super-pattern of s1. In the following, we simply
say patterns for sequential patterns.
Given a pattern (an ordered termset ) X in document d, (cid:2)X(cid:3) is still used to
denote the covering set of X, which includes all paragraphs ps ∈ P S(d) such
that X (cid:8) ps, i.e., (cid:2)X(cid:3) = {ps|ps ∈ P S(d), X (cid:8) ps}. Its absolute support and
relative support are deﬁned as the same as for the normal patterns.
A sequential pattern X is called frequent pattern if its relative support ≥
min sup, a minimum support. The property of closed patterns can be used to
deﬁne closed sequential patterns. A frequent sequential pattern X is called closed

if not ∃ any super-pattern X1 of X such that supa(X1) = supa(X).

536

A. Algarni and Y. Li

4 Acquiring User Information Needs

Extracting high-level patterns from text documents would help us to focus on
interesting topics in positive (relevant) feedback documents. In this paper, a fea-
ture’s speciﬁcity describes the extent to which the feature focuses on interesting
topics.

4.1 Two Levels of Features

Term-based user proﬁles are considered the most mature theories for term weight-
ing to emerge over the last couple decades in information retrieval. A term-based
model is based on the bag of words, which uses terms as elements and evaluates
term weights based on terms’ appearance or distribution in documents. This
main drawback is that the relationship among words cannot be depicted [20].
Another problem in considering single words as features is semantic ambigui-
ties, such as synonyms and polysemy. To overcome the limitations of term-based
approaches, pattern mining-based techniques are used for information ﬁltering
systems, as patterns are less ambiguous and more discriminative than individual
terms; but, pattern-based approaches suﬀer from low frequency problem.

To improve the eﬃciency of pattern taxonomy mining, an algorithm, SP-
Mining(D+, min sup) [24], was proposed to ﬁnd closed sequential patterns in
paragraphes for all documents ∈ D+ that used the well-known Apriori property
to reduce searching space. For all positive documents d ∈ D+, the SPMining
algorithm discovered all closed sequential patterns based on a given min sup.

Let SP1, SP2, ..., SPn be the sets of discovered closed sequential patterns for
all document di ∈ D+(i = 1,··· , n), where n = |D+|). All possible candidates
of speciﬁc terms can be obtained from all SPi (i = 1,··· , n) as follows:

T =

n(cid:2)

i=1

{t|t ∈ p, p ∈ SPi}

4.2 Speciﬁcity of Low-level Features

We assume a topic is a set of terms. We call a topic interesting if it is a closed
sequential pattern. Usually large number of topics can be extracted from feed-
back documents, and there are overlaps among many topics. It is very diﬃcult
to determine which topic are useful to describe user information needs. More-
over, the user can be interested in one or many topics. Thus, in this paper we
deﬁne the speciﬁcity of a term t based on the speciﬁcity of topics that contain t
(ST ); its distribution in topics (or term’s frequency in patterns, T F P ) and its
appearance in documents (or called document frequency, DF )

The speciﬁcity of any given term t to topics ST can be measured by the topics
size and the terms distribution in topics that contain t. The topic that contains
more terms is unlikely used by other irrelevant documents, and then it is more

Mining Speciﬁc Features for Acquiring User Information Needs

537

likely a speciﬁc topic for user information needs. Thus, a large topic that contains
term t is more important than a short topic. Moreover, the relative support of
topics is signiﬁcant for measure the term’s speciﬁcity. Therefore, the speciﬁcity
of a term to topics ST can be calculated as follows:

ST (t) =

n(cid:3)

(cid:3)

t∈p⊆SPi

i=1

supr(p, di) × |p|

where supr(p, di) is the relative support of pattern p in document di and n is
the number of positive feedback documents.

All positive documents in the user feedback describe user information needs.
In other words, terms that appear in all positive documents are likely speciﬁc
features. For example, if the user seeks information about Unicef, we expect the
keyword Unicef appear in all positive feedback documents; however, many feed-
back documents contain noisy terms. To reduce noisy terms, the terms frequency
will be calculated only according to their appearances in the extracted topics
rather than in documents.
to calculate the speciﬁcity of term t for all t ∈ T :

Based on the above analysis, in this paper, we propose the following equation

spe(t) = T F P (t) × DF (t) × ST (t)
(cid:6)
supa(p, di)
(cid:7)

t∈p⊆SPi

(cid:5)

n(cid:5)

i=1
n(cid:5)

(cid:5)

(cid:4)

(cid:4)

=

(cid:4)

×

supr(p, dj) × |p|(cid:8)(cid:6)

t∈p⊆SPj

j=1

|coverage(t,D+)|

|D+|

(cid:6)
×

(cid:4)

n(cid:5)

(cid:5)

(cid:6)
×

supa(p, di)

= 1
(cid:4)
n

|coverage(t, D+)| ×
n(cid:5)

(cid:5)

(cid:7)

t∈p⊆SPi

supr(p, dj) × |p|(cid:8)(cid:6)

i=1

j=1

t∈p⊆SPj
× n(cid:5)

n(cid:5)

i=1

j=1

= r(t)
n

(cid:9)

(cid:5)

t∈p⊆SPi

supa(p, di) × (cid:5)
t∈q⊆SPj

supr(q, dj ) × |q|(cid:8)
(cid:7)

(cid:10)

where, supa(p, di) is the frequency of patterns that contain term t in document
d; r(t) = |coverage(t, D+)| is the number of positive documents that contain
terms t; and n is the total number of positive documents.

For a term t, the higher of its spe score is, the more useful for describing the
user information needs. The relevance of an incoming document d to the user
information needs can be evaluated using the following ranking function:

(cid:3)

rank(d) =

t∈T

spe(t)τ (t, d)

where τ (t, d) = 1 if t ∈ d; τ (t, d) = 0 otherwise.

538

A. Algarni and Y. Li

5 Evaluation

In this paper, we conduct binary text classiﬁcation to test the proposed approach.
We use routing ﬁltering to avoid the need for threshold tuning, which is beyond
our research scope. The proposed model in this paper is called Speciﬁc Feature
Discovery (SFD). The SFD model uses positive relevance feedback to build user
proﬁles. Unlike other models, it uses only positive feedback for selecting useful
features.

According to Buckley and others [3], 50 topics are adequate to make a stable,
high quality experiment. This evaluation used the 50 expert-designed topics
in Reuters Corpus Volume 1 (RCV1) [21]. RCV1 corpus consists of 806,791
documents produced by Reuter’s journalists. The document collection is divided
into training sets and test sets. These topics were developed by human assessors
of the National Institute of Standards and Technology (NIST). The documents
are treated as plain text documents by preprocessing the documents. The tasks
of removing stop-words according to a given stop-words list and stemming term
by applying the Porter Stemming algorithm are conducted.

5.1 Baseline Models and Setting

The main baseline models were the well-known term-based methods: Rocchio,
BM25 and SVM. The Rocchio algorithm [17] has been widely adopted in the
areas of text categorization and information ﬁltering. It can be used to build a
proﬁle for representing the concept of a topic which consists of a set of relevant
(positive) and irrelevant (negative) documents. we set α = β = 1.0 in this paper.
BM25 [16] is one of state-of-the-art term-based models. The values of k1 and

b are set as 1.2 and 0.75, respectively, in this paper.

Information ﬁltering can also be regarded as a special form of text classiﬁca-
tion [19]. SVM is a statistical method that can be used to ﬁnd a hyperplane that
best separates two classes. SVM achieved the best performance on the Reuters-
21578 data collection for document classiﬁcation [28]. The decision function in
SVM is deﬁned as:

h(x) = sign(w · x + b) =

⎧
⎨
⎩

+1 if (w · x + b) > 0
−1 otherwise

where x is the input object; b  (cid:11) is a threshold and w =
l
i=1 yiαixi for
the given training data: (xi, yi), ..., (xl, yl), where xi ε (cid:11)n and yi = +1(−1), if
document xi is labelled positive (negative). αi  (cid:11) is the weight of the sample
xi and satisﬁes the constraint:

(cid:5)

∀i : αi ≥ 0 and

l(cid:3)

i=1

αiyi = 0

(2)

Mining Speciﬁc Features for Acquiring User Information Needs

539

To compare with other baseline models, SVM was used to rank documents rather
than to make binary decisions. For this purpose, threshold b was ignored. For
the documents in a training set, we knew only what were positive (or negative),
but not which one was more important. To avoid this bias, we assigned the same
αi value (i.e., 1) to each positive document ﬁrst, and then determined the same
αi (i.e., ´α) value to each negative document based on Eq.(2). Therefore, we used
the following weighting function to estimate the similarity between a testing
document and a given topic:

weight(d) = w · d

where · means inner product ; d is the term vector of the testing document; and

(cid:3)

(cid:3)

w = (

di∈D+

di) + (

dj∈D−

dj ´α).

For each topic, we also chose 150 terms in the positive documents, based on
tf*idf values for all term-based baseline models.

5.2 Evaluation Measures

Precision p and recall r are suitable because the complete classiﬁcation is based
on the positive class. In order to evaluate the eﬀectiveness of the proposed
SFD method, we utilized a variety of existing methods; Mean Average Preci-
sion (MAP ),breakeven points(b/p), the precision of top-20 returned documents,
F-scores and recall at 11-points (IAP ). These methods have been widely used
to evaluate the performance of information ﬁltering system.

A statistical method, t-test, was also used to analyse the experimental results.
The t-test assesses whether the means of two groups are statistically diﬀerent
from each other. If the p-value associated with t is signiﬁcantly low (<0.05), there
is evidence to reject the null hypothesis, and the diﬀerence in means across the
paired observations is signiﬁcant.

In summary, the eﬀectiveness is measured by ﬁve diﬀerent means: the average
precision of the top 20 documents, F1 measure, Mean Average Precision (MAP ),
the break-even point (b/p), and Interpolated Average Precision (IAP) on 11-
points. The larger their values are, the better the system performs.

5.3 Results

We compared the proposed method, SFD, with baseline models, including Roc-
chio, BM25, and SVM. The experimental results for all 50 assessing topics are
reported in Table 3, with the percentage changes %chg. The percentage changes
%chg of the proposed SFD model were compared with the performance of the
best baseline model (Rocchio). The SFD model outperforms all the baseline
models, including the deployment of sequential closed patterns without using
the speciﬁcity score (Seq. Cls). The average percentage of improvement over the

540

A. Algarni and Y. Li

Fig. 1. Comparison of the results in all assessing topics

Table 3. Detailed comparisons of all models in all assessing topics

SFD
Seq.Cls*
Rocchio
SVM
BM25
%chg
* Applying Deploying method to sequential closed patterns without weight revision.

+12.71% +9.05% + 5.70% +8.59%

+8.84%

Fβ=1
0.456
0.439
0.431
0.421
0.414

b/p

0.460
0.430
0.420
0.408
0.407

top-20
0.543
0.496
0.474
0.453
0.445

MAP
0.473
0.444
0.431
0.409
0.407

IAP
0.496
0.464
0.452
0.435
0.428

standard measures is 8.98%, with a maximum of 12.71% and minimum 5.70%
compared with the best results in Table 3.

The improvements are consistent and very signiﬁcant on all ﬁve measures, as
shown by 11-points on all 50 assessing topics in Figure 1. The t-test p values in
Table 4 indicate the signiﬁcance of improvements in the SFD model statistically.
Therefore, we conclude the SFD model is an exciting achievement in discovering
high-quality features in text documents because it uses high-level patterns to get
low-level terms and revises low-level terms based on speciﬁcity and distributions
in positive relevance feedback.

5.4 Discussion

Generally, term-based approaches extract many terms from documents without
considering terms relationships. The advantage of using patterns is that they
carry more semantic information than single terms–but these suﬀer from low
frequency [10]. Based on that observation, we used the patterns in this paper
to consider the relationship among terms to reduce the extracted noise terms in
features extracted from documents. As shown in Table 5, the number of extracted
patterns is about 202 patterns with an average length of 2 terms in patterns.

Mining Speciﬁc Features for Acquiring User Information Needs

541

Table 4. T-Test p-values for all models compared with the SFD model in all assessing
topics

Rocchio
SVM
BM25

top-20
0.02621
0.00269
0.00516

MAP
0.03650
0.00122
0.00424

Fβ=1

0.05762
0.00658
0.00645

b/p

IAP
0.08629 0.02868
0.02094 0.00135
0.03155 0.00206

Table 5. Patterns statistical information for the proposed model

|SP|
202

Average length of P

2

|T|
156

50 Topics

supr
86.393

Table 6. Statistical information for the proposed model

|D+|
13

Average No. terms

terms weight in topics

spe

156

202.788

250.570

From that information, we expected about 404 = 202∗2 terms in all patterns. But
the actual number of terms deployed from those patterns are 156 terms, which
indicated that about 61.37 = 404−156
of the patterns overlap. This overlapping
from the closed pattern indicates some terms importance in the documents.

404

As shown in Table 5, the average weight of patterns for each topic is 86.393
distributed into 202 patterns on average, which gave about 0.428 = 86.393
202 . On
the other hand, Table 6 shows a weight of about 202.788 distributed in 156 terms
on average. That information indicates a weight of about 57.40% = 202.788−86.393
is increased according to terms from the deploying method.

202.788

Using common sense, we know that positive terms with large speciﬁcity are
more interesting than general terms with less speciﬁcity for a given topic. How-
ever, evaluating the speciﬁcity of a given term is challenging. The proposed
model calculates the speciﬁcity of terms based on the speciﬁcity of each term
to the topic ST , distribution of terms in topic T F P , and appearance of terms
in the documents DF . Unlike other models, in this paper, speciﬁc terms ap-
pear in most positive patterns in positive documents. As shown in Table 6,
before revision, 202.788 was distributed to all positive terms as weights; the
spe increased the weight of terms to 250.570. The percentage of increase is
19.07% = 250.570−202.788
. However, the amount of increase diﬀers for each term.

250.570

6 Conclusions

It has been proven that pattern-based approaches are useful for improving the
quality of feature selection from text documents, although they suﬀer from low
frequency. To solve that problem, deploying methods have been proposed to
deploy high-level patterns into low-level terms. However, these deploying meth-
ods cause many low-level terms to have the same weight regardless of a terms

542

A. Algarni and Y. Li

speciﬁcity. The proposed SFD approach utilizes term distribution in high-level
patterns (topics) and terms document frequency to calculate terms speciﬁcity
according to their appearances and distribution in topics. The experimental re-
sults on RCV1 demonstrate that the proposed method has performed excitingly,
with an average 8.98% improvement over the state-of-the-art benchmarks.

Acknowledgments. This paper was partially supported by Grant DP0988007
from the Australian Research Council (ARC Discovery Project).

References

1. Aas, K., Eikvil, L.: Text categorisation: A survey. Technical report, Norwegian

Computing Center (June 1999)

2. Ahonen, H., Heinonen, O., Klemettinen, M., Verkamo, A.I.: Applying data mining
techniques for descriptive phrase extraction in digital document collections. In:
Proceedings of the IEEE Forum on Research and Technology Advances in Digital
Libraries (ADL 1998), pp. 2–11 (1998)

3. Buckley, C., Voorhees, E.M.: Evaluating evaluation measure stability. In: Proceed-
ings of the 23rd Annual International ACM SIGIR Conference on Research and
Development in Information Retrieval, pp. 33–40 (2000)

4. Cao, G., Nie, J.-Y., Gao, J., Robertson, S.: Selecting good expansion terms for
pseudo-relevance feedback. In: Proceedings of the 31st Annual International ACM
SIGIR Conference on Research and Development in Information Retrieval, pp.
243–250 (2008)

5. Dumais, S.T.: Improving the retrieval of information from external sources. Be-

havior Research Methods, Instruments, & Computers 23(2), 229–236 (1991)

6. Jindal, N., Liu, B.: Identifying comparative sentences in text documents. In: Pro-

ceedings of SIGIR 2006, pp. 244–251 (2006)

7. Joachims, T.: A probabilistic analysis of the rocchio algorithm with tﬁdf for text
categorization. In: Proceedings of the Fourteenth International Conference on Ma-
chine Learning, pp. 143–151. Morgan Kaufmann Publishers Inc. (1997)

8. Lewis, D.D.: An evaluation of phrasal and clustered representations on a text

categorization task. In: Proceedings of SIGIR 1992, pp. 37–50 (1992)

9. Li, X., Liu, B.: Learning to classify texts using positive and unlabelled data. In:

Proceedings of IJCAI 2003, pp. 587–594 (2003)

10. Li, Y., Algarni, A., Zhong, N.: Mining positive and negative patterns for relevance
feature discovery. Proceedings of the 16th ACM SIGKDD International Conference
on Knowledge Discovery and Data Mining, pp. 753–762 (2010)

11. Li, Y., Zhong, N.: Mining ontology for automatically acquiring web user informa-
tion needs. IEEE Transactions on Knowledge and Data Engineering 18(4), 554–568
(2006)

12. Li, Y., Zhou, X., Bruza, P., Xu, Y., Lau, R.Y.: A two-stage text mining model for
information ﬁltering. In: Proceeding of the 17th ACM Conference on Information
and Knowledge Management, pp. 1023–1032 (2008)

13. Ling, X., Mei, Q., Zhai, C., Schatz, B.: Mining multi-faceted overviews of arbitrary
topics in a text collection. In: Proceeding of the 14th ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining, pp. 497–505 (2008)

Mining Speciﬁc Features for Acquiring User Information Needs

543

14. Metzler, D., Croft, W.B.: Latent concept expansion using markov random ﬁelds. In:
Proceedings of the 30th Annual International ACM SIGIR Conference on Research
and Development in Information Retrieval, pp. 311–318 (2007)

15. Pon, R.K., Cardenas, A.F., Buttler, D., Critchlow, T.: Tracking multiple topics for
ﬁnding interesting articles. In: Proceedings of the 13th ACM SIGKDD Interna-
tional Conference on Knowledge Discovery and Data Mining, pp. 560–569 (2007)
16. Robertson, S.E., Soboroﬀ, I.: The trec 2002 ﬁltering track report. In: Proceedings

of TREC (2002)

17. Salton, G.: The SMART Retrieval System-Experiments in Automatic Document

Processing. Prentice-Hall, Inc., Upper Saddle River (1971)

18. Scott, S., Matwin, S.: Feature engineering for text classiﬁcation. In: The 16th In-

ternational Conference on Machine Learning, pp. 379–388 (1999)

19. Sebastiani, F.: Machine learning in automated text categorization. ACM Comput.

Surv. 34(1), 1–47 (2002)

20. Shen, D., Sun, J.-T., Yang, Q., Zhao, H., Chen, Z.: Text classiﬁcation improved
through automatically extracted sequences. In: Proceedings of the 22nd Inter-
national Conference on Data Engineering, pp. 121–123. IEEE Computer Society
(2006)

21. Soboroﬀ, I., Robertson, S.: Building a ﬁltering test collection for trec 2002. In:

Proceedings of SIGIR 2003, pp. 243–250 (2003)

22. Wang, X., Fang, H., Zhai, C.: A study of methods for negative relevance feed-
back. In: Proceedings of the 31st Annual International ACM SIGIR Conference on
Research and Development in Information Retrieval, pp. 219–226 (2008)

23. Wu, S.-T., Li, Y., Xu, Y.: Deploying approaches for pattern reﬁnement in text

mining. In: Proceedings of ICDM 2006, pp. 1157–1161 (2006)

24. Wu, S.-T., Li, Y., Xu, Y., Pham, B., Chen, P.: Automatic pattern-taxonomy ex-

traction for web mining. In: Proceedings of WI 2004, pp. 242–248 (2004)

25. Xu, Y., Li, Y.: Generating concise association rules. In: Proceedings of CIKM 2007,

pp. 781–790 (2007)

26. Xu, Z., Akella, R.: Active relevance feedback for diﬃcult queries. In: Proceeding
of the 17th ACM Conference on Information and Knowledge Management, pp.
459–468 (2008)

27. Yan, X., Cheng, H., Han, J., Xin, D.: Summarizing itemset patterns: a proﬁle-based
approach. In: Proceedings of the Eleventh ACM SIGKDD International Conference
on Knowledge Discovery in Data Mining, pp. 314–323 (2005)

28. Yang, Y., Liu, X.: A re-examination of text categorization methods. In: Proceed-
ings of the 22nd Annual International ACM SIGIR Conference on Research and
Development in Information Retrieval, pp. 42–49 (1999)


