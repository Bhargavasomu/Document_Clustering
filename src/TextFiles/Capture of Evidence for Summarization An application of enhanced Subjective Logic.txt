Capture of Evidence for Summarization: An

Application of Enhanced Subjective Logic

Sukanya Manna, B. Sumudu U. Mendis, and Tom Gedeon

School of Computer Science, The Australian National University, Canberra,

{sukanya.manna,sumudu.mendis,tom.gedeon}@anu.edu.au

ACT 0200, Australia

Abstract. In this paper, we present a method to generate an extractive
summary from a single document using subjective logic. The idea behind
our approach is to consider words and their co-occurrences between sen-
tences in a document as evidence of their relatedness to the contextual
meaning of the document. Our aim is to formulate a measure to ﬁnd
out ‘opinion’ about a proposition (which is a sentence in this case) using
subjective logic in a closed environment (as in a document). Stronger
opinion about a sentence represents its importance and are hence con-
sidered to summarize a document. Summaries generated by our method
when evaluated with human generated summaries, show that they are
more similar than baseline summaries.

Keywords: subjective logic, opinions, evidence, events, summarization,
information extraction.

1 Introduction

It is sometime necessary to analyse a single document for intelligent decision
making purpose in the absence of prior domain knowledge. In such a scenario,
signiﬁcant sentences from a document or rather gist of that document can only
let an user know about what it is all about. Based on this ﬁltered information,
the user can decide what kind of measures to be taken to perform the analysis;
thus, single-document summarization is one of the best ways to do this.

One way to do text summarization is by text extraction, which means to
extract pieces of original text on statistical basis or heuristic methods and put
them together to a new shorter text with as much information as possible pre-
served [9]. The concept of extracting signiﬁcant sentences from a document for
generating extractive summaries has drawn attention in the literature.

In this paper, our approach is not mere assigning scores to a sentence. When
a document is looked from the perspective of human, they analyse it by ﬁnding
what the main idea of the source text is and ﬁltering what is essential in the
information conveyed by the text. In [10], the authors have pointed out that a
given piece of text is interpreted by diﬀerent person in a diﬀerent fashion espe-
cially in the way how they understand and interpret the context. Thus we see

M.J. Zaki et al. (Eds.): PAKDD 2010, Part II, LNAI 6119, pp. 291–298, 2010.
c(cid:2) Springer-Verlag Berlin Heidelberg 2010

292

S. Manna, B.S.U. Mendis, and T. Gedeon

that human understanding and reasoning is subjective in nature unlike proposi-
tional logic which deals with either truth or falsity of a statement. So, to deal
with this kind of situation we used subjective logic to ﬁnd out sentences which
are signiﬁcant in the context and can be used to summarize a document.

2 Modeling ‘Opinions’ about a Sentence in a Document

Using Subjective Logic

In this section, we present how we formulate ‘opinion’ about a sentence using
subjective logic. Subjective logic [3] is a logic which operates on subjective beliefs
about the world, and use the term opinion to denote the representation of a sub-
jective belief. An opinion can be interpreted as a probability measure containing
secondary uncertainty, and as such subjective logic can be seen as an extension of
both probability calculus and binary logic. It is a type of probabilistic logic that
explicitly takes uncertainty and belief into account. It is suitable for modeling
and analysing situations involving uncertainty and incomplete knowledge [3], [4].

2.1 Interpretation of Evidence in a Document

How can we deﬁne evidence in a document? This is what we are building here
automatically. We consider words, phrases or co-occurrence of words, or a sen-
tence itself to be evidence present in a document. Now, based on this, our basic
motivation is to formulate ‘opinion’ about a proposition, which is a sentence
in this case. Stronger the opinions about a sentence, more is its signiﬁcance in
the document. These opinions are measured by probability expectation of a sen-
tence. Greater the probability expectation, more signiﬁcant is the sentence. If
probability expectation of two sentences are similar, then we need to look at the
sentence with lower uncertainty to fetch the important one [4] between two.

Assumptions: We propose the following framework for the practical application
of subjective logic in a document computing context.
1. All the words or terms (removing the stop words) in a document are atomic.
2. The sentences are unique, i.e., each of them occur only once in a given
document.

Representation of a document: A document consists of sentences. In this paper,
a sentence is considered to be a set of words. In a document, sentences are sep-
arated by stop marks (“.”, “!”, “?”). Terms (stop words excluded) are extracted
and the frequencies (i.e. number of occurrences) of the words in each sentence
are calculated.

Let us now deﬁne the notations which we will be using in the rest of the equa-
tions and explanations. Θ is the frame of discernment. We represent a document
as a collection of words, which is

Θ = Dw = {w1, w2, ..., wn}

(1)

Capture of Evidence for Summarization

293

where, Dw is a document consisting of words like w1, w2...wn and |Dw| = n.
Now,

ρ(Θ) = {{w1},{w2}, ...,{w1, w2, w3, ..., wn}} ≡ 2Θ

(2)

|ρ(Θ)| = 2n

(3)

Since a document is a collection of sentences, it can be represented as

Ds = {s1, s2, ..., sm}

(4)
where m is a ﬁnite integer and each si is an element of ρ(Θ). Each sentence is
comprised of words, which belong to the whole word collection of the document
Dw. We thus represent each sentence by,

where, 1 ≤ i, k, r ≤ n and Sl ∈ ρ(Θ).

Sl = {wiwk...wr} ∈ Θ

(5)

2.2 Deﬁnitions of ‘Subjective Logic’ and Our Conceptualization
In ﬁg.1, we present a model of a document with four sentences (s1, s2, s3, and s4)
and ﬁve words (w1, w2, w3, w4, and w5) respectively. Let frequency of occurrence
of each word in each sentence be one for simplicity. The words and sentences
(atomic and non atomic states) represent evidence. Now, we use the original
deﬁnitions from [4], and explain our formulation.

S1

S2

W3 

S3

W1 

W2 

W4 

S4

W5 

Fig. 1. Example of a document

The ﬁrst step in applying evidential reasoning is to deﬁne a set of possible
situations which is called the frame of discernment, Θ. A frame of discernment
delimits a set of possible states of the world, exactly one of which is assumed
to be true at any one time. In the given example, total number of all possible
states are 25 for 5 words given.
Deﬁnition 1 (Belief Mass Assignment). Let Θ be a frame of discernment.
If with each substate x ∈ 2Θ a number mΘ(x) is associated such that:
1. mΘ(x) ≥ 0
2. mΘ(∅) = 0
3.
then mΘ is called a belief mass assignment in Θ, or BMA for short. For each
substate x ∈ 2Θ, the number mΘ(x) is called the belief mass of x.

x∈2Θ mΘ(x) = 1

(cid:2)

294

S. Manna, B.S.U. Mendis, and T. Gedeon

We calculate BMA for each event by,

m(x) =

F (x)

Z

,

(6)

(cid:2)N

k=1

fxk

where F (x) =
, where N is the total number of sentences in the docu-
ment, x ∈ 2Θ, and fxk is the frequency of occurrence of event x in sentence k. In
words, it is the total frequency of that event in all the sentences (or the whole
document).

Z =

F (x),

x ∈ 2Θ

(cid:3)

∀x(cid:5)=∅
fx(cid:5)=0

(7)

Z is the total frequency of the all the events which has valid evidence of truth
(whose frequency is non zero). In the given example, we have 7 valid states and
their corresponding frequencies in the document are: {F (w1) = 1, F (w2) =
2, F (w3) = 1, F (w4) = 2, F (w5) = 1, F (w1, w2) = 1, F (w2, w3, w4) = 1}.
Therefore, Z = 9 in this case. Using (6), we calculate BMA for each of the states
(or events) in the given example.
Deﬁnition 2 (Belief Function). Let Θ be a frame of discernment, and let mΘ
be a BMA on Θ. Then the belief function corresponding with mΘ is the function
b : 2Θ → [0, 1] deﬁned by:

b(x) =

mΘ(y),

x, y ∈ 2Θ

(8)

(cid:3)

y⊆x

We calculate the belief of a sentence of the example as, b(s1) = m(w1)+ m(w2)+
m(w1, w2).
Deﬁnition 3 (Disbelief Function). Let Θ be a frame of discernment, and let
mΘ be a BMA on Θ. Then the disbelief function corresponding with mΘ is the
function d : 2Θ → [0, 1] deﬁned by:
(cid:3)

d(x) =

mΘ(y),

y∩x=∅

x, y ∈ 2Θ.

(9)

We calculate disbelief of s1 by d(s1) = m(w3) + m(w4) + m(w5).
Deﬁnition 4 (Uncertainty Function). Let Θ be a frame of discernment, and
let mΘ be a BMA on Θ. Then the uncertainty function corresponding with mΘ
is the function u : 2Θ [0, 1] deﬁned by:

u(x) =

mΘ(y),

x, y ∈ 2Θ.

(10)

(cid:3)

y∩x(cid:5)=∅
y(cid:2)x

From Josang’s idea, we can get the Belief Function Additivity which is ex-
pressed as:

b(x) + d(x) + u(x) = 1,

(11)
Now, one can simply calculate the uncertainty of a sentence by using (11), i.e.,
u(s1) = 1 − (b(s1) + d(s1)).

x ∈ 2Θ, x (cid:8)= ∅.

Capture of Evidence for Summarization

295

x, y ∈ 2Θ, y (cid:8)= ∅.

,

a(x/y) =

Deﬁnition 5 (Relative Atomicity). Let Θ be a frame of discernment and
let x, y ∈ 2Θ. Then for any given y (cid:8)= ∅ the relative atomicity of x to y is the
function a : 2Θ → [0, 1] deﬁned by:
|x ∩ y|
|y|

(12)
It can be observed that x∩y = ∅ ⇒ a(x/y) = 0 and that y ⊆ x ⇒ a(x/y) = 1.
In all other cases relative atomicity will be a value between 0 and 1. The relative
atomicity of an atomic state to its frame of discernment, denoted by a(x/Θ), can
simply be written as a(x). If nothing else is speciﬁed, the relative atomicity of a
state then refers to the frame of discernment. In this case, we get the following
relative atomicity for sentence s1 as:
a(s1/w1) =
1 = 1
a(s1/w2) =
1 = 1
a(s1/{w1, w2}) = a(s1, s1) =
|s1∩w5|
a(s1/w5) = a(s1/s4) =
|w5| = 0
Likewise, we calculate the atomicity for other sentences.
Deﬁnition 6 (Probability Expectation). Let Θ be a frame of discernment
with BMA mΘ then the probability expectation function corresponding with mΘ
is the function E : 2Θ → [0, 1] deﬁned by:

|s1∩w1|
|w1| = 1
|s1∩w2|
|w2| = 1

|s1∩{w1,w2}|
|{w1,w2}| = 2

2 = 1...

1 = 0

(cid:3)

E(x) =

mΘ(y)a(x/y),

y ∈ 2Θ.

(13)

y

So, for the given example, we calculate P robExp for sentence s1 as follows:
E(s1) = m(w1)a(s1/w1) + m(w2)a(s1/w2) + m({w1, w2})a(s1/{w1, w2}) + ... +
m(w5)a(s1/w5) For compactness and simplicity of notation we will in the follow-
ing denote belief, disbelief, uncertainty, relative atomicity and opinion functions
as bx, dx, ux, ax and ωx respectively. Thus opinion (ωs1 or ω(s1))about a sentence
s1 can be expressed using these four parameters as, ω(s1) = (b(s1), d(s1), u(s1),
a(x)).

In this context, we order sentences based on descending order of their probabil-
ity expectation and ascending order of their uncertainty; sentence with stronger
‘opinion’ has greater signiﬁcance in a document.

3 Method

3.1 Data Processing
In this experiment we used DUC2001 data set [1] for evaluation. The documents
are grouped based on a speciﬁc topic. Our main aim is to see how our model
works on single documents for content analysis purposes, so we focussed on this
kind of data set unlike other information retrieval areas. These documents were
parsed, tokenized, cleaned, and stemmed. The cleaning is done by removing
the stop words. DUC2001 comes with human generated summaries and baseline
summaries, providing a good platform for evaluation.

296

S. Manna, B.S.U. Mendis, and T. Gedeon

3.2 Generation of Summaries

Summaries are broadly classiﬁed into text extraction and text abstraction [7], [5].
For text extraction, sentences from the documents are used as summaries and for
text abstraction important pieces of information are extracted and then stitched
together to form summaries following some linguistic rules. This evidence based
model can be used as a text extraction as we use the original sentences. We
compared our method and DUC baseline summaries with the human generated
summaries provided by them.

Evidence based model (PEU): In sec.2, we described our method of sentence
ranking; subjective logic based where we ranked the sentences based on the
descending order probability expectation and ascending order of uncertainty
(PEU) of that sentence in the document. We took 30% [2] of the top ranked
sentences and used them as summary.

3.3 Evaluation by ROUGE

ROUGE [6] stands for Recall-Oriented Understudy for Gisting Evaluation. It
includes measures to automatically determine the quality of a summary by com-
paring it to other (ideal) summaries created by humans. ROUGE is a recall
based metric for ﬁxed length summaries. The measures count the number of
over lapping units such as n-gram, word sequences, and word pairs between the
computer-generated summary to be evaluated and the ideal summaries created
by humans.

In this experiment, we present the result with ROUGE-1 (n-gram, where n=1)
at 95% conﬁdence level. ROUGE is sensitive to the length of the summaries [8];
hence we ﬁxed the length to 100 words for the evaluation.

4 Results

We used DUC2001 dataset for this experiment. Among diﬀerent document sets,
we presented here the evaluation with ‘daycare’, ‘healthcare’ and ‘pres92’. We
compared our method (PEU) and baseline summaries (denoted by LP) with two
diﬀerent human assessors. For each set the assessors are diﬀerent. The average
(table.1) results show that our method out performs the baseline summaries.

Figures 2(a) and 2(b) show the evaluation comparison using daycare data,
where Acc d and Acc i are two human assessors. In both the ﬁgures 2(a) and
2(b), our method outperforms the baseline summaries (90% of documents with
Acc d and 80% of documents with Acc i).

Now, ﬁgures 3(a) and 3(b) present the results with healthcare data set. Here
Acc b and Acc j are the two human assessors. There was no baseline summary
for the 7th document in this series. So, in both the ﬁgures we have value as 0
in the comparison results. In ﬁg.3(a), ROUGE score for PEU with Acc b is higher

Capture of Evidence for Summarization

297

LP-Acc_d

PEU-Acc_d

LP-Acc_i

PEU-Acc_i

l
l

 

a
c
e
R
1
-
E
G
U
O
R

1
0.8
0.6
0.4
0.2
0

l
l

 

a
c
e
R
1
-
E
G
U
O
R

1
0.8
0.6
0.4
0.2
0

2
1
1
0
-
2
0
4
0
0
9
J
S
W

8
2
0
0
-
8
1
6
0
0
9
J
S
W

2
9
0
0
-
6
0
7
0
0
9
J
S
W

5
8
0
0
-
5
1
8
0
0
9
J
S
W

9
5
0
0
-
5
0
2
0
1
9
J
S
W

1
0
0
0
-
5
0
9
0
1
9
J
S
W

9
8
0
0
-
6
2
9
0
1
9
J
S
W

5
4
1
0
-
7
1
0
1
1
9
J
S
W

8
5
1
0
-
3
2
0
1
1
9
J
S
W

3
0
0
0
-
6
0
1
0
2
9
J
S
W

2
1
1
0
-
2
0
4
0
0
9
J
S
W

8
2
0
0
-
8
1
6
0
0
9
J
S
W

2
9
0
0
-
6
0
7
0
0
9
J
S
W

5
8
0
0
-
5
1
8
0
0
9
J
S
W

9
5
0
0
-
5
0
2
0
1
9
J
S
W

1
0
0
0
-
5
0
9
0
1
9
J
S
W

9
8
0
0
-
6
2
9
0
1
9
J
S
W

5
4
1
0
-
7
1
0
1
1
9
J
S
W

8
5
1
0
-
3
2
0
1
1
9
J
S
W

3
0
0
0
-
6
0
1
0
2
9
J
S
W

Documents

Documents

(a) Comparison with Assessor d

(b) Comparison with Assessor i

Fig. 2. Daycare dataset

LP-Acc_b

PEU-Acc_b

LP-Acc_j

PEU-Acc_j

l
l

 

a
c
e
R
1
-
E
G
U
O
R

1
0.8
0.6
0.4
0.2
0

l
l

 

a
c
e
R
1
-
E
G
U
O
R

1
0.8
0.6
0.4
0.2
0

7
2
1
0
-
8
2
5
0
1
9
J
S
W

1
6
0
0
-
6
0
6
0
1
9
J
S
W

1
6
1
0
-
0
2
6
0
1
9
J
S
W

7
5
1
0
-
4
2
6
0
1
9
J
S
W

9
8
0
0
-
8
2
6
0
1
9
J
S
W

6
1
1
0
-
4
2
9
0
1
9
J
S
W

9
7
0
0
-
1
1
2
1
1
9
J
S
W

5
5
1
0
-
8
0
1
0
2
9
J
S
W

6
4
0
0
-
5
1
1
0
2
9
J
S
W

2
1
1
0
-
0
1
2
0
2
9
J
S
W

7
2
1
0
-
8
2
5
0
1
9
J
S
W

1
6
0
0
-
6
0
6
0
1
9
J
S
W

1
6
1
0
-
0
2
6
0
1
9
J
S
W

7
5
1
0
-
4
2
6
0
1
9
J
S
W

9
8
0
0
-
8
2
6
0
1
9
J
S
W

6
1
1
0
-
4
2
9
0
1
9
J
S
W

9
7
0
0
-
1
1
2
1
1
9
J
S
W

5
5
1
0
-
8
0
1
0
2
9
J
S
W

6
4
0
0
-
5
1
1
0
2
9
J
S
W

2
1
1
0
-
0
1
2
0
2
9
J
S
W

Documents

Documents

(a) Comparison with Assessor b

(b) Comparison with Assessor j

Fig. 3. Healthcare dataset

LP-Acc_c

PEU-Acc_c

LP-Acc_f

PEU_Acc_f

l
l

 

a
c
e
R
1
-
E
G
U
O
R

1
0.8
0.6
0.4
0.2
0

1

0.8

0.6

0.4

0.2

0

6
5
0
0
-
8
0
7
0
1
9
J
S
W

5
9
0
0
-
2
2
8
0
1
9
J
S
W

0
4
1
0
-
8
1
0
1
1
9
J
S
W

6
2
1
0
-
3
2
0
1
1
9
J
S
W

6
0
1
0
-
6
2
1
1
1
9
J
S
W

3
0
0
0
-
2
1
2
1
1
9
J
S
W

6
0
0
0
-
6
1
2
1
1
9
J
S
W

0
5
1
0
-
6
0
1
0
2
9
J
S
W

1
0
0
0
-
7
0
1
0
2
9
J
S
W

6
0
0
0
-
1
2
1
0
2
9
J
S
W

Documents

6
5
0
0
-
8
0
7
0
1
9
J
S
W

5
9
0
0
-
2
2
8
0
1
9
J
S
W

0
4
1
0
-
8
1
0
1
1
9
J
S
W

6
2
1
0
-
3
2
0
1
1
9
J
S
W

6
0
1
0
-
6
2
1
1
1
9
J
S
W

3
0
0
0
-
2
1
2
1
1
9
J
S
W

6
0
0
0
-
6
1
2
1
1
9
J
S
W

0
5
1
0
-
6
0
1
0
2
9
J
S
W

1
0
0
0
-
7
0
1
0
2
9
J
S
W

6
0
0
0
-
1
2
1
0
2
9
J
S
W

(a) Comparison with Assessor c

(b) Comparison with Assessor f

Fig. 4. Pres92 dataset

than baseline on average except for 30% of the documents. In ﬁg.3(b), baseline
shows higher similarity with Acc j than PEU in 60% documents.

In ﬁgures 4(a) and 4(b), PEU outperforms the baseline summaries (90% of
documents with each assessors). In table.1, Acc1 and Acc2 are alias of human
assessors used in each case. Except for Acc2 in healthcare data, PEU has out-
performed all the baseline summaries.

From these results, we can see that summaries produced by humans are ab-
stract. So overlap with human generated of summaries with automated ones
can vary a lot unless they are compared with extractive summaries created by
humans selecting the original sentences from documents.

298

S. Manna, B.S.U. Mendis, and T. Gedeon

Table 1. Summary of all three sets of results (ROUGE-1 Recall)

LP-Acc1 LP-Acc2 PEU-Acc1 PEU-Acc2

daycare

healthcare

pres92

Avg

0.19

0.27

0.20

0.22

0.26

0.35

0.19

0.27

0.24

0.29

0.24

0.25

0.32

0.29

0.28

0.29

5 Conclusion

In this paper we presented an evidence based sentence extraction method for
single document summarization. We used enhanced subjective logic to formu-
late the whole process. Here standard methods for evaluating data are used; in
the whole process we ﬁgured out that summarization is subjective to the user.
In our system we basically used word frequency and co-occurrence concept for
formulating subjective logic; rather superﬁcial knowledge. But the results are
good in the sense that they have outperformed baseline summaries as illustrated
in the results. For our future work we will extend this method to perform deeper
semantic analysis of the text and redeﬁne some features of subjective logic in
document computing context.

References

1. DUC (2001), The document understanding conference, http://duc.nist.gov/
2. Dalianis, H.: SweSum-A Text Summarizer for Swedish (2000),

http://www.dsv.su.se/%7Ehercules/papers.Textsumsummary.html

3. Jøsang, A.: Artiﬁcial reasoning with subjective logic. In: Proceedings of the Second

Australian Workshop on Commonsense Reasoning, vol. 48 (1997) Perth:[sn]

4. Jøsang, A.: A logic for uncertain probabilities. International Journal of Uncertainty,

Fuzziness and Knowledge-Based Systems 9(3), 279–311 (2001)

5. Liddy, E.D.: The discourse-level structure of empirical abstracts: an exploratory

study. Inf. Process. Manage. 27(1), 55–81 (1991)

6. Lin, C.-Y.: Rouge: A package for automatic evaluation of summaries, Barcelona,

Spain, July 2004, pp. 74–81. Association for Computational Linguistics (2004)

7. Lin, C.Y., Hovy, E.: Identifying topics by position. In: Proceedings of the ﬁfth con-
ference on Applied natural language processing, pp. 283–290. Morgan Kaufmann
Publishers Inc., San Francisco (1997)

8. Lin, C.Y., Hovy, E.: Automatic evaluation of summaries using n-gram co-
occurrence statistics. In: Proceedings of the 2003 Conference of the North Ameri-
can Chapter of the Association for Computational Linguistics on Human Language
Technology, vol. 1, p. 78. Association for Computational Linguistics (2003)

9. Mani, I., Maybury, M.T.: Advances in automatic text summarization. MIT Press,

Cambridge (1999)

10. Pardo, T.A.S., Rino, L.H.M., Nunes, M.G.V.: Extractive summarization: how to
identify the gist of a text. In: The Proceedings of the 1st International Information
Technology Symposium–I2TS, Citeseer, pp. 1–6 (2002)


