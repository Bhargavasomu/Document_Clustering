Leveraging Hybrid Citation Context   

for Impact Summarization 

Po Hu1,2, Yujing Guo1, Donghong Ji1,*, and Jiacong He3 

1 Computer School, Wuhan University, China 

2 Computer School, Central China Normal University, China 
3 International School of Software, Wuhan University, China 

phu@mail.ccnu.edu.cn, 

{yujingguo.ximo,hejiacongtheone}@gmail.com, 

donghong_ji2000@yahoo.com.cn 

Abstract.  Impact  summarization  aims  to  highlight  the  influential  aspects  of  a 
cited  paper  by  selecting  a  few  representative  citation  sentences  into  the 
summary. Most existing work considers only the citation sentence information 
while the hybrid citation context associated with each citation sentence has been 
ignored.  This  paper  proposes  a  context-aware  approach.  In  the  approach, 
different  kinds  of  relationships  among  papers  and  authors  are  leveraged  to 
jointly infer the impact of hybrid citation context, which is further integrated in 
a sentence language smoothing model to measure citation sentence relationships 
more effectively. The experimental results show that the proposed approach can 
achieve significantly better results than several baselines. 

Keywords:  impact  summarization,  hybrid  citation  context,  bibliographic 
network relationships. 

1 

Introduction 

With  the  rapid  evolution  of  scientific  research,  the  volume  of  literature  keeps  on 
expanding  fast.  However,  the  explosive  growth  of  the  publications  makes  it  rather 
difficult to identify the influential aspects of papers quickly and effectively. 

The  abstract  part  of  a  scientific  paper  may  help  researchers  quickly  understand   
the  main  content  of  the  paper,  but  it  only  presents  what  the  authors  think  to  be  the 
important contribution but not necessarily the actual impact of the paper. Actually, the 
impact of a paper should be judged by the consent of research community instead of 
the author himself. Moreover, the impact of a paper may dynamically change due to 
the progress of research. For example, a paper published before may be no longer the 
state of the art, but the research problem it addressed or the method it proposed will 
still attract peer attention. 

Therefore,  we  argue  that  only  the  abstract  part  representing  the  author’s  point  of 
view is not enough, and how other papers cite and describe the target paper needs to 
                                                           
*  Corresponding author. 

J. Pei et al. (Eds.): PAKDD 2013, Part I, LNAI 7818, pp. 354–365, 2013. 
© Springer-Verlag Berlin Heidelberg 2013 

 

Leveraging Hybrid Citation Context for Impact Summarization 

355 

be comprehensively investigated to generate an impact summary, which can not only 
help researchers digest the results of research better, but also facilitate other literature 
mining applications such as research trend prediction, and survey generation, etc. 

Actually, given a scientific paper, different citation sentences often focus on different 
aspects of that paper and all the citation sentences will provide a rich information source 
to summarize its impact [1]. Although some research has been done based on citation 
sentences, to the best of our knowledge, simultaneous consideration of the impact from 
hybrid citation context associated with each citation sentence has not been investigated. 
Therefore, we propose a novel approach by incorporating the impact of hybrid citation 
context  into  the  summarization  process.  In  the  proposed  approach,  three  kinds  of 
relationships among papers and authors are first leveraged to jointly infer the impact of 
hybrid citation context. Next, the hybrid citation context and its impact are integrated in 
a sentence language smoothing model to measure citation sentence relationships more 
effectively.  Lastly,  a  unified  graph  ranking  algorithm  is  adopted  to  evaluate  the 
significance of each citation sentence by taking advantage of the relationships between 
citation sentences. 

The remainder of this paper is organized as follows. Section 2 reviews related work. 
The  proposed  approach  is  presented  in  Section  3.  We  then  report  the  experimental 
results in Section 4. Finally, we present our conclusion and future work in Section 5. 

2 

Related Work 

Automatic creation of scientific summaries has been studied for many years [2-4], but 
most  previous  work  considers  only  the  local  features  of  the  scientific  paper,  while 
other contextual information has been mostly ignored. 

Recently,  researchers  have  begun  to  make  use  of  contextual  information  to  aid 
news and  webpage summarization [5-10]. Likewise, in order to summarize a paper, 
differentiating and utilizing citations from context have received increasing interests. 
Nakov et al.  used sentences surrounding citations to create training and testing data 
for  scientific  paper  summarization  [11].  Nanba  and  Okumura  classified  different 
citation  sentences into three categories and explored how to use them to aid  survey 
generation [12]. Schwartz and Hearst utilized the citation sentences to summarize the 
key  concepts  and  entities  in  bioscience  texts  [13].  Teufel  et  al.  adopted  rhetorical 
status  analysis  to  reveal  the  scientific  attribution  of  a  paper,  in  which  each  citation 
sentence  is  labeled  as  one  of  Own,  Other,  Background,  Textual,  Aim,  Basis,  and 
Contrast [14]. Kan et al. used annotated bibliographies to cover certain summarization 
aspects [15]. Elkiss et al. performed a large-scale study on the PubMed repository and 
confirmed  the  importance  of  citation  sentences  in  understanding  what  a  paper 
contributes [16]. They also concluded that the citation sentences contain more focused 
information that generally does not appear in the abstract part of a paper. 

Recently,  Mei  and  Zhai  proposed  a  language  model  based  approach  to  impact 
summarization [17]. Qazvinian and Radev presented two different methods for the task 
[18]  [19].  One  utilized  all  the  citation  sentences  of  a  paper  to  construct  a  similarity 
graph  first,  and  then  applied  network  analysis  technique  to  cluster  graph  nodes  and 

356 

P. Hu et al. 

produce an impact summary. Another method first extracted a number of key phrases 
from the citation sentences, and then used these phrases to build the impact summary. 
How to produce more readable summaries based on citation sentences have also been 
investigated in [20] 

As far as we know, none of the previous studies has investigated the impact from 
hybrid  citation  context  (i.e.,  the  combination  of  citation  paper  context  and  citation 
author context), and has used the citation context in the same way as we did. In this 
study,  we  propose  a  context-aware  approach  to  simultaneously  consider  the  impact 
from  hybrid  citation  context  and  what  is  more,  we  further  incorporate  the  hybrid 
citation context and its impact into a sentence language smoothing model to measure 
the citation sentence relationships beyond sentence level. 

3 

Impact Summarization Based on Hybrid Citation Context 

Our  approach  incorporates  hybrid  citation  context  into  the  impact  summarization, 
which  consists  of  three  steps:  inferring  the  impact  of  hybrid  citation  context, 
estimation of citation sentence language model, and impact summary generation. 

3.1 

Inferring the Impact of Hybrid Citation Context 

In  the  study,  the  sentence  containing  an  explicit  reference  to  the  target  paper  and 
describing the work being cited is called a citation sentence. All the other citing papers 
and  citing  authors  associated  with  the  citation  sentences  are  called  hybrid  citation 
context. The citation sentences occurring in the papers with higher topical relevance will 
contribute more than those in less important papers. The citation sentences written by the 
authors  with  better  authority  expertise  will  contribute  more  than  those  written  by  less 
professional authors. Therefore, to summarize the impact of a particular paper, the impact 
of  hybrid  citation  context  (i.e.,  the  topical  relevance of  citing  papers  and  the  authority 
expertise of citing authors) should be inferred first. 

Our  approach  operates  over  a  bibliographic  network  G.  G=(V,  E)=(VP∪VA, 
EP∪EA∪EPA). G connects three subgraphs GP, GA, and GPA. GP=(VP, EP) is a directed 
graph representing the citation relationships between papers. VP={pi | pi∈VP} denotes 
authors. VA={ai | ai∈VA} is the set of authors with size |VA|, and EA is the set of co-
authorship links between them. GPA=(VP∪VA, EPA) is a bipartite graph that ties GP and 

a collection of |VP| papers and EP is the set of citation links between them. GA=(VA, 
EA)  is  an  undirected  graph  representing  the  co-authorship  relationships  between 

GA and represents authorship associations between papers and authors.   

Let  RP(pi)  and  RA(ai)  denote  the  topical  relevance  of  paper  pi  and  the  authority 
expertise of author ai respectively. A query q can be constructed by extracting the title 
can  be 
and  keywords  from  the  target  paper,  and  then  the  initial  scores
p t θ is  the  maximum 
calculated  by
( |

.  Where 

= ∏

( | 
p t

(
p q

θ

θ

n t q

( ,

R

R

p

i

0

P

(

)

=

)

(

|

)

0

P

p

i

)

p
i

∈
t q

)

p
i

)

ip

likelihood estimation of the term t in the paper pi, and n(t, q) is the number of times 
that term t occurs in query q. Since an author ai can be represented by the set of papers 
authored by ai, the initial score 

for author ai can be calculated similarly.   

R

)

(

a

0

A

i

 

Leveraging Hybrid Citation Context for Impact Summarization 

357 

Inspired by [22] and based on the assumption that similar papers will have similar 
relevance  for  a  given  query,  we  refine  the  topical  relevance  of  citing  papers  by 
making use of the paper citation graph GP and the initial topical relevance of papers.   
  for  the  graph  GP  is  constructed.  If  a 
paper  pi  cites  another  paper  pj  (i≠j),  then  we  set  the  corresponding  element 
ijpw   in 
WP  as  1,  otherwise  set  it  as  0.  Then  WP  is  further  normalized  as  a  random  walk 

Firstly,  the  adjacency  matrix  WP

∈ℜ

×
|V |
P

|V |
P

transition  matrix  SP  by

PS

=

1/ 2

.  Where PD is  the  diagonal 

−

1/ 2

D W D
P

P

P

−

1/ 2

−

1/ 2

D W D
P

P

P

T

−

+
2

matrix with (i,i)-element equal to the sum of the i-th row of WP. 

Next, inspired by [21], a regularization framework is developed by regularizing the 
smoothness  of  relevance  over  the  graph  and  the  cost  function  associated  with  it  is 
defined as follows: 

Ω =

P

1
2

V
P



i

,

j

=
1

s

p

ij

)
−

i

(
R p
P
d

P

ii

)

j

2

+

(
R p
P
d

P

jj

(
R p

P

)
−

i

(

p

i

)

0

R

P

2

 

(1)

1
2

V
P



=

1

i

Where the first tem defines the global consistency of the refined relevance over the 
graph,  while  the  second  term  defines  the  constraint  to  fit  the  initial  relevance.  By 
minimizing 

, the topical relevance of papers can be refined. 

P

Similarly,  based  on  the  assumption  that  if  two  authors  co-authored  many  papers 
related  to  a  given  query,  then  their  authority  expertise  in  the  queried  field  will  be 
similar, we can refine the authority expertise of citing authors by making use of the 
author co-authorship graph GA and the initial authority expertise of authors. 

|V |
A

Firstly,  the  adjacency  matrix  WA

  for  the  graph  GA  is  constructed.  If  an 
author  ai  coauthored  with  another  author  aj  (i≠j),  then  we  set  the  corresponding 
element
ijaw in WA as the number of papers that they collaborated, otherwise set it as 0. 
Then  WA  is  further  normalized  by
.  Where 
AD   is  the  diagonal 
matrix with (i,i)-element equal to the sum of the i-th row of WA. 

D W D

AS

=

1/ 2

1/ 2

−

−

A

A

A

Next, a regularization framework is developed by regularizing the smoothness of 
expertise over the graph and the cost function associated with it is defined as follows 
[21]. By minimizing A

, the authority expertise of authors can be refined. 

∈ℜ

×
|V |
A

Ω =

A

1
2

V
A



i

,

j

=

1

s

a

ij

)
−

i

(
R a
A
d

A

ii

(
R a
A
d

A

jj

)

j

2

+

1
2

V
A



=
1

i

(
R a

A

)
−

i

(

a

i

)

2

 

0

R

A

(2)

In addition to 
graph GPA by considering the authorship relations between papers and authors. 

, another cost function 

is also presented based on the 

and 

PA

P

A

Ω =

PA

1
2

V
p

V
A



=

1

i

=

1

j

)
−

i

(
R p
P
d

P

ii

(
R a
A
d

A

jj

)

j

2

+

1
2

s

pa

ij

V
p

V
A



=

1

j

=
1

i

)
−

j

(
R a
A
d

A

jj

s
ap

ji

2

)

i

 

(3)

(
R p
P
d

P

ii

Ω
Ω
Ω
Ω
Ω
358 

P. Hu et al. 

The  intuition  behind 
with that of the relevant papers he published. 

PA

  is  that  the  authority  expertise  of  an  author  is  consistent 

To define the cost function PA

  for the graph 
GPA  is  constructed.  If  a  paper  pi  is  written  by  an  author  aj,  then  we  set  the 
corresponding  element
in  WPA  as  1,  otherwise  set  it  as  0.  Then  WPA  is  further 
normalized as SPA such as the sum of each row of the matrix equal to one. 

, the adjacency matrix WPA

ijpaw

|V |
A

∈ℜ

×
|Vp|

  that combines

,

, and 

A

is developed in a 

PA

Next, a hybrid cost function  Ω
unified regularization framework. 

P

PA

 

Ω =

1
Ω + Ω + Ω
(
2

P

A

)

1
2

(4)

We can minimize the hybrid cost function  Ω
  using the standard conjugate gradient 
method,  and  a  closed-form  optimal  solution  can  be  derived.  However,  for  a  large-
scale dataset, an iterative–form computation strategy would be more effective. So in 
* by adopting the equivalent 
the study, we calculate the optimal solutions RP
iterative computation strategy, which details are omitted due to space limit, and you 
can find it in [21].   

* and RA

Finally, the converged solutions RP

* and RA

* correspond to the topical relevance of 

citing papers and the authority expertise of citing authors respectively. 

3.2  Estimation of Citation Sentence Language Model 

After inferring the impact of hybrid citation context, the next step is to make use of 
the contextual information to evaluate the relationships between citation sentences. 

From the language model perspective, it can be assumed that a citation sentence s 
θ and Dirichlet prior smoothing [23] is 

is generated from a sentence language model
often adopted to estimate s

θ as follows. 

s

(
p w

|

θ
)

s

=

(
, )
c w s

μ
+
|
|
s

s

∗
μ
+

(
p w B

|

)

 

s

(5)

Where  |s|  is  the  length  of  s,  c(w,  s)  is  the  count  of  term  w  in  s,  p(w|B)  is  usually 
μ is the 

. Here B is the whole background paper set and s

estimated by 

(
,
c w B
∈
(
c w B

)
',

w W

'

)

sentence smoothing parameter which is set as 1000 as in [17]. 

In this  study,  we propose a citation  sentence  language  smoothing  model  inspired 
p w θ by using hybrid citation context as background, which can 

|

by [6] to estimate (
be defined as follows. 

)s

(
p w

|

θ α
= ∗

)

s

(
| )
p w s

+ ∗
β

(

p

s

)

∗

R

P

(
p w p

|

)

s

γ
+ ∗

(

a
i

s

)

∗



i

R

A

(
p w a
i

|

)

 

s

(6)

Ω
Ω
Ω
Ω
Ω
 

Leveraging Hybrid Citation Context for Impact Summarization 

359 

Where α, β,  and  γ  belong  to  [0,  1]  and  α+ β+ γ=1. 
citation sentence s belongs to and 
sia is  the  i-th  citing  author  of  the  citing  paper
expertise of author

sp . 

AR

PR

(

)

sp   denotes the topical relevance of paper

sp is  the  citing  paper  that 
sp . 
denotes  the  authority 

)

(

sia

|

)

(
p w a
si
estimated 

sia . 
the 
,
)
s s
i

j

Based 

on 

Dis

distance
average KL divergence as follows. 

AvgKL

(

  is estimated by the papers authored by

sia . 

the 
  between two citation sentences si and sj can be measured by the 

language  model, 

sentence 

citation 

Dis

(

,
s s
i

j

)

AvgKL

Dis

(

s

j

||

s
i

)

KL

=

Dis

(

s
i

||

s

)

j

KL

 

+
2

Dis

(

s

j

||

s
i

)

KL

= 

∈
w W

(
p w

|

θ

s

j

)log

(
p w
(
p w

|
|

s

θ
θ

j

s

i

Dis

(

s
i

||

s

)

j

KL

= 

∈
w W

(
p w

|

θ

s

i

)log

(
p w
(
p w

|
|

θ
θ

s

i

s

j

)
)

)
)

 

 

(7) 

(8) 

(9) 

Where  W  is  the  set  of  terms  in  our  vocabulary  and  w  is  a  term  in  W.  And  the 
similarity Sim(si, sj) between two citation sentences si and sj can then be inferred by 
the following formula. 

(

Sim s ,  s

i

)

j

=

+

1

e

1
Dis

AvgKL

 

(

,
s s
i

j

)

(10)

3.3 

Impact Summary Generation 

In this step, all the citation sentences are to be evaluated by the significance and a few 
sentences with highest significant scores will be selected into the impact summary.   

In most of the methods for impact summarization, all citation sentences are treated 
uniformly.  However,  different  citation  sentences  from  different  citation  contexts 
should  be  treated  differently,  since  the  citation  sentences  from  a  more  important 
context  should  receive  higher  significant  score.  Therefore,  it  is  more  reasonable  to 
assign unequal weights to different citation sentences in accordance with the impact 
of different citation contexts which they belong to. 

Given  a  set  of  citation  sentences  S  for  a  target  paper,  let  GS=(VS,  ES)  be  an 
undirected graph to reflect the relationships between citation sentences in S. Here VS 
is the set of citation sentences. ES is the set of edges and each edge 
ijse is associated 
with the similarity Sim(si, sj) between sentences si and sj (i≠j), which is calculated by 
formula 10. Two sentences are connected if their similarity is larger than 0 and we let 
Sim(si, si)=0 to avoid self transition. We use the affinity matrix 
SM   to describe GS. 
Then

SM   by making the sum of each row equal to 1. 

SM is normalized to  

360 

P. Hu et al. 

Based  on  

SM ,  the  significant  score 

SigScore(s )   for  citation  sentence  si  can  be 
deduced from those sentences linked with it, which can be formulated in a recursive 
form as follows: 

i

SigScore(s )=

i

δ
∗



 
all j

≠

i


SigScore(s ) M

∗

S

j

+

ji

δ
−
1
| V |
S

 

(11)

Where δis the damping factor usually set to 0.85, as in the PageRank algorithm. For 
implementation,  the  initial  significant  scores  of  all  citation  sentences  are  set  to  1. 
Usually  the  convergence  of  the  iteration  algorithm  is  achieved  when  the  difference 
between the scores computed at two successive iterations  for any citation  sentences 
fall below a given threshold (0.0001 in this study).   

After  evaluating  the  significance  of  each  citation  sentence,  we  select  a  few 
representative  sentences  with  highest  significant  scores  to  generate  the  impact 
summary. 

Recall that in the proposed approach, we incorporate diverse relationships on GP, 
GA,  and  GPA  into  a  unified  regularization  framework  to  infer  the  impact  of  hybrid 
citation context, and then rank citation sentences on GS by leveraging both the impact 
of hybrid citation context and the relationships between citation sentences, which can 
be intuitively represented by Figure 1.   

 

 

 

Fig. 1. The intuitive representation of the proposed approach 

 

4 

Experiments and Evaluation 

4.1  Data Collection 

We  evaluate  the  proposed  approach  on  the  dataset1,  which  contains  25  highly  cited 
papers  from  computational  linguistics  domain.  Each  paper  has  a  set  of  manually 

                                                           
1 http://www-personal.umich.edu/~vahed/resources/single.tar.gz 

 

Leveraging Hybrid Citation Context for Impact Summarization 

361 

selected  terms  representing  the  most  important  impacts  of  that  paper  and  shared  by 
multiple evaluators who has read all the citation sentences of that paper. 

Considering that  hybrid citation context  may improve the  performance of impact 
summarization, we extend the dataset by adding a number of papers with similar topic 
and related authors from the ACL Anthology Network2, which is a large collection of 
more  than  18,000  papers  from  computational  linguistics  domain.  Table  1  shows 
general statistics about the extended dataset. 

Table 1. The general statistics about the extended dataset 

Papers 
Authors 

Citation links between papers 

Co-authorship links between authors 

Authorship links between papers and authors 

7921 
1475 
38542 
14176 
13951 

 
We deem that a good impact summary should cover more important impacts of the 
target paper. If an impact fact occurs in more citation sentences, it should be regarded 
as  more  important  and  be  assigned  higher  weight.  Under  the  condition,  the  citation 
sentence  including  more  impact  facts  with  higher  weight  will  become  a  good 
candidate  for  impact  summary.  Accordingly,  we  construct  a  reference  summary  for 
each  of  the  25  highly  cited  papers  by  making  use  of  the  manually  selected  impact 
terms. We pick citation sentences that cover new and highly weighted impact terms 
into the reference summary until the defined summary length is reached. By this way, 
we expect a good system generated summary to be closer to the reference summary. 

4.2  Evaluation Metrics 

In  the  study,  the  ROUGE  toolkit  [24]  is  adopted,  which  was  officially  adopted  by 
DUC for automatic summarization evaluation. ROUGE metrics measure a summary’s 
content  quality  by  counting  overlapping  units  such  as  n-gram,  word  sequences,  and 
word pairs between the automatically generated summary and the reference summary. 
The higher the ROUGE scores, the similar the two summaries are. 

A few recall-oriented ROUGE metrics have been employed including ROUGE-1, 
ROUGE-2, and  ROUGE-SU4, etc.  Among the different ROUGE scores,  ROUGE-1 
has been shown to agree with human judgment most [24]. Therefore, we only report 
ROUGE-1 in the following experiments since other metrics gives very similar results. 

4.3  Experimental Results 

We  compared  our  proposed  approach  with  several  baselines  as  follows.  All  the 
approaches for comparison are required to extract a few representative citation sentences 
into  the  impact  summary  for  each  of  the  25  highly  cited  papers.  The  main  difference 
                                                           
2 http://clair.eecs.umich.edu/aan_site2/index.php 

362 

P. Hu et al. 

between our approach and other baselines is that we leverage the hybrid citation context 
associated with each citation sentence while other baselines do not. 

Random:  In  this  baseline,  the  sentences  are  selected  randomly  from  the  set  of 

citation sentences and added to the impact summary. 

OTS  [25]:  It  integrates  shallow  NLP  techniques  with  statistical  word  frequency 

analysis to rank and select citation sentences. 

LexRank  [26]:  It  runs  on  the  set  of  citation  sentences  by  first  constructing  a 
citation  sentence  affinity  graph,  and  then  extracting  a  few  informative  citation 
sentences based on eigenvector centrality. 

C-LexRank [18]: This is another state-of-the-art impact summarizer in which the 
citation sentences are firstly clustered, and then the sentences within each cluster are 
ranked via LexRank algorithm. 

We show the evaluation results of different methods in Tables 2, and the highest 

ROUGE-1 scores are shown in bold type. 

Table 2. The evaluation results of different methods 

Method 

Our Approach 
C-LexRank 
LexRank 

OTS 

Random 

ROUGE-1 

0.39507 
0.37837 
0.36021 
0.34404 
0.32966 

 
In  the  experiments,  the  best  result  of  our  approach  is  achieved  when  the  weight 
adjusting  parameters  in  the  formula  6  are  set  as  follows: α=0.4, β=0.3,  and γ=0.3. 
These  parameters  give  different  weights  to  the  citation  sentence,  the  citation  paper 
context, and the citation author context respectively. 

Seen  from  Table  2,  our  proposed  approach  using  the  hybrid  citation  context 
achieves  the  best  performance  compared  to  that  of  the  baseline  approaches  (i.e.  C-
LexRank, LexRank, OTS, and Random), which demonstrates that both citation paper 
context  and  citation  author  context  are  critical  for  improving  the  performance  of 
impact summarization. 

C-LexRank and LexRank perform better than those of OTS and Random. This is 
mainly  because  both  C-LexRank  and  LexRank  make  use  of  the  inter-relationships 
between  citation  sentences  to  rank  them  globally,  while  OTS  only  depends  on  the 
local features. 

C-LexRank outperforms  LexRank in our experiments,  which indicates the  use of 
appropriate  cluster-level  information  is  an  improvement  over  the  use  of  citation 
sentences alone. 

Note that all these baselines generate the impact summary based only on the citation 
sentences  or  sentence  clusters,  regardless  of  the  impact  from  hybrid  citation  context. 
Our proposed approach shows significantly better performance on ROUGE scores, and 
the result difference between our approach and other baselines is significant at the 95% 

 

Leveraging Hybrid Citation Context for Impact Summarization 

363 

statistical confidence level. These observations  again demonstrate the effectiveness of 
our approach by exploiting hybrid citation context to aid impact summarization. 

In the following, we will explore the effect of different parameters in our approach. 

The key parameters we want to investigated are α, β, and  γ. 

Figure  2  to  4  demonstrate  the  influence  of  these  parameters  in  the  proposed 
approach when we tune a parameter from 0 to 1 with the step length 0.1 and vary the 
other two for the best performance to achieve. 

ROUGE-1

e
r
o
c
S
 
E
G
U
O
R

0.4

0.39

0.38

0.37

0

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

1

α

Fig. 2. ROUGE-1 score of the proposed approach vs.α 

ROUGE-1

e
r
o
c
S
 
E
G
U
O
R

0.4

0.39

0.38

0.37

0.36

0

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

1

β

Fig. 3. ROUGE-1 score of the proposed approach vs. β 

ROUGE-1

e
r
o
c
S
 
E
G
U
O
R

0.4

0.39

0.38

0.37

0.36

0

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

1

Fig. 4. ROUGE-1 score of the proposed approach vs. γ 

γ

 

 

 

364 

P. Hu et al. 

From  Figure  2  to  4,  it  can  be  found  that  the  citation  sentence  information 
controlled  by  the  parameter αis  relatively  stable  and  have  little  impact  on  the 
performance. Both citation paper context and citation author context can help improve 
the  performance,  but  excessive  dependence  on  any  one  of  them  will  impair  the 
performance to a certain extent. 

5 

Conclusion and Future Work 

This  paper  proposes  a  context-aware  approach  to  impact  summarization.  In  the 
proposed  approach,  different  kinds  of  relationships  among  papers  and  authors  are 
leveraged  to  jointly  infer  the  impact  of  hybrid  citation  context,  which  is  further 
integrated  in  a  sentence  language  smoothing  model  to  measure  citation  sentence 
relationships more effectively. 

In  future  work,  it  would  be  interesting  to  investigate  the  performance  of  the 
proposed approach on larger bibliographic datasets such as DBLP, ArnetMiner, etc. 
Besides, we will explore machine learning based methods to determine the parameters 
of our approach in an adaptive way. 

 

Acknowledgments.  This  work  was  supported  by  the  National  Natural  Science 
Foundation of China (No. 61133012, 61173062, 61070082) and the Major Projects of 
Chinese National Social Science Foundation (No.11&ZD189). 

References 

1.  Amjad,  A.J.,  Radev,  D.R.:  Reference  Scope  Identification  in  Citing  Sentences.  In:  2012 
Conference  of  the  North  American  Chapter  of  the  Association  for  Computational 
Linguistics: Human Language Technologies (NAACL 2012), pp. 80–90 (2012) 

2.  Paice,  C.D.,  Jones,  P.A.:  The  Identification  of  Important  Concepts  in  Highly  Structured 
Technical Papers. In: 16th Annual International ACM SIGIR Conference on Research and 
Development in Information Retrieval (SIGIR 1993), pp. 69–78 (1993) 

3.  Saggion,  H.,  Lapalme,  G.:  Generating  Indicative-Informative  Summaries  with  SumUM. 

Computational Linguistics 28(4), 497–526 (2002) 

4.  Teufel, S., Moens, M.: Summarizing Scientific Articles: Experiments with Relevance and 

Rhetorical Status. Computational Linguistics 28(4), 409–445 (2002) 

5.  Wan,  X.J.,  Yang,  J.W.: Single  Document  Summarization  with  Document  Expansion.  In: 

22nd National Conference on Artificial Intelligence (AAAI 2007), pp. 931–936 (2007) 

6.  Yan,  R.,  Yuan,  Z.,  Wan,  X.,  Zhang,  Y.,  Li,  X.:  Hierarchical  Graph  Summarization: 
Leveraging  Hybrid  Information  through  Visible  and  Invisible  Linkage.  In:  Tan,  P.-N., 
Chawla, S., Ho, C.K., Bailey, J. (eds.) PAKDD 2012, Part II. LNCS (LNAI),  vol. 7302, 
pp. 97–108. Springer, Heidelberg (2012) 

7.  Sun, J.T., Shen, D., Zeng, H.J., Yang, Q., Lu, Y.C., Chen, Z.: Web-Page Summarization 
Using  Clickthrough  Data.  In:  28th  Annual  International  ACM  SIGIR  Conference  on 
Research and Development in Information Retrieval (SIGIR 2005), pp. 194–201 (2005) 

8.  Hu,  P.,  Sun,  C.,  Wu,  L.F.,  Ji,  D.H.,  Teng,  C.:  Social  Summarization  via  Automatically 
Discovered  Social  Context.  In:  5th  International  Joint  Conference  on  Natural  Language 
Processing (IJCNLP 2011), pp. 483–490 (2011) 

 

Leveraging Hybrid Citation Context for Impact Summarization 

365 

9.  Hu, M.S., Sun, A.X., Lim, E.P.: Comments-Oriented Document Summarization: Understanding 
Documents with Users’ Feedback. In: 31st Annual International ACM SIGIR Conference on 
Research and Development in Information Retrieval (SIGIR 2008), pp. 291–298 (2008) 

10.  Yang, Z., Cai, K.K., Tang, J., Zhang, L., Su, Z., Li, J.Z.: Social Context Summarization. 
In:  34th  International  ACM  SIGIR  Conference  on  Research  and  Development  in 
Information Retrieval (SIGIR 2011), pp. 255–264 (2011) 

11.  Nakov, P., Schwartz, A., Hearst, M.: Citances: Citation Sentences for Semantic Analysis 
of  Bioscience  Text.  In:  ACM  SIGIR  2004  Workshop  on  Search  and  Discovery  in 
Bioinformatics (2004) 

12.  Nanba,  H.,  Okumura,  M.:  Towards  Multi-Paper  Summarization  Using  Reference 
Information.  In:  16th  International  Joint  Conference  on  Artificial  Intelligence  (IJCAI 
1999), pp. 926–931 (1999) 

13.  Schwartz, A.S., Hearst, M.: Summarizing Key Concepts Using Citation Sentences. In: The 
Workshop  on  Linking  Natural  Language  Processing  and  Biology:  Towards  Deeper 
Biological Literature Analysis (BioNLP 2006), pp. 134–135 (2006) 

14.  Teufel,  S.:  Argumentative  Zoning  for  Improved  Citation  Indexing.  Computing  Attitude 

and Affect in Text: Theory and Applications, pp. 159–170 (2005) 

15.  Kan,  M.Y.,  Klavans,  J.L.,  McKeown,  K.R.:  Using  the  Annotated  Bibliography  as  a 
Resource  for  Indicative  Summarization.  In:  3rd  International  Conference  on  Language 
Resources and Evaluation, LREC 2002 (2002) 

16.  Elkiss,  A.,  Shen,  S.W.,  Fader,  A.,  Erkan,  G.,  States,  D.,  Radev,  D.:  Blind  Men  and 
Elephants: What Do Citation Summaries Tell Us about a Research Article. Journal of the 
American Society for Information Science and Technology 59(1), 51–62 (2008) 

17.  Mei, Q.Z., Zhai, C.X.: Generating Impact-Based Summaries  for Scientific Literature. In: 
46th Annual Meeting of the Association for Computational Linguistics: Human Language 
Technology (ACL 2008), pp. 816–824 (2008) 

18.  Qazvinian,  V.,  Radev,  D.R.:  Scientific  Paper  Summarization  Using  Citation  Summary 
Networks.  In:  22nd  International  Conference  on  Computational  Linguistics  (COLING 
2008), pp. 689–696 (2008) 

19.  Qazvinian,  V.,  Radev,  D.R.,  Ozgur,  A.:  Citation  Summarization  through  Keyphrase 
Extraction.  In:  23rd  International  Conference  on  Computational  Linguistics  (COLING 
2010), pp. 895–903 (2010) 

20.  Amjad, A.J., Radev, D.R.: Coherent Citation-Based Summarization of Scientific Paper. In: 
49th Annual Meeting of the Association for Computational Linguistics: Human Language 
Technologies (ACL 2011), pp. 500–509 (2011) 

21.  Deng, H.B., Lyu, M.R., King, I.: A Generalized Co-HITS Algorithm and Its Application to 
Bipartite  Graphs.  In:  15th  ACM  SIGKDD  International  Conference  on  Knowledge 
Discovery and Data Mining (KDD 2009), pp. 239–248 (2009) 

22.  Deng,  H.B.,  Han,  J.W.,  Lyu,  M.R.,  King,  I.:  Modeling  and  Exploiting  Heterogeneous 
Bibliographic Networks for Expertise Ranking. In: 12th ACM/IEEE-CS Joint Conference 
on Digital Libraries (JCDL 2012), pp. 71–80 (2012) 

23.  Zhai, C.X., Lafferty, J.: A Study of Smoothing Methods for Language Models Applied to 
Ad Hoc Information Retrieval. In: 24th Annual International ACM SIGIR Conference on 
Research and Development in Information Retrieval (SIGIR 2001), pp. 334–342 (2001) 

24.  Lin,  C.Y.,  Hovy,  E.:  Automatic  Evaluation  of  Summaries  Using  N-Gram  Cooccurrence 
Statistics.  In:  2003  Conference  of  the  North  American  Chapter  of  the  Association  for 
Computational Linguistics on Human Language Technology, pp. 71–78 (2003) 

25.  Nadav, R.: The Open Text Summarizer, http://libots.sourceforge.net/ 
26.  Erkan, G., Radev, D.R.: LexPageRank: Prestige in Multi-Document Text Summarization. 
In:  2004  Conference  on  Empirical  Methods  in  Natural  Language  Processing,  EMNLP 
2004 (2004) 


