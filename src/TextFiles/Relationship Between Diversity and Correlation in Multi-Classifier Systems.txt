Relationship between Diversity and Correlation

in Multi-Classiﬁer Systems

Kuo-Wei Hsu and Jaideep Srivastava

University of Minnesota, Minneapolis, MN 55455, USA

{kuowei,srivasta}@cs.umn.edu

Abstract. Diversity plays an important role in the design of Multi-
Classiﬁer Systems, but its relationship to classiﬁcation accuracy is still
unclear from a theoretical perspective. As a step towards the solution
of this probelm, we take a diﬀerent route and explore the relationship
between diversity and correlation. In this paper we provide a theoret-
ical analysis and present a nonlinear function that relates diversity to
correlation, which hence can be further related to accuracy. This paper
contributes to connecting existing research in diversity and correlation,
and also providing a proxy to the relationship between diversity and ac-
curacy. Our experimental results reveal deeper insights into the role of
diversity in Multi-Classiﬁer Systems.

Keywords: Diversity, Correlation, Multi-Classiﬁer System (MCS).

1 Introduction

The design of Multi-Classiﬁer Systems (MCSs) is inspired by the group decision
making process [13,14]. The motivation behind MCSs is that each classiﬁer has
its own strengths and weaknesses, and hence a group of classiﬁers could poten-
tially leverage the wisdom of crowds. If each classiﬁer in an MCS has expertise
in classifying samples in some portions of a data space, the ﬁnal output that
is aggregated from all classiﬁers would become more reliable. More precisely,
eﬀective classiﬁers in an MCS are those that are accurate and independent. The
former means that a classiﬁer in an MCS is expected to provide performance at
least better than random guessing, while the latter means that correlation be-
tween outputs of classiﬁers is expected to be small. This also implies that their
outputs are expected to be diverse.

Diversity could be captured by disagreements between classiﬁers in an MCS
and it plays a signiﬁcant role in the success of MCSs [10]. However, the fol-
lowing research question becomes important for the design of MCSs: Is there a
relationship between diversity (between the member classiﬁers of an ensemble)
and accuracy (of the ensemble)? We address this research question by taking
a diﬀerent route and building a relationship between diversity and correlation,
which could be related to accuracy.

Fig. 1 illustrates the focus of this paper. The relationship between diversity
and accuracy is ambiguous in theory (e.g. that elusive diversity [9]). The rela-
tionship between correlation and the accuracy is relatively clear to researchers.

M.J. Zaki et al. (Eds.): PAKDD 2010, Part II, LNAI 6119, pp. 500–506, 2010.
c(cid:2) Springer-Verlag Berlin Heidelberg 2010

Relationship between Diversity and Correlation in Multi-Classiﬁer Systems

501

Fig. 1. Relationships among the accuracy, diversity, and correlation

Fig. 1 also gives two more examples of such relationships: Tumer and Ghosh
build such a relationship for simple averaging ensemble [15], while Bremian re-
lates correlation to performance of Random Forests [1].

This paper provides a proxy to the relationship between diversity and accu-

racy, while it has a potential to assist with a design guideline for MCSs.

The rest of this paper is structured as follows. Section 2 gives a theoretical
analysis and Section 3 discusses experimental results. Section 4 is a brief review
of some related work, while Section 5 gives conclusions and future work.

2 Theoretical Analysis of Diversity and Correlation

Diversity has been studied by many researchers [3,6], but its relationship to ac-
curacy is not clear. One diﬃculty is that there exists an elegant bias-variance-
covariance decomposition framework for regression tasks, but the framework does
not directly apply to classiﬁcation tasks [4]. Here we do not directly connect diver-
sity to accuracy. Rather we build a relationship between diversity and correlation.
Notations. For a set of N instances and two classiﬁers, N11 and N00 denote
the numbers of instances for which both classiﬁers are correct and incorrect,
respectively; N10 and N01 denote the numbers of instances for which only the
ﬁrst and the second classiﬁer is correct, respectively. The following deﬁnitions
are with respect to outputs of classiﬁers i and j.
Deﬁnition 1. Disagreement measure (Dis) representing diversity [10].

Disi,j =

N01 + N10

N11 + N10 + N01 + N00

=

N01 + N10

N

Deﬁnition 2. Q-statistic or Q [10,11].

Qi,j =

N11 · N00 − N01 · N10
N11 · N00 + N01 · N10

502

K.-W. Hsu and J. Srivastava

Deﬁnition 3. Correlation [10].

ρi,j =

N11 · N00 − N01 · N10

(cid:2)
(N11 + N10) · (N01 + N00) · (N11 + N01) · (N10 + N00)

One could calculate system-wise values by averaging all pairs, so we ignore the
subscripts i and j for concise representation. Using these deﬁnitions and the in-
equality of arithmetic-geometric-harmonic means, we obtain Corollary 1, as given
below.

Corollary 1. Relationship between disagreement measure and Q-statistic.

Q ≤ (1 − Dis)2 · N 2 − 4 · Dis · N
(1 − Dis)2 · N 2 + 4 · Dis · N

Corollary 1 helps us connect diversity to correlation, since a connection between
Deﬁnition 2 and Deﬁnition 3 is that the absolute value of correlation will be
bounded by the absolute value of Q − statistic. Next we deﬁne f(x) based on
Corollary 1.

f(x) =

(1 − x)2 · N 2 − 4 · x · N
(1 − x)2 · N 2 + 4 · x · N , where x = Dis

Since x = Dis and hence x ∈ (0, 1), we have f(0) = 1 and f(1) = −1. As the
goal is to have zero correlation, we would like to know the interception of f(x)
and x-axis. We call the interception the critical value of x (xc) or the critical
point of Dis, and the following critical value is straightforward:

(cid:3)

xc = (1 +

N ) − 2 ·
2

1
N

− 1
N 2

Before this critical point, higher diversity reduces correlation. This supports the
intuition that higher diversity between classiﬁers is usually associated with a
better MCS. When diversity crosses the critical point, increasing diversity would
increase correlation while highly correlated classiﬁers usually correspond to an
inferior MCS.

3 Experiments and Discussion

For each trial for a data set, we randomly draw samples and accordingly train a
decision tree (without pruning). Similarly, we generate a disjoint set of samples
and use it as a test set for each trial for a data set. To control the variable in,
we create a dummy classiﬁer for each decision tree. We repeat this 100 times
and create 100 pairs of classiﬁers in every experiment, using the corresponding
test set to evaluate each pair of classiﬁers, calculating values of disagreements,
Q − statistic, and correlation. Figures in Appendix illustrate the results. Our
ﬁndings are summarized as below:

Relationship between Diversity and Correlation in Multi-Classiﬁer Systems

503

– The relationship between disagreement measure and Q−statistic is not linear.
Although curves of the theoretical upper bounds do not always match curves
of the observed values, they do indicate trends of curves of the observed values.
– For some data sets, the theoretical upper bounds of the values of Q−statistic
are close to the observed values. For all data sets, they are close when diver-
sity is lower and especially when N is smaller.
responding to them. They are exceptional cases where Q − statistic is 1.

– There are exceptions that are larger than the theoretical upper bounds cor-

– As N increases, curves move to the right. The critical point is a function of
N. This suggests that we need to increase diversity in order to obtain low
(or even 0) correlation when the number of training samples increases.
– It is not always the case that we observe critical points in experiments. For
those showing critical points, we observe that Q − statistic and correlation
move away from 0 as the diversity increases. This follows our analysis.

Now we take a couple of steps further and use our analysis result to explain some
interesting phenomenon. [7] showed theoretically that heterogeneity (i.e. using dif-
ferent algorithms in an MCS) would improve diversity among member classiﬁers
in an MCS. Furthermore, [8] showed empirically that one could obtain such an
improvement more often in bagging setting than in boosting setting; in addition
it empirically showed that AdaBoost with heterogeneous algorithms would work
better when the data set is larger. Compared to bagging, AdaBoost often provides
higher diversity. When we introduce heterogeneity into AdaBoost, diversity will
probably be increased. As discussed earlier, increasing diversity has positive eﬀect
in the left region (between 0 and the critical point) of the graph of f(x), but it has
negative eﬀect in the right region (between the critical point and 1) of the graph of
f(x). Moreover, the smaller the data set, the smaller the critical point, the smaller
the left region. Therefore, using heterogeneous algorithms in AdaBoost on small
data sets may actually have negative eﬀect to the performance.

4 Related Work

The importance of reducing correlation between classiﬁers in an MCS has been
recognized [2]. Tumer and Ghosh discuss a framework that quantiﬁes the need
to reduce correlation between classiﬁers in an MCS, and associate the number
of training samples (i.e. the size of the training set) with the eﬀect of correlation
reduction [15]. Our analysis suggests that, for example, the critical point of Dis
depends on N. Mane et al. prove that classiﬁers trained by using independent
feature sets give more independent estimations and their combination gives more
accurate estimations [12].

The term anti-correlation is confusing. In [13] McKay and Abbass describe it as
a mechanism to promote diversity, but they do not explain why anti-correlation is
equivalent to diversity promoting. Our analysis, however, explains this: When we
promote diversity to a certain level (i.e. we have diversity in the neighborhood of
the critical point), we decrease the upper bound of the absolute value of correlation
and thus it is possible to observe very low or even negative correlation.

504

K.-W. Hsu and J. Srivastava

In [5] Chung et al. argue that, given the average the accuracy (or performance)
of classiﬁers, there is a linear relationship between correlation and disagreement
measure. Nevertheless, our analysis clearly shows that the relationship is not linear
and our experimental results do not reveal the linear relationship as given in [5].

5 Conclusions and Future Work

In this paper we explored the relationship between diversity, represented by dis-
agreement, and correlation between classiﬁers in MCSs, conducting a theoretical
analysis and experiments for the relationship between diversity and correlation.
As a result, we demonstrated a nonlinear function for the relationship, while
the experimental results reveal some interesting insights. Therefore, this paper
contributes to a better understanding of the role of diversity in MCSs.

Future work includes (1) investigating a tighter theoretical bound of Q-statistic,
(2) integrating our analysis into those proposed by others in order to build a more
elegant relationship between diversity and accuracy, and (3) using our analysis
result to assist with classiﬁer selection and/or combination algorithms for MCSs.

Acknowledgements. The research reported herein was supported by the Na-
tional Aeronautics and Space Administration via award number NNX08AC36A,
by the National Science Foundation via award number CNS-0931931, and a gift
from Huawei Telecom. We gratefully acknowledge all our sponsors. The ﬁndings
presented do not in any way represent, either directly or through implication,
the policies of these organizations.

References

1. Breiman, L.: Random Forests. Machine Learning 45(1), 5–32 (2001)
2. Brown, G., Wyatt, J., Tino, P.: Managing Diversity in Regression Ensembles. Jour-

nal of Machine Learning Research (JMLR) 6(September), 1621–1650 (2005)

3. Brown, G., Wyatt, J., Harris, R., Yao, X.: Diversity Creation Methods: A Survey

and Categorisation. Journal of Information Fusion 6(1), 5–20 (2005)

4. Brown, G.: Ensemble Learning. Encyclopedia of Machine Learning (2010)
5. Chung, Y., Hsu, D.F., Tang, C.Y.: On the Relationships Between Various Diversity
Measures in Multiple Classiﬁer Systems. In: International Symposium on Parallel
Architectures, Algorithms, and Networks, pp. 184–190 (2008)

6. Ghosh, J.: Multiclassiﬁer systems: Back to the future. In: Roli, F., Kittler, J. (eds.)

MCS 2002. LNCS, vol. 2364, pp. 1–15. Springer, Heidelberg (2002)

7. Hsu, K.-W., Srivastava, J.: Diversity in Combinations of Heterogeneous Classiﬁers.
In: Theeramunkong, T., Kijsirikul, B., Cercone, N., Ho, T.-B. (eds.) PAKDD 2009.
LNCS, vol. 5476, pp. 923–932. Springer, Heidelberg (2009)

8. Hsu, K.-W., Srivastava, J.: An Empirical Study of Applying Ensembles of Hetero-
geneous Classiﬁers on Imperfect Data. In: Workshop on Data Mining When Classes
are Imbalanced and Errors Have Costs (2009)

9. Kuncheva, I.: That Elusive Diversity in Classifer Ensembles. In: Iberian Conference

on Pattern Recognition and Image Analysis (IbPRIA), pp. 1126–1138 (2003)

10. Kuncheva, I., Whitaker, J.: Measures of Diversity in Classiﬁer Ensembles and Their
Relationship with the Ensemble Accuracy. Machine Learning 51(2), 181–207 (2003)

Relationship between Diversity and Correlation in Multi-Classiﬁer Systems

505

11. Kuncheva, I.: Combining Pattern Classiﬁers: Methods and Algorithms. Wiley

Press, Chichester (2004)

12. Mane, S., Srivastava, J., Hwang, S.-Y.: Estimating missed actual positives using
independent classiﬁers. In: International Conference on Knowledge Discovery and
Data Mining (KDD), pp. 648–653 (2005)

13. McKay, R., Abbass, H.A.: Anti-correlation: A diversity promoting mechanism in
ensemble learning. Australian Journal of Intelligence Information Processing Sys-
tems 7(3/4), 139–149 (2001)

14. Polikar, R.: Ensemble based systems in Decision making. IEEE Circuits and Sys-

tems Magazine 6(3), 21–45 (2006)

15. Tumer, K., Ghosh, J.: Error Correlation and Error Reduction in Ensemble Classi-

ﬁers. Connection Science 8(3-4), 385–403 (1996)

Appendix A Experimental Results

In these ﬁgures, the x-axis is the value of disagreement measure (representing
diversity) and y-axis corresponds to values of Q − statistic or correlation ρ.
A (blue) diamond and a (pink) square represent respectively an observed Q −
statistic and an observed correlation, while a (yellow) triangle gives an upper
bound of the corresponding value of Q-statistic. We report results for 100 and
1000 training samples for each data set.

Fig. A1. Results for Letter with 100 (left) and 1000 (right) samples

Fig. A2. Results for Splice with 100 (left) and 1000 (right) samples

506

K.-W. Hsu and J. Srivastava

Fig. A3. Results for Waveform-5000 with 100 (left) and 1000 (right) samples

Fig. A4. Results for Nursery with 100 (left) and 1000 (right) samples

Fig. A5. Results for Optdigits with 100 (left) and 1000 (right) samples

Fig. A6. Results for Pendigits with 100 (left) and 1000 (right) samples


