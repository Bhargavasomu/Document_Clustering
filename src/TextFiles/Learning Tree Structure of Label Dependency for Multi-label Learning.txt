Learning Tree Structure of Label Dependency

for Multi-label Learning(cid:2)

Bin Fu1, Zhihai Wang1, Rong Pan2, Guandong Xu3, and Peter Dolog2

1 School of Computer and Information Technology,
Beijing Jiaotong University, Beijing 100044, China

{09112072,zhhwang}@bjtu.edu.cn

2 Department of Computer Science, Aalborg University, Denmark

{rpan,dolog}@cs.aau.dk

3 School of Engineering & Science, Victoria University, Australia

Guandong.Xu@vu.edu.au

Abstract. There always exists some kind of label dependency in multi-
label data. Learning and utilizing those dependencies could improve the
learning performance further. Therefore, an approach for multi-label
learning is proposed in this paper, which quantiﬁes the dependencies
of pairwise labels ﬁrstly, and then builds a tree structure of the labels
to describe them. Thus the approach could ﬁnd out potential strong la-
bel dependencies and produce more generalized dependent relationships.
The experimental results have validated that compared with other state-
of-the-art algorithms, the method is not only a competitive alternative,
but also has shown better performance after ensemble learning especially.

Keywords: classiﬁcation; multi-label instance; multi-label learning; la-
bel dependency.

1

Introduction

Classiﬁcation is to predict possible labels on unlabeled instance given a set of
labeled training instances. Traditionally, it is assumed that each instance is as-
sociated with only one label. However, an instance often has multiple labels
simultaneously in practice [1,2]. For example, a report about religion could also
be viewed as a politics report. Classiﬁcation for this kind of instance is called
multi-label learning. Nowadays, multi-label learning is receiving more and more
concerns, and becoming an important topic.

Various methods have been developed for multi-label learning, and these
methods mainly fall into two categories [2]: (1) algorithm adaptation, which
extends traditional single-label models so that they can deal with multi-label
instances directly. Several adapted traditional models include Bayesian method,

(cid:2) This research has been partially supported by the Fundamental Research Funds for
the Central Universities, China (2011YJS223), National Natural Science Fund of
China (60673089, 60973011), and EU FP7 ICT project M-Eco: Medical Ecosystem
Personalized Event-based Surveillance (No. 247829).

P.-N. Tan et al. (Eds.): PAKDD 2012, Part I, LNAI 7301, pp. 159–170, 2012.
c(cid:2) Springer-Verlag Berlin Heidelberg 2012

160

B. Fu et al.

AdaBoost, decision tree, associative rules, k-NN, etc. [3,4,5,6,7]. (2) problem
transformation, which converts a multi-label problem into one or several single-
label problems. Thus traditional single-label classiﬁers can be used directly with-
out modiﬁcation. Recently, many methods have been proposed to learn label
dependency as a way of increasing learning performance [1,2,8,9,10,11,12]. How-
ever, most of them do not give an explicit description of label dependency. For
example, classiﬁer chain, a model proposed recently [9], links the labels into a
chain randomly and assumes that each label is dependent on all its preceding
labels in the chain. However, each label may be independent with its preceding
labels while dependent on its following labels since they are linked randomly.
Moreover, more complex dependency such as a tree or DAG-like hierarchical
structure of labels often exists in practice, thus more appropriate models are
needed to describe them.

Hence, we propose one kind of novel method for aforementioned issues. We
quantify the dependencies of pairwise labels ﬁrstly, building a complete undi-
rected graph that takes the labels as the set of vertices and the dependent val-
ues as edges. A tree is then derived to depict the dependency explicitly, so the
unrelated labels can be removed for each label and the dependency model is
generalized into a tree model. Furthermore, we also use ensemble technique to
build multiple trees to capture the dependency more accurately. The experimen-
tal results would show our proposed method is competitive and could further
enhance learning performance on most of datasets.

The remainder of this paper is organized as follows: We review the related
works in section 2. A formal deﬁnition of multi-label learning is given in section 3.
In section 4, we describe and analyze our proposed methods in detail. Section 5 is
devoted to the experiment design and result analysis. The last section concludes
this paper and gives some potential issues with further research.

2 Related Work

Many methods have been proposed to cope with multi-label learning by exploit-
ing label’s dependencies. According to the order of dependency be learned, these
methods mainly fall into following categories.

(1) No label dependency is learned. Basic BR (Binary Relevance) method
decomposed one multi-label problem into multiple independent binary classiﬁ-
cation problems, one for each label [2]. Boutell et al. used BR for scene classi-
ﬁcation [13]. Zhang et al. proposed ML-KNN, a lazy method based on BR [7].
Tsoumakas et al. proposed HOMER to deal with a large number of labels [14].
(2) Learning the dependencies of pairwise labels. Hullermeier et al. proposed
the RPC method that learned the pairwise preferences and then ranked the
labels [15]. Furnkranz et al. extended the RPC by introducing a virtual label [16].
Madjarov et al. proposed a two stage architecture to reduce the computational
complexity of the pair-wise methods [17].

(3) Learning the dependencies within multiple labels. Basic LP (Label Power-
set) method treated the whole set of labels as a new single label and learned
dependencies within all them [2]. Tsoumakas et al. proposed the RAkELd

Learning Tree Structure of Label Dependency for Multi-label Learning

161

method that divided the label set into disjoint subsets of size k randomly [18].
Stacking-base method was proposed to aggregate binary predictions to form
meta-instances [19]. Read proposed the PS, which decomposed the instance’s la-
bels until a threshold was met [8]. Read et al. proposed the CC (Classiﬁer Chain)
algorithm to link the labels into a chain randomly [9]. Dembcynski et al. pro-
posed PCC, a probabilistic framework that solved the multi-label classiﬁcation
in terms of risk minimization [10].

A number of models have also been used to depict the labels dependencies
explicitly, which include multi-dimensional Bayesian network, conditional depen-
dency networks, conditional random ﬁelds [11,20,21,22,23]. Dembczynski et al.
formally explained the diﬀerence between the conditional dependency and un-
conditional dependency [24]. Similar with these methods, our proposed method
uses the tree to learn the label dependency explicitly. the diﬀerence is that we
simply ignore the feature set in the process of constructing a tree, whereas others
[11] build the models conditioned on the feature set.

3 The Concept of Multi-label Learning

Let X be the instance space, and L = (l1, l2, . . . , lm) be a set of labels. Given a
training instance set D = {(x1, C1), (x2, C2), . . . , (xn, Cn)}, where xk ∈ X is an
instance, and Ck ⊂ L is a subset of L denoting xk’s true labels, the target of
multi-label learning is to build a classiﬁer: f : X → 2L, that is a mapping from
the instance space to a set of label subset, where 2L is the power set of L. Ck
can also be represented by a Boolean vector (bk1, bk2, . . . , bkm), where bkj = 1
indicates label lj is xk’s true label (lj ∈ Ck), while bkj = 0 indicates the opposite.
Let x ∈ X be an unlabeled instance, y = (y1, y2, . . . , ym) be its Boolean
vector of predicted labels, we can also make prediction by calculating the joint
conditional probabilityP (y|x). For each label lk, let P arent(lk) denote the set
of labels that label lk is dependent on, P arent(yk) is the corresponding Boolean
counterpart. Hence P (y|x) can be transformed as Eq.(1).

P (y|x) =

m(cid:2)

k=1

P (yk|parent(yk), x)

(1)

where yk denotes the kth label. Hence we can get the label vector’s posterior
probability by calculating each label’s posterior probability respectively, so the
transformation of Eq.(1) is a kind of problem transformation. A key issue is how
to exactly ﬁnd the set of dependent labels for each label in order to calculate
the posterior probability more accurately.

4 Learning a Tree Structure of Labels

As mentioned above, to eliminate weak dependencies in CC model, and ﬁt the
real data more accurately, we propose a new algorithm named as LDTS (Learning
dependency from Tree Structure of Labels) in this section.

162

B. Fu et al.

LDTS ﬁrstly measures the dependency for each pairwise labels li and lj, no-
tated as dependency(li, lj), thus an undirected complete graph G(L, E) is con-
structed, where the label set L denotes the vertices, and E = {dependency(li, lj) :
li ∈ L, lj ∈ L} denotes the edges. To determine the dependent labels for each
label, a maximum spanning tree is then derived using Prim algorithm, and each
label is assumed to be dependent on its ancestor labels. A dataset is then created
for each label and their dependent labels are added into the feature set, so we
could utilize these dependency since the classiﬁers is trained based on the new
feature set. The whole training process is outlined in Algorithm 1.

Algorithm 1. The process of training LDTS classiﬁer
Input:

The training dataset: D = {(x1, C1), (x2, C2), . . . , (xn, Cn)};
The algorithm for training base classiﬁer: B.

Output:

Classiﬁers: (f1, f2, . . . , fm).

1: for each pair of labels (li, lj ), measure their dependency: dependency(li, lj)
2: create a undirected full graph G = (L, E)
3: use the P rim algorithm to derive a maximum spanning tree: T
4: for label l1, l2, ..., lm, get the set consists of its ancestor labels: P arent(li)
5: for i = 0 to m do
let the Di = D
6:
for j = 0 to m do
7:
8:
9:
10:
11:
12:
13: end for
14: return the m classiﬁers: (f1, f2, . . . , fm)

end if
end for
for the Di, set li as its only label, train the classiﬁer fi

if lj (cid:2)∈ P arent(li) then

delete this label from Di

At step 1, mutual information is used to compute the dependencies of pairwise

labels. Its deﬁnition is shown as follows [25].

(cid:3)

H(X, Y ) =

P (x, y) log

x,y

P (x, y)

P (x)P (y)

(2)

where X and Y are two variables, x and y are their all possible values.

The labels is organized using a tree for two purposes. Firstly, the properties
of maximum spanning tree ensure that each label is more dependent on its
ancestor labels than other labels, since they have greater mutual information
value. Hence it could eliminate weak dependency further by assuming each label
is only dependent on its ancestor labels. When generating the graph and tree of
labels, we simply assume that label dependency is independent with the feature
set and only consider the mutual inﬂuence among the labels, this is one kind
of the unconditional dependency described in [24]. Secondly, various kinds of
dependencies including tree hierarchy and DAG of dependency may exist within

Learning Tree Structure of Label Dependency for Multi-label Learning

163

labels. Therefore, we expect the performance could be improved, especially on
the datasets in which the labels are organized into a tree indeed.

It is also should be noted that the main purpose of our method is to ﬁnd more
accurate label dependency, and it does not impose a hierarchy on labels since
labels have the same parent or in diﬀerent paths could exist simultaneously.
This is diﬀerent from the hierarchical classiﬁcation that impose a strict label
hierarchy. Although the randomness in not eliminated fully, we do reduce it to
only select the strong dependency randomly. One possible issue is that a full
graph of labels needs to be learned with the computational complexity O(n2),
the eﬃciency needs further improvement to cater for a large number of labels.

When classifying an unlabeled instance x, each label li can not be predicted
until its dependent labels are all predicted. Hence the labels should be predicted
from the root of the tree and then its children recursively until all the leaves
are reached. The detailed process is depicted in Algorithm 2. For each label, the
labels dependencies are considered since its prediction is based on the feature
set and the predictions of its dependent labels.

Algorithm 2. The process of classiﬁcation using LDTS classiﬁer
Input:

A unlabeled instance x that needs to be classiﬁed.

Output:
The prediction Y = (y1, y2, . . . , ym).
1: set the vector to be empty, Y ← ()
2: set the root label as the current label need to be predicted: t
3: predict current label t for x using corresponding classiﬁer ft
4: add ft(x) into Y , Y ← Y
5: use the result ft(x) to update the x, x = (x, ft(x))
6: ﬁnd all the children labels of t
7: repeat
8:
9:
10:
11: until all the labels are predicted
12: return the predicted vector Y

for each children labels ci of t do

repeat the step 2-6

(cid:2)

ft(x)

end for

When generating the directed tree in LDTS, the root node is selected ran-
domly. However, selecting a diﬀerent label will result in a diﬀerent tree and thus
generating diﬀerent dependent labels for each label. Another issue is the label
dependency could not be utilized fully, since the dependency of pairwise labels
li, lj calculated here is mutual and useful equally to each other. One possibility
is that a label may also depend on its children labels, but the directed tree does
not allow for this situation. To address such issues, the ensemble learning is used
to generate multiple LDTS classiﬁers iteratively. In each iteration, the classiﬁer
is trained on a sampling of the original dataset, and the root label is reselected
randomly. Hence each iteration will get a diﬀerent label tree and combining them
will reduce the inﬂuence of the root’s randomness and take full advantage of the
label dependency. We call this extended method ELDTS(Ensemble of LDTS).

164

B. Fu et al.

The detail process is depicted in Algorithm 3. Given an unlabeled instance x,
all predictions of these classiﬁers will be aggregated into a ﬁnal result by voting
simply.

Algorithm 3. The process of training ELDTS classiﬁer
Input:

The training dataset: D = {(x1, C1), (x1, C1), . . . , (xn, Cn)};
The algorithm for training base classiﬁer: B;
The number of iteration: n.

Output:

An ensemble of LDTS classiﬁers F = (f1, f2, . . . , fm).

1: set the F to be empty: F = ()
2: for i = 0 to m do
3:

generate a new dataset Di by sampling on the original dataset with replacement

select the root label ri randomly;
train a LDTS classiﬁer ti using B, based on the dataset Di and root label ri
add fi into F

4:
5:
6:
7: end for
8: return the ensemble of classiﬁers: F

All above are the description and analysis of our proposed algorithms. Com-
parison with other state-of-the-art algorithms and further analysis will be given
in the following section.

5 Experiment Design and Analysis

5.1 The Description of Datasets

We take several datasets from multiple domains for the experiments, and table
1 depicts them in detail.

Table 1. Description of the datasets used in experiments

Domain

Dataset
emotions music
enron
medical
scene
yeast

text
text
image
biology

Instances Attributes Labels LC
593
1702
978
2407
2417

72
1001
1449
294
103

1.869
3.378
1.245
1.074
4.237

6
53
45
6
14

LD
0.311
0.064
0.028
0.179
0.303

DLS
27
753
94
15
198

Several statistics as follows have been used to characterize these datasets.
(1) Label cardinality: LC = 1
n

|Ci|. It calculates the average number
of labels for each instance, where |Ci| is the number of true labels of the ith
(cid:5)(cid:5). It is calculated by dividing the label
instance.

(2) Label density: LD = 1
n

(cid:4)n
i=1

(cid:4)n
i=1

cardinality by m, the size of original label set.

(cid:5)(cid:5) Ci

m

Learning Tree Structure of Label Dependency for Multi-label Learning

165

(3) Distinct label sets: DLS(D) = |{C|∃(x, C) ∈ D}|. It counts the number of

distinct label sets that appear in the dataset.

Seen from table 1, these datasets cover many domains including text catego-
rization, scene classiﬁcation, emotion analysis, biology etc.. It should be noted
that there are no label hierarchies in these datasets and we use them to examine
whether our methods could ﬁnd more strong label dependency and gain bet-
ter performance. More detail description can be found on the oﬃcial website of
Mulan1.

5.2 Evaluation Criteria

In order to evaluate the algorithm performance, the criteria should be speciﬁed.
Let D = {(x1, C1), (x2, C2), . . . , (xn, Cn)} be a dataset, where xi is the ith in-
stance, and Ci ⊂ L is its true labels. Given a classiﬁer f and an instance xi,
Yi denotes the predicted labels for xi, while rank(xi) or ranki denotes the pre-
dicted rank of labels, and rank(xi, l) denotes the label l’s position in the rank.
All the criteria we used are as follows.

(1) Hamming loss: It is proposed by Schapire and Singer [4].

H-Loss(f, D) =

n(cid:3)

Yi

i=1

1
n

(cid:6)

m

Ci

(3)

(cid:6)

The operator
number of misclassiﬁed labels for an instance.

calculates the symmetric diﬀerence of two sets, which is the

(2) Accuracy: It calculates the ratio between the intersection and union of the

predicted set of labels and the true set of labels for the instances on average.

Accuracy(f, D) =

(cid:7)
(cid:8)

(cid:5)(cid:5)(cid:5)(cid:5) Yi

Yi

Ci
Ci

(cid:5)(cid:5)(cid:5)(cid:5)

n(cid:3)

i=1

1
n

(4)

(3) One-error: It calculates how many times that top-ranked label is not a

true label of the instance.

One-Error =

n(cid:3)

i=1

1
n

δ(arg min
l∈L

rank(xi, l))

(5)

where δ(x) = 1 if l is a true label of the instance, otherwise δ(x) = 0.

(4) Ranking loss: It expresses the number of times when the irrelevant labels

are ranked before the true labels.

R-Loss=

n(cid:3)

i=1

1
n

(cid:5)(cid:5)Ci

1

(cid:5)(cid:5)|Ci|

(cid:5)(cid:5){(la, lb) : rank(xi, la) > rank(xi, lb), (la, lb) ∈ Ci × Ci}(cid:5)(cid:5)

(6)

1 http://mulan.sourceforge.net/

166

B. Fu et al.

(5) Average precision: This measurement calculates the average fraction of

labels ranked above a particular label l ∈ Ci, which are all also in Ci.
) ≤ rank(xi, l)}|

(cid:4) ∈ Ci : rank(xi, l

n(cid:3)

(cid:3)

|{l

(cid:4)

(7)

AvePrec =

1
n

i=1

1(cid:5)(cid:5)Ci

(cid:5)(cid:5)

l∈Ci

rank(xi, l)

These criteria evaluate the diﬀerent aspects of these methods. While Hamming
loss and accuracy do not consider the relation between diﬀerent predictions, the
other 3 criteria take such a relation into considerations, since they are based on
the ranking of the probabilities predicted for all labels. Because our methods are
intended to get a more accurate probability for each label by ﬁnding more strong
labels dependencies, thus for each label, it should be predicted more accurately
and the true labels should be given greater possibilities. Therefore, we expect
that our method could gain better performance under Hamming loss and ranking
loss, since Hamming loss examines the predictions of all labels independently and
ranking loss focuses on whether the true labels are given greater probabilities
than other labels. For other 3 criteria, our method may be eﬀective, but they
are not what our method optimize for.

5.3 Algorithms and Settings

The algorithms used for comparison are listed in table 2 with their abbreviations
respectively. To examine the eﬀect of label dependency, BR algorithm is used as
a baseline since it does not consider the label dependency, then we compare our
proposed LDTS and ELDTS with CC and ECC methods to see their eﬀectiveness
after eliminating weak dependencies. RAkELd and RAkEL are also used for
comparison as other ways of learning label dependency.

The experiments are divided into two parts, according to the two purposes
mentioned in section 4. One part is on the ﬁve aforementioned datasets without
label hierarchy to see whether our method can ﬁnd more strong dependency and
thus gain better performance, the other part is on the dataset rcv1v2, a dataset
in which there exists a tree hierarchy of labels, to see its performance when a
tree structure is learned. Since only one tree exists in rcv1v2, we do not use the
ensemble method on it.

Table 2. The algorithms used for comparison

Compared with LDTS
BR: Binary relevance method
CC: Classiﬁer chain
RAkELd: Random disjoint k label subsets RAkEL: Random k label subsets

Compared with ELDTS
EBR: Ensemble of BR
ECC: Ensemble of CC

All algorithms are implemented on the Mulan framework [26], an open plat-
form for multi-label learning. The parameter values are chosen as those used in
the paper [9]. For the RAkEL, we set the k = m
2 . For the RAkELd, we set the

Learning Tree Structure of Label Dependency for Multi-label Learning

167

k = 3. For the ensemble algorithms, the number of iterations is 10, and for each
iteration, 67% of the original dataset is sampled with replacement to form the
training dataset. SMO, a support vector machine classiﬁer implemented in Weka
[27], is used as the base classiﬁer. All algorithms are executed 5 times using 10-
fold cross validation on all datasets expect rcv1v2 with diﬀerent random seeds
1, 3, 5, 7, 11, respectively, and the ﬁnal results are the averaged values. For the
rcv1v2, only 100 attributes are kept, and 10-fold cross validation is used only
one time since it has a huge amount of instances and attributes.

5.4 Experimental Results and Analysis

Based on above setup, we get the ﬁnal results and the following tables display
them in detail. The bold result indicates the best one, and result with the black
dot “•” indicates our proposed algorithm is better than itself indicated algorithm.

Table 3. The hamming loss of each algorithm on the datasets

Dataset
emotions
enron
medical
scene
yeast

BM
CC
0.1939 0.2159•
0.0601 0.0606•
0.0101• 0.0098
0.1037
0.1046
0.1990 0.2115•

LDTS
0.2038
0.0602
0.0099
0.1056
0.2060

EBM
0.1947•
0.0540•
0.0098•
0.1020•
0.1991 0.2106•

ELDTS RAkEL
ECC
0.2108• 0.1932 0.2283•
0.0536• 0.0535 0.0541•
0.0096• 0.0095 0.0102•
0.0997• 0.0968 0.1047•
0.2371•

0.2034

Table 4. The accuracy of each algorithm on the datasets

LDTS

CC
EBM
0.5336• 0.5727 0.5226•
0.4083• 0.4085 0.4370•

Dataset
emotions
enron
medical
scene
yeast

BM
0.5199•
0.4058•
0.7580• 0.7750
0.5999• 0.6949
0.5003•

0.7670
0.6496

0.7655• 0.7799
0.6137• 0.7020

0.4879• 0.5073 0.5031•

ELDTS RAkEL
ECC
0.5451• 0.5808 0.5119•
0.4110• 0.4396 0.4063•
0.7686•
0.6281•
0.4929• 0.5249 0.4692•

0.7759
0.6783

As shown from table 3 to table 7, our proposed LDTS method performs better
on the majority of datasets evaluated by the criteria. It is superior to CC on
3 datasets under the Hamming loss, accuracy, one-error, and ranking loss, but
inferior under other metrics. LDTS algorithm does not improve all the time or
the improvement is not signiﬁcant. The possible reason is that although LDTS
algorithm could learn the dependency further, it still ignore lots of useful de-
pendency since it only considers unidirectional dependency of pairwise labels,
especially when the labels are dependent mutually. We expect that ensemble
learning that combines diﬀerent trees can further utilize the label dependency ,
since the dependent direction between pairwise labels is changed in a diﬀerent
tree by choosing a diﬀerent root.

To validate above assumption, we also use ensemble learning on these algo-
rithms and compare them each other. Also shown from table 3 to table 7, our

168

B. Fu et al.

proposed ELDTS has a substantial improvement after the employing ensemble
learning. Under all 5 criteria, ELDTS is superior to ECC on most datasets. These
results show that through learning multiple label trees by ensemble learning, the
inﬂuence of the root label’s randomness could be mitigated, and the label de-
pendencies are learned more eﬀectively. Although ECC algorithm also changed
the order of labels, it could not make sure that only the strong dependency is
considered each time, since it’s totally random when determining the dependent
relationship within labels.

It can be observed that the proposed algorithms do not perform well on two
datasets medical and scene. Seen from the table 1, these two datasets have very
small label cardinality, which means there tend to be less label dependency in
them and overemphasis on label dependency may not be preferable. Thus the
algorithms we propose are more suitable for the datasets that there are indeed
strong label dependency in them.

The results gotten on rcv1v2, a dataset with tree structure of labels, are also
given in table 8. We can clearly see that our proposed LDTS method is superior
under Hamming loss and ranking loss, the criteria it optimize for. Therefore,
it has been proven that our method is more eﬀective when there is complex
dependency within labels.

Table 5. The one-error of each algorithm on the datasets

Dataset
emotions
enron
medical
scene
yeast

Dataset
emotions
enron
medical
scene
yeast

LDTS
0.3103

ELDTS RAkEL
ECC
CC
BM
EBM
0.2989 0.3700•
0.2534 0.3181•
0.3096•
0.2563
0.4912•
0.4938• 0.4897 0.3078•
0.3071• 0.3054 0.3210•
0.2029• 0.1847
0.1407•
0.1415• 0.1397 0.1634•
0.2609• 0.2485 0.2777•
0.2553•
0.3389• 0.2793
0.2557 0.2559•
0.2557•
0.2583• 0.2551 0.2895•

0.1932
0.3132
0.2557

Table 6. The rank loss of each algorithm on the datasets

LDTS

EBM
BM
CC
0.2778•
0.2876• 0.2334 0.2169•
0.2915 0.2929•
0.1648•
0.0952• 0.0926
0.0537• 0.0516
0.1718• 0.1576
0.1162•
0.3351• 0.3181 0.2739•
0.3188•

ELDTS RAkEL
ECC
0.2317• 0.1743 0.1964•
0.1640• 0.1622 0.1784•
0.0598•
0.1115• 0.0945 0.1110•
0.2771• 0.2273 0.2300•

0.2925
0.0932
0.1664

0.0518

Table 7. The average precision of each algorithm on the datasets

Dataset
emotions
enron
medical
scene
yeast

LDTS

EBM
BM
CC
0.7384•
0.7159• 0.7634 0.7814•
0.4682• 0.4702
0.6284•
0.7977• 0.8115
0.8672• 0.8710
0.8353•
0.7752• 0.8048
0.6611• 0.6728 0.7003•
0.6697•

ELDTS RAkEL
ECC
0.7573• 0.8040 0.7734•
0.6287• 0.6314 0.6011•
0.8524•
0.8351• 0.8479 0.8285•
0.6975• 0.7253 0.7048•

0.4693
0.8066
0.7881

0.8707

Learning Tree Structure of Label Dependency for Multi-label Learning

169

Table 8. The performance of algorithms on dataset rcv1v2

criterion
H-Loss
Accuracy
One-Error
R-Loss
AvePrec

BM
0.0235
0.1810•
0.7638•
0.3560•
0.2537•

CC
0.0294•
0.2529
0.7065
0.3508•
0.3085

LDTS
0.0235
0.2237
0.7120
0.3381
0.2940

RAkELd
0.0237•
0.1783•
0.9538•
0.4590•
0.1001•

6 Conclusion
In this paper, one kind of novel approaches are proposed to exploit the label depen-
dency. Speciﬁcally, the dependency degree of pairwise labels is calculated ﬁrstly
and then a tree is build to represent the dependency structure of labels. The meth-
ods assume that the dependencies only exist between each label and its ancestor
labels, resulting in reducing the inﬂuence of weak dependency. At the same time,
they also generalize the label dependency into a tree model. Furthermore, we utilize
ensemble learning to learn and aggregate multiple label trees to reﬂect the labels
dependencies fully. The experimental results show that the algorithms we proposed
perform better, especially after boosted by the ensemble learning.

One potential problem is that using mutual information to measure the de-
pendency will give equal values to both of the labels, which assumes that the
dependency for pairwise labels is mutual and equal for each other. However, the
label dependency could be directed possibly and this assumption is often vio-
lated in reality. Hence how to measure the directed label dependency should be
one of the next directions. Additionally, how to generalize the tree structure of
labels further to graph or forest structure is another issue in the future work.

References

1. Cheng, W., Hullermeier, E.: Combining Instance-Based Learning and Logistic Re-

gression for Multilabel Classiﬁcation. Machine Learning 76(2-3), 211–225 (2009)

2. Tsoumakas, G., Katakis, I., Vlahavas, I.: Mining Multi-label Data. In: Oded, M.,
Lior, R. (eds.) Data Mining and Knowledge Discovery Handbook, pp. 667–685.
Springer, New York (2010)

3. McCallum, A.K.: Multi-label Text Classiﬁcation with a Mixture Model Trained by

EM. In: Proceedings of AAAI 1999 Workshop on Text Learning (1999)

4. Schapire, R.E., Singer, Y.: Boostexter: a Boosting-Based System for Text Catego-

rization. Machine Learning 39(2-3), 135–168 (2000)

5. Clare, A.J., King, R.D.: Knowledge Discovery in Multi-label Phenotype Data. In:
Siebes, A., De Raedt, L. (eds.) PKDD 2001. LNCS (LNAI), vol. 2168, pp. 42–53.
Springer, Heidelberg (2001)

6. Thabtah, F.A., Cowling, P., Peng, Y.: MMAC: a New Multi-class, Multi-label
Associative Classiﬁcation Approach. In: Proceedings of the 4th International Con-
ference on Data Mining, pp. 217–224 (2004)

7. Zhang, M., Zhou, Z.: ML-KNN: A Lazy Learning Approach to Multi-label Learn-

ing. Pattern Recognition 7(40), 2038–2048 (2007)

8. Read, J.: Multi-label Classiﬁcation using Ensembles of Pruned Sets. In: Proceed-
ings of the IEEE International Conference on Data Mining, pp. 995–1000. IEEE
Computer Society, Washington, DC (2008)

170

B. Fu et al.

9. Read, J., Pfahringer, B., Holmes, G., Frank, E.: Classiﬁer Chains for Multi-label Classi-
ﬁcation. In: Buntine, W., Grobelnik, M., Mladeni´c, D., Shawe-Taylor, J. (eds.) ECML
PKDD 2009, Part II. LNCS, vol. 5782, pp. 254–269. Springer, Heidelberg (2009)

10. Dembczynski, K., Cheng, W., Hullermeier, E.: Bayes Optimal Multilabel Classiﬁ-
cation via Probabilistic Classiﬁer Chains. In: Proceedings of the 27th International
Conference on Machine Learning, pp. 279–286. Omnipress (2010)

11. Zhang, M., Zhang, K.: Multi-label Learning by Exploiting Label Dependency. In:
Proceedings of the 16th ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining, pp. 999–1000. ACM Press, Washington, DC (2010)

12. Zhang, Y., Zhou, Z.: Multi-label Dimensionality Reduction via Dependence Maxi-
mization. ACM Transactions on Knowledge Discovery from Data 4(3), 1–21 (2010)
13. Boutell, M.R., Luo, J., Shen, X.: Learning Multi-label Scene Classiﬁcation. Pattern

Recognition 37(9), 1757–1771 (2004)

14. Tsoumakas, G., Katakis, I., Vlahavas, I.: Eﬀective and Eﬃcient Multilabel Classiﬁ-
cation in Domains with Large Number of Labels. In: Proceedings of ECML/PKDD
2008 Workshop on Mining Multidimensional Data, pp. 30–44 (2008)

15. Hullermeier, E., Furnkranz, J., Cheng, W.: Label Ranking by Learning Pairwise

Preferences. Artiﬁcial Intelligence 172(16-17), 1897–1916 (2008)

16. Furnkranz, J., Hullermeier, E., Mencia, E.L.: Multilabel Classiﬁcation via Cali-

brated Label Ranking. Machine Learning 2(73), 133–153 (2008)

17. Madjarov, G., Gjorgjevikj, D., Dzeroski, S.: Two Stage Architecture for Multi-label

learning. Pattern Recognition 45(3), 1019–1034 (2011)

18. Tsoumakas, G., Katakis, I., Vlahavas, I.: Random k-labelsets for Multi-label Classi-
ﬁcation. IEEE Transactions On Knowledge and Data Engineering 23(7), 1079–1089
(2011)

19. Tsoumakas, G., Dimou, A., Spyromitros, E.: Correlation-Based Pruning of
Stacked Binary Relevance Models for Multi-Label Learning. In: Proceeding of
ECML/PKDD 2009 Workshop on Learning from Multi-Label Data, Bled, Slovenia,
pp. 101–116 (2009)

20. Gaag, L., Waal, P.: Multi-dimensional Bayesian Network Classiﬁers. In: Third Eu-

ropean Workshop on Probabilistic Graphical Models, pp. 107–114 (2006)

21. Bielza, C., Li, G., Larranage, P.: Multi-dimensional Classiﬁcation with Bayesian
Networks. International Journal of Approximate Reasoning 52(6), 705–727 (2011)
22. Guo, Y., Gu, S.: Multi-label Classiﬁcation using Conditional Dependency Net-
works. In: Proceedings of the 22nd International Joint Conference on Artiﬁcial
Intelligence, pp. 1300–1305 (2011)

23. Ghamrawi, N., McCallum, A.K.: Collective Multi-label Classiﬁcation. In: Proceed-
ings of the 2005 ACM Conference on Information and Knowledge Management,
pp. 195–200 (2005)

24. Dembczynski, K., Waegeman, W., Cheng, W.: On Label Dependence in Multi-label
Classiﬁcation. In: Proceedings of the 2nd International Workshop on Learning From
Multi-label Data, pp. 5–12 (2010)

25. Chow, C.K., Liu, C.N.: Approximating Discrete Probability Distributions with De-
pendency Trees. IEEE Transactions on Information Theory 14(3), 462–467 (1968)
26. Tsoumakas, G., Spyromitros-Xiouﬁs, E., Vilcek, J., Vlahavas, I.: Mulan: A Java
Library for Multi-Label Learning. Journal of Machine Learning Research 12, 2411–
2414 (2011)

27. Witten, I., Frank, E.: Data Mining: Practical Machine Learning Tools and Tech-

niques with Java Implementations. Morgan Kaufmann, San Francisco (2000)


