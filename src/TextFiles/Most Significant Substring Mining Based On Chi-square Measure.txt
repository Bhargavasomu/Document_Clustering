Most Signiﬁcant Substring Mining Based

on Chi-square Measure

Sourav Dutta and Arnab Bhattacharya

Department of Computer Science and Engineering, Indian Institute of Technology,

Kanpur, India

{sdutta,arnabb}@iitk.ac.in

Abstract. Given the vast reservoirs of sequence data stored worldwide,
eﬃcient mining of string databases such as intrusion detection systems,
player statistics, texts, proteins, etc. has emerged as a great challenge.
Searching for an unusual pattern within long strings of data has emerged
as a requirement for diverse applications. Given a string, the problem
then is to identify the substrings that diﬀers the most from the expected
or normal behavior, i.e., the substrings that are statistically signiﬁcant
(i.e., less likely to occur due to chance alone). To this end, we use the
chi-square measure and propose two heuristics for retrieving the top-k
substrings with the largest chi-square measure. We show that the al-
gorithms outperform other competing algorithms in the runtime, while
maintaining a high approximation ratio of more than 0.96.

1 Motivation

A recent attractive area of research has been detecting statistically relevant se-
quences or mining interesting patterns from a given string [1,2]. Given an input
string composed of symbols from an alphabet set with a probability distribu-
tion deﬁning the chance of occurrence of the symbols we would like to ﬁnd the
portions of the string which deviate from the expected behavior and can thus
be potent sources of study for hidden pattern and information. An automated
monitoring system such as a cluster of sensors sensing the temperature of the
surrounding environment for ﬁre alert, or a connection server sniﬃng the net-
work for possible intrusion detection provides a few of the applications where
such pattern detection is essential. Other applications involve text analysis of
e-mails and blogs to predict terrorist activities or judging prevalent public sen-
timents and studying trends of the stock market. Similarly, another interesting
ﬁeld of application can be the identiﬁcation of good and bad career patches of a
sports icon. For example, given the runs scored by Sachin Tendulkar in each in-
nings of his one-day international cricket career, we may be interested in ﬁnding
his in-form and oﬀ-form patches.

A statistical model is used to determine the relationship of an experimental
or observed outcome with the factors aﬀecting the system, or to establish the
occurrence as pure chance. An observation is said to be statistically signiﬁcant

M.J. Zaki et al. (Eds.): PAKDD 2010, Part I, LNAI 6118, pp. 319–327, 2010.
c(cid:2) Springer-Verlag Berlin Heidelberg 2010

320

S. Dutta and A. Bhattacharya

if its presence cannot be attributed to randomness alone. The degree of unique-
ness of a pattern can be captured by several measures including the p-value and
z-score [3,4]. For evaluating the signiﬁcance of a substring, it has been shown
that the p-value provides a more precise conclusion as compared to that by the
z-score [1]. However, computing the p-value entails enumerating all the possible
outcomes, which can be exponential in number, thus rendering it impractical.
So, heuristics based on branch-and-bound techniques have been proposed [5].
The log–likelihood ratio G2 provides such a measure based on the extent of devi-
ation of the substring from its expected nature [6]. For multinomial models, the
χ2 statistic approximates the importance of a string more closely than the G2
statistic [6,7]. Existing systems for intrusion detection use multivariate process
control techniques such as Hotelling’s T 2 measure [8], which is again computa-
tionally intensive. The chi-square measure, on the other hand, provides an easy
way to closely approximate the p-value of a sequence [6]. To simplify compu-
tations, the χ2 measure, unlike Hotelling’s method, does not consider multiple
variable relationship, but is as eﬀective in identifying “abnormal” patterns [2].
Thus, in this paper, we use the Pearson’s χ2 statistic as a measure of the p-value
of a substring [6,7]. The χ2 distribution is characterized by the degrees of free-
dom, which in the case of a string, is the size of the alphabet set minus one. The
larger the χ2 value of a string, the smaller is its p-value, and hence more is its
deviation from the expected behavior.

Formally, given a string S composed of symbols from the alphabet set Σ with
a given probability distribution P modeling the chance of occurrence of each
symbol, the problem is to identify and extract the top-k substrings having the
maximum chi-square value or the largest deviation within the framework of p-
value measure for the given probability distribution of the symbols. Na¨ıvely we
can compute the χ2 value of all the substrings present in S and determine the
top-k substrings in O(l2) time for a string of length l. We propose to extract
such substrings more eﬃciently.
Related Work: The blocking algorithm and its heap variant [9] reduce the
practical running time for ﬁnding such statistically important substrings, but
suﬀers from a high worst-case running time. The number of blocks found by this
strategy increases with the size of the alphabet set and also when the proba-
bilities of the occurrence of the symbols are nearly similar. In such scenarios,
the number of blocks formed can be almost equal to the length of the given
string, thereby degenerating the algorithm to that of the na¨ıve one. The heap
variant requires a high storage space for maintaining the separate max and min
heap structures and also manipulates a large number of pointers. Further, the
algorithm cannot handle top-k queries. In time-series databases, categorizing a
pattern as surprising based on its frequency of occurrence and mining it eﬃ-
ciently using suﬃx trees has been proposed in [10]. However, the χ2 measure,
as discussed earlier, seems to provides a better parameter for judging whether a
pattern is indeed interesting.

In this paper, we propose two algorithms, All-Pair Reﬁned Local Maxima
Search (ARLM) and Approximate Greedy Maximum Maxima Search (AGMM)

Most Signiﬁcant Substring Mining Based on Chi-square Measure

321

to eﬃciently search and identify interesting patterns within a string. We show
that the running time of the algorithms are better than the existing algorithms
with lesser space requirements. The procedures can also be easily extended to
work in streaming environments. ARLM, a quadratic algorithm in the number
of local maxima found in the input string, and AGMM, a linear time algorithm,
both use the presence of local maxima in the string. We show that the approx-
imation ratio of the reported results to the optimal is 0.96 or more. Empirical
results emphasize that the algorithms work eﬃciently.

The outline of the paper is as follows: Section 2 formulates the properties
and behavior of strings under the χ2 measure. Section 3 describes the two pro-
posed algorithms. Section 4 discusses the experimental results, before Section 5
concludes the paper.

2 Deﬁnition and Properties

Let S = s1s2 . . . sl be a given string of length l composed of symbols si from
the alphabet set Σ = {σ1, σ2, . . . , σm}, where |Σ| = m. To each symbol σi ∈
Σ is associated a pσi (henceforth represented as pi), denoting the probability
i=1 pi = 1. Let θσi,S (henceforth
of occurrence of that symbol, such that
represented as θi,S) denote the observed number of symbol σi in string S.
The chi-square value of a string S ∈ Σ

∗ of length l is computed as

(cid:2)m

S =
χ2

m(cid:3)

(pil − θi,S)2

i=1

pil

(1)

We now state certain observations and lemmas, the formal proofs of which are
in the full version of the paper [11].

Observation 1. Under string concatenation operation (.), for two arbitrary
strings S and T drawn from the same alphabet set and probability distribution
of the symbols (henceforth referred to as the same universe), the χ2 measure of
the concatenated string is commutative, i.e., χ2

S.T = χ2

T.S.

Lemma 1. The χ2 value of the concatenation of two strings drawn from the
same universe is less than or equal to the sum of the χ2 values of the individual
strings.

Lemma 2. The χ2 value of a string composed of only a single type of symbol
increases with the length of the string.

We next deﬁne the term local maxima and describe the procedure for ﬁnding
such a local maxima within a given string.

Deﬁnition 1 (Local maxima). The local maxima is a substring, such that
while traversing through it, the inclusion of the next symbol does not decrease
the χ2 value of the resultant sequence.

322

S. Dutta and A. Bhattacharya

s1s2...sn

s1s2...sn+1

≥

s1s2

≤ χ2

s1s2...sn.

≥ χ2

s1s2...sn−1 and χ2

Let s1s2 . . . sn be a local maxima of length n. Then the following holds: χ2
s1 , . . . , χ2
χ2
The process of ﬁnding the local maxima involves a single scan of the entire
string. We consider the ﬁrst local maxima to start at the beginning of the string.
We keep appending the next symbol to the current substring until there is a
decrease in the chi-square value of the new substring. The present substring
is then considered to be a local maxima ending at the previous position. The
last symbol appended that decreased the chi-square value signiﬁes the start of
the next local maxima. Thus, the running time is O(l) time for a string of
length l.
Lemma 3. The expected number of local maxima in a string of length l is O(l).

However, practically the number of local maxima is less than l, as all adjacent
positions of dissimilar symbols may not correspond to a local maxima boundary.
We further optimize the local maxima ﬁnding procedure by initially blocking
the string S, as described in [9], and then searching for the local maxima. A
contiguous sequence of the same symbol is considered to be a block, and is
replaced by a single instance of that symbol representing the block. If a symbol
is selected, the entire block associated with it is considered to be selected. The
next lemma shows that a local maxima cannot end in the middle of a block.
Lemma 4. If the insertion of a symbol of a block increases the chi-squared value
of the current substring, then the chi-squared value will be maximized if the entire
block is inserted.

3 Algorithms

Based on the observations, lemmas and local maxima extracting procedure dis-
cussed previously, in this section we explain the All-Pair Reﬁned Local Maxima
(ARLM) and Approximate Greedy Maximum Maxima (AGMM) search algo-
rithms for mining the most signiﬁcant substring based on the chi-square value.

3.1 All-Pair Reﬁned Local Maxima Search (ARLM)

Given a string S of length l and composed of symbols from the alphabet set Σ,
we ﬁrst extract all the local maxima present in it in linear time, as described
earlier. With S partitioned into its local maxima, the global maxima can either
start from the beginning of a local maxima or from a position within it. Thus, it
can contain an entire local maxima, a suﬃx of it or itself be a substring of a local
maxima. It is thus intuitive that the global maxima should begin at a position
such that the subsequent sequence of characters oﬀer the maximum chi-square
value. Otherwise, we could keep adding to or deleting symbols from the front of
such a substring and will still be able to increase its χ2 value. Based on this, the
ARLM heuristic ﬁnds within each local maxima the suﬃx having the maximum

Most Signiﬁcant Substring Mining Based on Chi-square Measure

323

chi-square value, and considers the position of the suﬃx as a potential starting
point for the global maxima.

Let xyz be a local maxima, where x is a preﬁx, y is a single symbol at position
ψ, and z is the remaining suﬃx. For a local maxima the chi-square value of all
its suﬃces is computed. The starting position of the suﬃx having the maximum
chi-square value provides the position ψ for the component y, i.e, yz will be the
suﬃx of xyz having the maximum chi-square value.

For each local maxima, the position ψ is inserted into a list α. If no such proper
suﬃx exists for the local maxima, the starting position of the local maxima xyz
is inserted in the list. After populating α with position entries of y for each of
the local maxima of the input string, the list contains the prospective positions
from where the global maxima may start.

β list is similarly ﬁlled with positions y

The string S is now reversed and the same algorithm is re-run. This time, the
(cid:4) relative to the beginning of the string.
For simplicity and eﬃciency of operations, we maintain a table C having m
rows and l columns, where m is the cardinality of the alphabet set. The rows
of the table contain the observed number of each associated symbols present in
the length of the string denoted by the column. The observed count of a symbol
between two given positions of the string can be easily computed from this table
in O(1) time.
Given the two α and β lists, we now ﬁnd the chi-square value of substrings
from position g ∈ α to h ∈ β, and g ≤ h. The substring having the maximum
value is reported as the global maxima. While computing the chi-square values
for all the pairs of positions in the two list, the top-k substrings can be main-
tained using a heap of k elements.

Conjecture 1. The starting position of the global maxima is always present in
the α list.

Corollary 1. From the above conjecture, it follows that the ending position of
the global maxima is also present in the β list.

Finding all the local maxima in the string requires a single pass, which takes
O(l) time for a string of length l. Let the number of local maxima in the string be
d. Finding the maximum valued suﬃx for each local maxima using the C table,
requires another pass of each of the local maxima, and thus also takes O(l) time.
Since, each local maximum contributes one position to the lists, the number of
elements in both the lists is d. We then evaluate the substrings formed by each
possible pair of start and end positions, which takes O(d2). So, in total, the time
complexity of the algorithm is O(l + d2).

3.2 Approximate Greedy Maximum Maxima Search (AGMM)

In this section, we propose a linear time greedy algorithm for ﬁnding the maxi-
mum substring, which is linear in the size of the input string S. We extract all
the local maxima of the input string and its reverse, and populate the α and

324

S. Dutta and A. Bhattacharya

β lists as discussed previously. We identify the local maxima suﬃx max hav-
ing the maximum chi-square value among all the local maxima present in the
string. AGMM assumes this local maxima suﬃx to be completely present within
the global maxima. We then ﬁnd a position g ∈ α for which the new substring
starting at g and ending with max as a suﬃx has the maximum χ2 value, for
all g. Using this reconstructed substring, we ﬁnd a position h ∈ β such that
the new string starting at the selected position g and ending at position h has
the maximum chi-square measure for all positions of h. This new substring is
reported by the algorithm as the global maxima.

The intuition here is that the global maxima will contain the maximum of the
local maxima to maximize its value. Although this is a heuristic, the assumption
is justiﬁed by empirical results in Section 4, which shows that we always obtain
an approximation ratio of 0.96 or more.

Using the C table, AGMM takes O(d) time, where d is the number of local
maxima found. The total running time of the algorithm is thus O(d + l). Thus,
being a linear time algorithm, it provides a order of increase in the runtime as
compared to the other algorithms.

4 Experiments

To assess the performance of the two proposed heuristics ARLM and AGMM,
we conduct tests on multiple datasets and compare it with the results of the
na¨ıve algorithm and the blocking algorithm [9]. The heap variant of the blocking
algorithm is not eﬃcient as it has a higher running time and uses more memory,
and hence has not been reported. We compare the results based on the following
parameters: (i) search time for top-k queries, (ii) number of local maxima found,
and (iii) accuracy of the result based on the ratio of the optimal χ2 value to that
returned by the algorithms.1

Table 1. Results of (a) Sachin’s records. (b) Uniform dataset

Form Date Avg.

Runs scored

22/04/98

143,134,33,18,100*

Best
patch 13/11/98

to

84.31

65,53,17,128,77
127*,29,2,141,8,3
118*,18,11,124*

Worst 15/03/92
patch

to

21.89

19/12/92

14,39,15
10,22,21
32,23,21

(a)

Parameters Variable Blocks Local maxima

m=5,
k=1

l=104,
k=1

l=103
l=104
l=105
m=5
m=25
m=50

831
7821
77869
7821
8104
8704

(b)

742
6740
66771
6740
7203
7993

1 The experiments were conducted on a 2.1GHz desktop PC with 2GB of memory

using C++ in Linux.

Most Signiﬁcant Substring Mining Based on Chi-square Measure

325

Sachin’s dataset (l = 425, m = 5)

Sachin’s dataset (l = 425, m = 5)

)
c
e
s
(
 
e
m

i
t
 

h
c
r
a
e
s
 
k
-
p
o
T

 0.7

 0.6

 0.5

 0.4

 0.3

 0.2

 0.1

 0

Naive
Blocking
ARLM
AGMM

 5

 10  15  20  25  30  35  40  45  50

Value of k for top-k search

)
y
c
a
r
u
c
c
A

(
 

o

i
t

a
R
n
o

 

i
t

i

a
m
x
o
r
p
p
A

 1
 0.99
 0.98
 0.97
 0.96
 0.95
 0.94
 0.93
 0.92
 0.91
 0.9

ARLM
AGMM

 5

 10  15  20  25  30  35  40  45  50

Value of k for top-k search

(a)

(b)

Fig. 1. (a) Time for ﬁnding the top-k query in Sachin’s run dataset. (b) Approximation
ratio of the top-k query in Sachin’s run dataset.

4.1 Real Datasets

We used the innings-by-innings runs scored by Sachin Tendulkar in one-day
internationals (ODI)2 as a real dataset. We quantized the runs scored into 5
symbols as follows: 0-9 is represented by A, 10-24 by B, 25-49 by C, 50-99 by D,
and 100+ by E. The actual probability of occurrences of the diﬀerent symbols
were 0.28, 0.18, 0.22, 0.22 and 0.10 respectively for the ﬁve symbols, and the
overall average is 45.5 runs per innings. Table 1(a) summarizes the results. We
ﬁnd that during his best patch he had scored 8 centuries and 3 half-centuries
in 20 innings with an average of 84.31, while in the oﬀ-form period he had an
average of 21.89 in 9 innings without any score of above 40.

Figure 1(a) show the times taken by the diﬀerent algorithms for diﬀerent
values of k. The AGMM algorithm requires the least running time as compared to
the other procedures, while the ARLM is faster than the na¨ıve and the blocking
ones. The number of local maxima found was 281, which is lesser than 319, the
number of blocks constructed by the blocking algorithm. So, the heuristic prunes
the search space more eﬃciently. Figure 1(b) plots the approximation factor for
the heuristics. The accuracy of the ARLM heuristic is found to be 100% for
the top-1 query, i.e., it provides the correct result validating the conjecture we
proposed in Section 3. As the value of k increases we ﬁnd an increase in the
approximation ratio of both the heuristics.

4.2 Synthetic Datasets

We now benchmark the ARLM and AGMM heuristics against datasets gener-
ated randomly using a uniform distribution. To simulate the deviations from the
expected characteristics as observed in real applications, we perturb the random
data with chunks of data generated from a geometric distribution with param-
eter p = 0.3. The parameters that aﬀect the performance of the heuristics are:
(i) length of the input string, l, (ii) size of the alphabet set, m, and (iii) num-
ber of top-k values. For diﬀerent values of these parameters we compare our
2 http://stats.cricinfo.com/ci/engine/player/35320.html?class=2;template=results;

type=batting;view=innings

326

S. Dutta and A. Bhattacharya

Random dataset (m = 5, k = 1)

Random datasets (l = 104, k = 1)

)
c
e
s
(
 

i

 

e
m
T
h
c
r
a
e
S

 2500

 2000

 1500

 1000

 500

 0

Naive
Blocking
ARLM
AGMM

 10  20  30  40  50  60  70  80  90  100

Length of the string (l) (x103)

(a)

)
c
e
s
(
 
e
m

i
t
 

h
c
r
a
e
S

 160
 140
 120
 100
 80
 60
 40
 20
 0

Naive
Blocking
ARLM
AGMM

 10  20  30  40  50  60  70  80  90  100

Size of alphabet set (m)

(b)

Fig. 2. (a) Eﬀect of length on search time. (b) Eﬀect of size of alphabet on search time.

Random dataset (l = 104, m = 5)

Random dataset (l = 104, m = 2, k = 1)

 50

 40

 30

 20

 10

)
c
e
s
(
 
e
m

i
t
 
h
c
r
a
e
S

 0

 0

Naive
Blocking
ARLM
AGMM

 10

 20

 30

 40

 50

Value of k for top-k query

(a)

)
c
e
s
(
 
e
m

i
t
 
h
c
r
a
e
S

 20

 15

 10

 5

 0

Naive
Blocking
ARLM
AGMM

 0

 0.1

 0.2

 0.3

 0.4

 0.5

Probability of occurrence of one symbol

(b)

Fig. 3. (a) Eﬀect of value of k for top-k query on search time. (b) Eﬀect of probability
in two symbol string on search time.

algorithms with the existing ones on the basis of (a) time to search, (b) approx-
imation ratio of the results, and (c) the number of blocks evaluated in case of
blocking algorithm to the number of local maxima found by our algorithm.

Fig 2(a) shows that with the increase in the length of the input string l, the
time taken for searching the top-k queries increases. The number of blocks or
local maxima increases with the size of the string and, hence, the time increases.
The time increases more or less quadratically for ARLM and the other existing
algorithms according to the analysis shown in Section 3.1. ARLM takes less
running time than the other techniques, as the number of local maxima found is
less than the number of blocks found by the blocking algorithm (see Table 1(b)).
Hence, it provides better pruning of the search space and is faster. On the other
hand, AGMM being a linear time heuristic, runs an order of time faster than the
others. We also ﬁnd that the accuracy of the top-k results reported by AGMM
show an improvement with the increase in the string length (graph not shown).
The approximation factor for ARLM is 1 for the top-1 query in all the cases
tested, while for other top-k queries and for AGMM it is always above 0.96.

The time taken for searching the top-k query as well as the number of blocks
formed increases with the size of the alphabet m (Table 1(b) and Fig 2(b)). As
m increases, the number of blocks increases as the probability of the same sym-
bol occurring contiguously falls oﬀ. A local maxima can only end at positions
containing adjacent dissimilar symbols. So the number of local maxima found

Most Signiﬁcant Substring Mining Based on Chi-square Measure

327

increases as well. There seems to be no appreciable eﬀect of m on the approxi-
mation ratio of the results returned by the algorithms. We tested with varying
values of m with l = 104 and k = 2, and found the ratio to be 1 in all cases.

Fig 3(b) shows the eﬀect of varying probability of occurrence of one of the
symbols in a string composed of two symbols only. The approximation ratio
remained 1 for both heuristics for the top-1 query.

We next show the scalability of our algorithms by conducting experiments for
varying values of k for top-k substrings. Fig 3(a) shows that search time increases
with the increase in the value of k. This is expected as more computations are
performed. The accuracy of the results for the heuristics increases with k. For
k = 2, it is 0.96, and increases up to 1 when k becomes more than 10.

5 Conclusions

In this paper, we proposed the problem of ﬁnding top-k substrings within a
string with the maximum chi-square value for mining interesting patterns. The
chi-square value represents the deviation of the observed from the expected.
We used the concept of local maxima and proposed two eﬃcient heuristics that
run in time quadratic and linear in the number of local maxima. Experiments
showed that the heuristics are faster than the existing algorithms, are scalable,
and return results that have an approximation ratio of more than 0.96.

References

1. Denise, A., Regnier, M., Vandenbogaert, M.: Accessing the statistical signiﬁcance of
overrepresented oligonucleotides. In: Work. Alg. Bioinf. (WABI), pp. 85–97 (2001)
2. Ye, N., Chen, Q.: An anomaly detection technique based on chi-square statistics for
detecting intrusions into information systems. Quality and Reliability Engineering
International 17(2), 105–112 (2001)

3. Rahmann, S.: Dynamic programming algorithms for two statistical problems in

computational biology. In: Work. Alg. Bioinf. (WABI), pp. 151–164 (2003)

4. Regnier, M., Vandenbogaert, M.: Comparison of statistical signiﬁcance criteria. J.

Bioinformatics and Computational Biology 4(2), 537–551 (2006)

5. Bejerano, G., Friedman, N., Tishby, N.: Eﬃcient exact p-value computation for
small sample, sparse and surprisingly categorical data. J. Comp. Bio. 11(5), 867–
886 (2004)

6. Read, T., Cressie, N.: Goodness-of-ﬁt statistics for discrete multivariate data.

Springer, Heidelberg (1988)

7. Read, T., Cressie, N.: Pearson’s χ2 and the likelihood ratio statistic G2: a compar-

ative review. International Statistical Review 57(1), 19–43 (1989)

8. Hotelling, H.: Multivariate quality control. Techniques of Statistical Analysis 54,

111–184 (1947)

9. Agarwal, S.: On ﬁnding the most statistically signiﬁcant substring using the chi-

square measure. Master’s thesis, Indian Institute of Technology, Kanpur (2009)

10. Keogh, E., Lonardi, S., Chiu, B.: Finding surprising patterns in a time series

database in linear time and space. In: SIGKDD, pp. 550–556 (2002)

11. Dutta, S., Bhattacharya, A.: Mining most signiﬁcant substrings based on the chi-

square measure. arXiv:1002.4315 [cs.DB] (2010)


