Unsupervised Multi-label Text Classiﬁcation

Using a World Knowledge Ontology

Xiaohui Tao1, Yuefeng Li2, Raymond Y.K. Lau3, and Hua Wang1

1 Centre for Systems Biology, University of Southern Queensland, Australia

{xtao,hua.wang}@usq.edu.au

2 Science and Engineering Faculty, Queensland University of Technology, Australia

3 Department of Information Systems, City University of Hong Kong, Hong Kong

y2.li@qut.edu.au

raylau@cityu.edu.hk

Abstract. The development of text classiﬁcation techniques has been
largely promoted in the past decade due to the increasing availability
and widespread use of digital documents. Usually, the performance of
text classiﬁcation relies on the quality of categories and the accuracy of
classiﬁers learned from samples. When training samples are unavailable
or categories are unqualiﬁed, text classiﬁcation performance would be
degraded. In this paper, we propose an unsupervised multi-label text
classiﬁcation method to classify documents using a large set of categories
stored in a world ontology. The approach has been promisingly evaluated
by compared with typical text classiﬁcation methods, using a real-world
document collection and based on the ground truth encoded by human
experts.

1

Introduction

The increasing availability of documents in the past decades has greatly pro-
moted the development of information retrieval and organising systems, such as
search engines and digital libraries. The widespread use of digital documents has
also increased these systems’ accessibility to textual information. A fundamen-
tal theory supporting these information retrieval and organising systems is that
information can be associated with semantically meaningful categories. Such a
theory supports also ontology learning, text categorisation, information ﬁltering,
text mining, and text analysis, etc. Text classiﬁcation aims at associating tex-
tual documents with semantically meaningful categorises, and has been studied
in the past decades, along with the development of information retrieval and
organising systems [11].

Text classiﬁcation is the process of classifying an incoming stream of docu-
ments into predeﬁned categories. Text classiﬁcation usually employs a supervised
learning strategy with the classiﬁers learned from pre-classiﬁed sample docu-
ments. The classiﬁers are then used to classify incoming documents. In terms
of supervised text classiﬁcation, the performance is determined by the accuracy
of pre-classiﬁed training samples and the quality of the categorisation. The ac-
curacy of classiﬁers determines their capability of diﬀerentiating the incoming

P.-N. Tan et al. (Eds.): PAKDD 2012, Part I, LNAI 7301, pp. 480–492, 2012.
c(cid:2) Springer-Verlag Berlin Heidelberg 2012

Unsupervised Multi-label Text Classiﬁcation

481

stream of documents; the descriptive and discriminative capacity of categorisa-
tion reduces noise in classiﬁcation, which is caused by sense ambiguities, sparsity,
and high dimensionality of the documents [7]. Text classiﬁcation performance is
also aﬀected by the topic coverage of categories. An inadequate category may
be assigned to a document if an in-comprehensive set of categories is employed,
because non-adequate categories can be found. The performance of text classiﬁ-
cation relies upon the descriptive and discriminative capacity of categories and
the accuracy of classiﬁers learned from training sets.

However, there exist situations that a qualiﬁed training document set may
not be available (e.g., the “cold start” problem in recommender systems); a set
of categories with in-comprehensive topic coverage may be used for classiﬁca-
tion; sometimes although a set of categories with comprehensive topic coverage
is available, the large number of classes would easily introduce noise in classiﬁ-
cation results [5]. Traditionally, text classiﬁcation models are designed to handle
only single-label problems. However, in some circumstances (e.g., categorizing
documents in library catalogue into multiple subjects), multi-label text clas-
siﬁcation is required and automatic classiﬁcation is necessary, especially when
classifying a very large volume of documents [15]. To deal with these prob-
lems, in this paper we propose an automatic unsupervised text classiﬁcation
approach to classify documents into multiple classes, without the requirement of
pre-classiﬁed sample documents for training classiﬁers. The approach consists of
three modules; pattern mining for document feature extraction; feature-subject
mapping for initial classiﬁcation; knowledge generalisation for optimal classiﬁca-
tion. The method incorporates comprehensive world knowledge stored in a large
ontology and classiﬁes documents into the classes in the ontology without any
pre-classiﬁed training samples available. The world ontology is built from Library
of Congress Subject Headings (LCSH), which represents the natural growth and
distribution of human intellectual work [4]. The subject classes and semantic
relationships in the ontology are investigated and exploited to improve the clas-
siﬁcation results. The proposed method was experimentally evaluated using a
large library catalogue, by compared with typical text classiﬁcation approaches.
The presented work makes three-fold contributions:

– An unsupervised text classiﬁcation method that classiﬁes documents into

multiple classes;

– A knowledge generalisation method to optimise text classiﬁcation by

analysing the semantic relations of categories;

– An exploration of using the LCSH as a world knowledge to facilitate text

classiﬁcation.

The paper is organised as follows. Section 2 discusses the related work; Section 3
introduces the research problem and the the conceptual model of proposed su-
pervised text classiﬁcation method; Section 4 presents the technical detail of the
proposed method. The experiment design is described in Section 5, whereas the
results are discussed in Section 6. Finally, Section 7 makes conclusions.

482

X. Tao et al.

2 Related Work

Unsupervised text classiﬁcation aims to classify documents into the classes with
absence of any labelled training documents. In many occasions the target classes
may not have any labelled training documents available. One particular example
is the “cold start” problem in recommender systems and social tagging. Unsu-
pervised classiﬁcation can automatically learn an annotation model to make
recommendations or label the tags when the products or tags are rare and do
not have any useful information associated. Unsupervised classiﬁcation has been
studied by many groups and many successful models have been proposed. With-
out associated training samples, Yang et al. [16] built a classiﬁcation model for a
target class by analysing the correlating auxiliary classes. Though as similar as
theirs in investigating correlating classes, our work is diﬀerent by exploiting a hi-
erarchical world knowledge ontology for classiﬁcation, instead of only auxiliary
classes. Also exploiting a world knowledge base, Yan et al. [14] examined un-
supervised relation extraction from Wikipedia articles and integrated linguistic
analysis with web frequency information to improve unsupervised classiﬁcation
performance. However, our work has diﬀerent aims from theirs; ours aims to
exploit a world knowledge ontology to help unsupervised classiﬁcation, whereas
Yan et al. [14] aims to extract semantic relations for Wikipedia concepts by using
unsupervised classiﬁcation techniques. Cai et al. [2] and Houle and Grira [6] pro-
posed unsupervised approaches to evaluate and improve the quality of selecting
features. Given a set of data, their work is to ﬁnd a subset containing the most
informative, discriminative features. Though the work presented in this paper
also relies on features selected from documents, the features are further investi-
gated with their referring-to ontological concepts to improve the performance of
classiﬁcation.

Text classiﬁcation models are originally designed to handle only single-label
problems, where each document is classiﬁed into only one class. However, in
many circumstances single-label text classiﬁcation cannot satisfy the demand,
for example, in social network multiple labels may need to be suggested for a
tag [8]. Comparing with the work done by Katakis et al. [8], our work relies on
the semantic content of documents, rather than the meta-data of documents used
in [8]. As similar as the work conducted by Yang et al. [15], our work also targets
on multi-label text classiﬁcation. However, Yang et al. [15]’ work is diﬀerent in
adopting active learning algorithms for multi-label classiﬁcation, whereas ours
exploits concepts and their structure in world knowledge ontologies.

Ontologies have been studied and exploited by many works to facilitate text
classiﬁcation. Gabrilovich and Markovitch [5] enhanced text classiﬁcation by
generating features using domain-speciﬁc and common-sense knowledge in large
ontologies with hundreds of thousands of concepts. Comparing with their work,
our work moves beyond feature discovery and investigates the hierarchical ontol-
ogy structure for knowledge generalisation to improve text classiﬁcation. Camous
et al. [3] also introduced a domain-independent method that uses the Medical
Subject Headings (MeSH) ontology. The method observes the inter-concept rela-
tionships and represents documents by MeSH subjects. Similarly, Camous’ work

Unsupervised Multi-label Text Classiﬁcation

483

considers the semantic relations existing in the ontological concepts. However,
their work focuses on only the medical domain, whereas our approach works on
general areas because exploiting the LCSH, a superior world knowledge ontol-
ogy. Another world ontology commonly used in text classiﬁcation is Wikipedia.
Wang and Domeniconi [13] and Hu et al. [7] derived background knowledge from
Wikipedia to represent documents and attempted to deal with the sparsity and
high dimensionality problems in text classiﬁcation. Instead of Wikipedia with
free-contributed entries, our work uses the superior LCSH ontology, which has
been under continuous development for a hundred years by knowledge engineers.
Many works utilise pattern mining techniques to help build classiﬁcation mod-
els, which is similar as the strategy employed in our work. Malik and Kender [10]
proposed the “Democratic Classiﬁer”, which is a pattern-based classiﬁcation al-
gorithm using short patterns. Diﬀerent from our work, their democratic classiﬁer
relies on the quality of training samples and cannot deal with the “no training
set available” problem. Bekkerman and Matan [1] argued that most of informa-
tion on documents can be captured in phrases and proposed a text classiﬁcation
method that employs lazy learning from labelled phrases. The phrases in their
work are in fact a special form of sequential patterns that are used in our work
for feature extraction of documents.

large set of classes, where K is the number of classes. If there is available a training

3 Unsupervised Multi-label Text Classiﬁcation
Let D = {di ∈ D, i = 1, . . . , m} be a set of text documents; S = {s1, . . . , sK} be a
set Dt = {dj ∈ D, j = m + 1, . . . , n} with yk
j = {0, 1}, k = 1, . . . , K provided
for describing the likelihood of dj belonging to class sk, it is easy to learn a binary
prediction function p(yk|d) and use it to classify di ∈ D. However, our objective
is to learn a prediction function p(yk|d) to classify di into {sk} ⊂ S without Dt

available. We refer to this problem as unsupervised multi-label text classiﬁcation.
The proposed classiﬁcation method consists of three steps: feature extraction,

initial classiﬁcation, and optimising classiﬁcation, using a world ontology.

3.1 World Ontology

The world knowledge ontology is constructed from the Library of Congress Sub-
ject Headings (LCSH), which is a knowledge system developed for organising
information in large library collections. It has been under continuous develop-
ment for over a hundred years to describe and classify human knowledge. Because
of the endeavours dedicated by the knowledge engineers from generation to gen-
eration, the LCSH has become a de facto standard for concept cataloguing and
indexing, superior to other knowledge bases. Tao et al. [12] once compared the
LCSH with the Library of Congress Classiﬁcation, the Dewey Decimal Classiﬁca-
tion, and Yahoo! categorisation, and reported that the LCSH has broader topic
coverage, more meaningful structure, and more accurate semantic relations. The
LCSH has been widely used as a means for many knowledge engineering and

484

X. Tao et al.

management works [4]. In this work, the class set S = {s1, . . . , sK} is encoded
from the LCSH subject headings.
Deﬁnition 1. (SUBJECT) Let S be the set of subjects, an element s ∈ S is a
4-tuple s := (cid:4)label, neighbour, ancestor, descendant(cid:5), where
– label is a set of sequential terms describing s; lable(s) = {t1, t2, . . . , tn};

– neighbour refers to the set of subjects in the LCSH that directly link to s,

– ancestor refers to the set of subjects directly and indirectly link to s and

neighbour(s) ⊂ S;
locating at more abstractive level than s in the LCSH, ancestor(s) ⊂ S;
– descendant refers to the set of subjects directly and indirectly link to s and
locating at more speciﬁc level than s in the LCSH, descendant(s) ⊂ S. (cid:2)
The semantic relationships of subjects are encoded from the references deﬁned in
the LCSH for subject headings, including Broader Term, Used for, and Related
to. The ancestor(s) in Deﬁnition 1 returns the Broader Term subjects of s; the
descendant(s) is the reversed function of ancestor(s), with additional subjects
Used for s; the neighbour(s) returns the subjects Related to s.
With Deﬁnition 1, the world knowledge ontology is deﬁned:
Deﬁnition 2. (ONTOLOGY) Let O be a world ontology. O contains a set of
subjects linked by their semantic relations in a hierarchical structure. O is a
3-tuple O := (cid:4)S,R,HS
– S is the set of subjects deﬁned in Deﬁnition 1;
– R is the set of relations linking any pair of subjects;
– HS

R is the hierarchical structure of O constructed by S × R.

R(cid:5), where

(cid:2)

3.2 Document Features

Various representations have been studied to formally describe text documents.
The lexicon-based representation is based on the statistic of occurring terms.
Such a representation is easy to understand by users and systems. However, along
with meaningful, representative features, some noisy terms are also extracted,
caused by sense ambiguity of terms. To deal with this problem, pattern-based
representation is studied, which uses frequent sequential patterns (phrases) to
represent document contents [9]. The pattern-based representation is superior
to lexicon-based, as the context of terms co-occurred in phrases is considered.
However, the pattern-based presentation suﬀers from a limitation caused by
the length of patterns. Though a long pattern is wealthy with information and
so more discriminative, it usually has low frequency and as a result, becomes
inapplicable. To overcome the problem, we represent the content of documents
by a set of weighted closed frequent sequential patterns discovered by pattern
mining techniques.

Deﬁnition 3. (FEATURES) Given a document d = {t1, t2, . . . , tn} as a se-
quential set of repeatable terms, the feature set, denoted as F (d), is a set of
weighted phrase patterns, {(cid:4)p, w(p)(cid:5)}, extracted from d that satisﬁes the follow-
ing constraints:

Unsupervised Multi-label Text Classiﬁcation

485

– ∀p ∈ F (d), p ⊆ d.
– ∀p1, p2 ∈ F(d)(p1 (cid:8)= p2), p1 (cid:8)⊂ p2 ∧ p2 (cid:8)⊂ p1.
– ∀p ∈ F (d), w(p) (cid:3) ϑ, a threshold.

(cid:2)

3.3 Initial Classiﬁcation

The initial classiﬁcation of d to sk ∈ S is done through accessing a term-subject

matrix created by the subjects and their labels. Adopting the features discovered
previously, we use a feature-subject mapping approach to initially assign subject
classes to the document.
Deﬁnition 4. (TERM-SUBJECT MATRIX) Let T be the term space of S,T =
{t ∈ (cid:2)
s∈S label(s)},(cid:4)S,T (cid:5) is the matrix coordinated by T and S, where a map-
ping exists:

μ : T → 2

S

, μ(t) = {s ∈ S|t ∈ label(s)}

and its reverse mapping also exists:

−1 : S → 2

T

(cid:2)
Adopting Deﬁnition 3 and 4, we can initially classify di ∈ D into a set of

−1(s) = {t ∈ T |s ∈ μ(t)}

, μ

μ

subjects using the following prediction:

i = I(sk ∈ h ◦ g ◦ f (di)), i = 1, . . . , m
(cid:3)yk

(1)

where I(z) is an indicator function that outputs 1 if z is true and zero, otherwise;

f (d) = {p|(cid:4)p, w(p)(cid:5) ∈ F (d)}; g(ρ) = {t ∈ ∪p∈ρp}; h(τ ) = {s ∈ ∪t∈τ μ(t)}.

3.4 Generalised Classiﬁcation

The initial classiﬁcation process easily generates noisy subjects because of direct
feature-subject mapping. Against the problem, we introduce a method to gener-
alise the initial subjects to optimise the classiﬁcation. We observed that in initial
classiﬁcation some subjects extracted from the ontology are overlapping in their
semantic space. Thus, we can optimise the classiﬁcation result by keeping only
the dominating subjects and pruning away those being dominated. This can be
done by investigating the semantic relations existing between subjects. Let s1
and s2 be two subjects and s1 ∈ ancestor(s2) (s2 ∈ descendant(s1)). s1 refers
to an broader semantic space than s2 and thus, is more general. Vice versa, s2
is more speciﬁc and focused than s1. Hence, if some subjects are covered by a
common ancestor, they can be replaced by the common ancestor without infor-
mation loss. The common ancestor is unnecessary to be chosen from the initial
classiﬁcation result, as choosing an external common ancestor also satisﬁes the
above rule. After generalising the initial classiﬁcation result, we have a smaller
set of subject classes, with no information lost but some focus. (The handling of
focus problem is presented in next section.)

486

X. Tao et al.

input : d = {t1, t2, . . . , tn} where n = |d|, a threshold ϑ.
output: The feature set F (d) = {(cid:4)p, w(p)(cid:5)}.
P (d) = ∅, F (d) = ∅, p = ∅;
//Extracting sequential patterns;
for (i = 1; i <= n; i + +) do

for (j = i; j <= (n − i); j + +) do

p = p ∪ {tj};

end
if p ∈ P (d) then w(p) + + for (cid:4)p, w(p)(cid:5) ∈ F (d)else P (d) = P (d) ∪ {p},
F (d) = F (d) ∪ {(cid:4)p, 1(cid:5)};

end
//Filtering F (d) for closed, frequent patterns;
foreach (cid:4)p, w(p)(cid:5) ∈ F (d) do

if w(p) < ϑ then F (d) = F (d) − {(cid:4)p, w(p)(cid:5)}else foreach (cid:4)pk, w(pk)(cid:5) ∈ F (d) do

if p ⊂ pk and w(p) ≤ w(pk) then F (d) = F (d) − {(cid:4)p, w(p)(cid:5)}

end

end
return F (d).

Algorithm 1. Extracting Features from a Document

1
2
3
4
5
6
7

8
9
10
11
12
13
14
15

Deﬁnition 5. (GENERALISED CLASSIFICATION) Given a document d and
its initial classiﬁcation result, a subject set denoted by SI (d), the generalised
classiﬁcation result, denoted as SG(d), is the set of subjects satisfying:
1. ∀s ∈ SI(d),∃s
2. ∀s1, s2 ∈ SG(d)(s1 (cid:8)= s2), s1 /∈ descendants(s2) ∧ s2 /∈ descendants(s1).

, s ∈ descendants(s

(cid:10) ∈ SG(d), s (cid:8)= s

).

(cid:10)

(cid:10)

4

Implementation

In this section, we present the technical details for implementing the proposed
approach of unsupervised multi-label text classiﬁcation.
Algorithm 1 describes the process of extracting features to represent a docu-
ment. The output is F (d), a set of closed frequent sequential patterns discovered
from d. Adopting the prediction in Eq. (1), with F (d) the initial set of subjects,
SI (d), can be assigned to classify d. Taking into account the weights of feature
patterns, we can evaluate t ∈ d:

(cid:4)

w(t) =

p∈{p|t∈g◦f (d),p∈f (d)}

w(p)

All s ∈ SI (d) can then be re-evaluated for their likelihood of being assigning to
d with consideration of term evaluation and term distribution in s ∈ SI (d). A
prediction function can then be used to assess initial classiﬁcation subjects for
the second run of classiﬁcation:

i = I(
(cid:3)y(cid:10)κ

(cid:4)

t∈μ−1(sκ)

w(t) × log(

|SI(di)|

sf (t, SI(di))

) (cid:3) θ), i = 1, . . . , m

(2)

where I(z (cid:3) θ) returns the value of z if z (cid:3) θ is true and zero, otherwise;
κ = 1, ...,K and SI (d) = {s1, . . . , sK} with |SI (d)| = K; θ is the threshold for

Unsupervised Multi-label Text Classiﬁcation

487

input : Si = {s1, s2, . . . , sj} (subject classes assigned to di after Eq. (2)), O;
output: S(cid:2)
S(cid:2)
foreach s ∈ Si do

i = {s1, s2, . . . , sk} (subject classes generalised for optimising classiﬁcation).

i = ∅, Stemp = ∅, Sredundant = ∅;

Extract S(s) from O where S(s) = {s
(cid:2)|s
sn ∈ Si where sn (cid:14)= s do
Extract S(sn) from O like Step 3;
if S(s) ∩ S(sn) (cid:14)= ∅ then
{(cid:2)s = LCA(S(s) ∪ S(sn)), str(i, (cid:2)s) = str(i, s) + str(i, sn); Stemp = Stemp ∪ {(cid:2)s};
Sredundant = Sredundant ∪ {s, sn}}

(cid:2) ∈ ancestor(s), δ(s (cid:12)→ s
(cid:2)

) ≤ 3}; foreach

end
if Stemp (cid:14)= ∅ then {S(cid:2)
Sredundant = ∅} else S(cid:2)

i = S(cid:2)
i = S(cid:2)

i ∪ Stemp; Si = Si − Sredundant; Stemp = ∅;
i ∪ {s}

1
2
3

4
5

6
7

8
9

end
return S(cid:2)

i.

Algorithm 2. Generalising Subjects for Optimal Classiﬁcation

ﬁltering out noisy subjects. In experiments diﬀerent values were tested for θ.
The results revealed that setting θ as the top ﬁfth z in SI(di), a variable rather
than a static value, gave the best performance. (Refer to Section 6 for detail.)

In the generalisation phase, descendant subjects are replaced by their common
ancestor subject. However, the common ancestor should not be too far away from
the replaced descendants in the ontology structure. The focus will be signiﬁcantly
lost, otherwise. In implementation, we use only the lowest common ancestor
(shortened by LCA) to replace its descendant subjects. The LCA is the common
ancestor of a set of subjects, with the shortest distance to these subjects in the
ontology structure. The LCA replaces descendant subjects with full information
kept and minimised focus lost.

Algorithm 2 describes the process of generalising the initial subject classes to
optimise classiﬁcation. The function str(i, s) describes the likelihood of assign
in Eq. (2).

s todi and returns the value of I(z (cid:3) θ) in Prediction function (cid:3)y(cid:10)κ
The function δ(s1 (cid:14)→ s2) returns a positive real number indicating the distance
edges travelled through from s1 to s2 in HS
R. The function LCA(S(s1) ∪ S(s2))
returns (cid:3)s, the LCA of s1 and s2. Note that δ(s1 (cid:14)→ s2) ≤ 3, which restricts

between two subjects. Such a distance is measured by counting the number of

i

LCAs to three edges in distance. Subjects further than that in distance are too
general; whereas using a highly-general subject for generalisation would severely
jeopardise the focus of original subjects. (In the experiments, δ(s1 (cid:14)→ s2) ≤ 3
and ≤ 5 were tested under the same environment in order to ﬁnd a valid distance
for tracking the competent LCA. The testing results revealed that as of three
the distance was better.)

5 Evaluation

The experiments were performed, using a large corpus collected from the cat-
alogue of a library using the LCSH for information organising. The title and
content of each catalogue item were used to form the content of a document.
The subject headings associated with the catalogue items were manually assigned

488

X. Tao et al.

by specialist librarians who were trained to specify subjects for documents with-
out bias [4]. The documents and subjects provided an ideal ground truth in the
experiments to evaluate the eﬀectiveness of the proposed classiﬁcation method.
This objective evaluation methodology assured the solidity and reliability of the
experimental evaluation.

The testing set was crawled from the online catalogue of library of the Uni-
versity of Melbourne1. General text pre-processing techniques, such as stopword
removal and word stemming (Porter stemming algorithm), were applied to the
preparation of testing set for experiments. In the experiments, we used only doc-
uments containing at least 30 terms, resulted in 31,902 documents in the testing
set. Documents shorter than that could hardly provided substantial frequent
patterns for feature extraction, as revealed in the preliminary experiments.

Given that the LCSH ontology contains 394,070 subjects in our implementa-
tion, the problem actually became a K-class text classiﬁcation problem where
K = |S| = 394, 070, a very large number. Hence, we chose two typical multi-
class classiﬁcation approaches, Rocchio and kNN, as the baseline models in the
experiments.

The performance of experimental models was measured by precision and re-
call, the modern evaluation methods in information retrieval and organising. In
terms of text classiﬁcation, precision was to measure the ability of a method to
assign a document with only focusing subjects, and recall the ability to assign a
document with all dealing subjects.
Taking into account K = |S| = 394070, in respect with the testing document
set and the ground truth featured by the LCSH, the classiﬁcation performance
was evaluated by:

|FT (Stgt) ∩ FT (Sgrt)|

|FT (Stgt) ∩ FT (Sgrt)|

and recall =

precision =
where FT (S) =
grt referred to the ground truth subjects.

|FT (Stgt)|
−1(s) (see Deﬁnition 4); tgt referred to the target model;

|FT (Sgrt)|

(cid:2)

s∈S μ

F1 Measure as another common method used in information organising sys-
tems was also employed in evaluation. We used micro-F1, which evaluated each
document’s classiﬁcation result ﬁrst and then averaged the results for the ﬁnal
F1 value. Greater F1 values indicate better performance.

6 Results and Discussions

Naming our proposed unsupervised classiﬁcation approach as the UTC model,
the experiments were to compare the eﬀectiveness performance of the UTC
model to the baselines, Rocchio and kNN models. Their eﬀectiveness perfor-
mances are depicted in Fig. 1 for the number of documents with valid eﬀective-
ness (> 0), where the value axis indicates the eﬀectiveness rate between 0 and 1;
the category axis indicates the number of documents whose classiﬁcation meets

1 http://www.library.unimelb.edu.au/

Unsupervised Multi-label Text Classiﬁcation

489

Fig. 1. Eﬀectiveness Performance Results

Table 1. Eﬀectiveness Performance on Average

Precision Recall F-Measure

UTC

Rocchio

kNN

0.158
0.020
0.021

0.135
0.290
0.054

0.125
0.020
0.016

the respective accuracy rate. As shown in the ﬁgure, the eﬀectiveness rates were
measured by precision, recall, and F1 Measure, where P (x) refers to the preci-
sion results of experimental model x, R(x) the recall results, and F (x) the F1
Measure results. Their overall average performances are shown in Table 1.

F1 Measure equally considers both precision and recall. Thus the F1 Measure
results can be deemed as an overall eﬀectiveness performance. The average F1
Measure result shown in Table 1 reveals that the UTC model has achieved a much
better overall performance (0.125) than other two models (0.020 and 0.016). Such
a performance is also conﬁrmed by the detailed results depicted in Fig. 1 - the
F (U T C) line is located at much higher bound level compared to the F (Rocchio)
and F (kN N ) lines.

Precision measures how accurate the classiﬁcation is. In terms of this, the UTC
model once again has outperformed the baseline models. The average precision
results shown in Table 1 demonstrates the achievement (UTC 0.158 vs. Rocchio
0.020 and kNN 0.021). The precision results depicted in Fig. 1 illustrate the
same conclusion; the P (U T C) outperformed others.

Recall measures the performance of classiﬁcation by considering all dealing
classes. The recall performance in the experiments shows a slightly diﬀerent
result, compared with those from F1 Measure and precision performance. The
Rocchio model achieved the best recall performance (0.290 on average), com-
pared to that of the UTC model (0.135) and the kNN model (0.054). The result
is also illustrated in Fig. 1, where R(U T C) lies in the middle of R(Rocchio) and
R(kN N ).

490

X. Tao et al.

There was a gap between the recall performance of the UTC and the Rocchio
models. From the observation of recall results, we found that the classes as-
signed by the Rocchio model were usually a large set of subjects (935 on av-
erage), whereas the UTC model assigned documents with a reasonable number
of subjects (16 on average) and the kNN results had an average size of 106.
Due to the natural of recall measurement, more feature term would be cover
if the subject size became larger. As a result, the Rocchio classiﬁcation with
the largest size achieved the best recall performance. The subject sets assigned
by the kNN model had larger size than those assigned by the UTC. However,
when expanding the classiﬁcation by neighbours, a large deal of nosey data was
also brought into the neighbourhood - the average number of neighbours arisen
was 336. This was caused by the very large set and short length of documents
in consideration. As a result, the classiﬁcation became inaccurate though only
the documents with the top cosine values were chosen to expand and only the
subjects with the top similarity values were chosen to classify a document.

Table 2. Performance Comparison for Finding the LCA

Precision Recall F-Measure

Level = 3
Level = 5

0.158
0.154

0.135
0.112

0.125
0.111

Diﬀerent number of levels were tested in sensitivity study for choosing a right
number of levels to ﬁnd the lowest common ancestor when generalising subjects
for optimal classiﬁcation. Table 2 displays the testing results for ﬁnding such a
right level number. In the same experimental environment, if tracing three levels
to ﬁnd a LCA the UTC model’s overall performance including F1 Measure,
precision, and recall was better than that of tracing ﬁve levels. In addition,
tracing three levels only would give us better complexity. Therefore, we chose
three levels to restrict the extent of ﬁnding CLAs.

7 Conclusions

Text classiﬁcation has been widely exploited to improve the performance in
information retrieval, information organising, text categorisation, and knowl-
edge engineering. Traditionally, text classiﬁcation relies on the quality of target
categorises and the accuracy of classiﬁers learned from training samples. Some-
times qualiﬁed training samples may be unavailable; the set of categories used
for classiﬁcation may be with inadequate topic coverage. Sometimes documents
may be classiﬁed into noisy classes because of large dimension of categories.
Aiming to deal with these problems, in this paper we have introduced an un-
supervised multi-label text classiﬁcation method. Using a world ontology built
from the LCSH, the method consists of three modules; closed frequent sequen-
tial pattern mining for feature extraction; extracting subjects from the ontology

Unsupervised Multi-label Text Classiﬁcation

491

for initial classiﬁcation; and generalising subjects for optimal classiﬁcation. The
method has been promisingly evaluated by compared with typical text classi-
ﬁcation methods, using a large real-world corpus, based on the ground truth
encoded by human experts.

References

1. Bekkerman, R., Gavish, M.: High-precision phrase-based document classiﬁcation
on a modern scale. In: Proceedings of the 17th ACM SIGKDD International Con-
ference on Knowledge Discovery and Data Mining, KDD 2011, pp. 231–239 (2011)
2. Cai, D., Zhang, C., He, X.: Unsupervised feature selection for multi-cluster data.
In: Proceedings of the 16th ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining, KDD 2010, pp. 333–342 (2010)

3. Camous, F., Blott, S., Smeaton, A.: Ontology-Based MEDLINE Document Classi-
ﬁcation. In: Hochreiter, S., Wagner, R. (eds.) BIRD 2007. LNCS (LNBI), vol. 4414,
pp. 439–452. Springer, Heidelberg (2007)

4. Chan, L.M.: Library of Congress Subject Headings: Principle and Application.

Libraries Unlimited (2005)

5. Gabrilovich, E., Markovitch, S.: Feature generation for text categorization using
world knowledge. In: Proceedings of The 19th International Joint Conference for
Artiﬁcial Intelligence, pp. 1048–1053 (2005)

6. Houle, M.E., Grira, N.: A correlation-based model for unsupervised feature selec-
tion. In: Proceedings of the 16th ACM Conference on Conference on Information
and Knowledge Management, CIKM 2007, pp. 897–900 (2007)

7. Hu, X., Zhang, X., Lu, C., Park, E.K., Zhou, X.: Exploiting wikipedia as external
knowledge for document clustering. In: KDD 2009: Proceedings of the 15th ACM
SIGKDD International Conference on Knowledge Discovery and Data Mining, pp.
389–396 (2009)

8. Katakis, I., Tsoumakas, G., Vlahavas, I.: Multilabel text classiﬁcation for auto-
mated tag suggestion. In: Proceedings of the ECML/PKDD 2008 Workshop on
Discovery Challenge (2008)

9. Li, Y., Algarni, A., Zhong, N.: Mining positive and negative patterns for relevance
feature discovery. In: Proceedings of 16th ACM SIGKDD Conference on Knowledge
Discovery and Data Mining, pp. 753–762 (2010)

10. Malik, H.H., Kender, J.R.: Classifying high-dimensional text and web data using
very short patterns. In: Proceedings of the 2008 8th IEEE International Conference
on Data Mining, ICDM 2008, pp. 923–928 (2008)

11. Rocha, L., Mour˜ao, F., Pereira, A., Gon¸calves, M.A., Meira Jr., W.: Exploiting
temporal contexts in text classiﬁcation. In: Proceeding of the 17th ACM Conference
on Information and Knowledge Management, CIKM 2008, pp. 243–252 (2008)

12. Tao, X., Li, Y., Zhong, N.: A personalized ontology model for web information
gathering. IEEE Transactions on Knowledge and Data Engineering, IEEE Com-
puter Society Digital Library 23(4), 496–511 (2011)

13. Wang, P., Domeniconi, C.: Building semantic kernels for text classiﬁcation using
wikipedia. In: KDD 2008: Proceeding of the 14th ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining, pp. 713–721 (2008)

492

X. Tao et al.

14. Yan, Y., Okazaki, N., Matsuo, Y., Yang, Z., Ishizuka, M.: Unsupervised relation
extraction by mining wikipedia texts using information from the web. In: Proceed-
ings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th
International Joint Conference on Natural Language Processing of the AFNLP,
ACL 2009, vol. 2, pp. 1021–1029 (2009)

15. Yang, B., Sun, J.-T., Wang, T., Chen, Z.: Eﬀective multi-label active learning for
text classiﬁcation. In: KDD 2009: Proceedings of the 15th ACM SIGKDD Interna-
tional Conference on Knowledge Discovery and Data Mining, pp. 917–926 (2009)
16. Yang, T., Jin, R., Jain, A.K., Zhou, Y., Tong, W.: Unsupervised transfer classiﬁca-
tion: application to text categorization. In: Proceedings of the 16th ACM SIGKDD
International Conference on Knowledge Discovery and Data Mining, KDD 2010,
pp. 1159–1168 (2010)


