Clustering-Based k-Anonymity

Xianmang He1, HuaHui Chen1, Yefang Chen1,

Yihong Dong1, Peng Wang2, and Zhenhua Huang3

1 School of Information Science and Technology, NingBo University
{hexianmang,chenhuahui,chenyefang,dongyihong}@nbu.edu.cn
2 School of Computer Science and Technology, Fudan University

No.818, Fenghua Road, Ning Bo, 315122, P.R. China

No.220, Handan Road, Shanghai, 200433, P.R. China

3 School of Electronic and Information Engineering, TongJi University

pengwang5@fudan.edu.cn

NO.1239. Siping Road, Shanghai, 200433, P.R. China

Huangzhenhua@tongji.edu.cn

Abstract. Privacy is one of major concerns when data containing sen-
sitive information needs to be released for ad hoc analysis, which has
attracted wide research interest on privacy-preserving data publishing in
the past few years. One approach of strategy to anonymize data is gener-
alization. In a typical generalization approach, tuples in a table was ﬁrst
divided into many QI (quasi-identiﬁer)-groups such that the size of each
QI-group is no less than k. Clustering is to partition the tuples into many
clusters such that the points within a cluster are more similar to each
other than points in diﬀerent clusters. The two methods share a com-
mon feature: distribute the tuples into many small groups. Motivated by
this observation, we propose a clustering-based k-anonymity algorithm,
which achieves k-anonymity through clustering. Extensive experiments
on real data sets are also conducted, showing that the utility has been
improved by our approach.

Keywords: privacy preservation, algorithm, proximity privacy.

1

Introduction

Privacy leakage is one of major concerns when publishing data for statistical
process or data analysis. In general, organizations need to release data that may
contain sensitive information for the purposes of facilitating useful data analysis
or research. For example, patients’ medical records may be released by a hospital
to aid the medical study. Records in Table 1 (called the microdata) is an example
of patients’ records published by hospitals. Note that attribute Disease contains
sensitive information of patients. Hence, data publishers must ensure that no
adversaries can accurately infer the disease of any patient. One straightforward
approach to achieve this goal is excluding unique identiﬁer attributes, such as
Name from the table, which however is not suﬃcient for protecting privacy
leakage under linking-attack [1, 2]. For example, the combination of Age and

P.-N. Tan et al. (Eds.): PAKDD 2012, Part I, LNAI 7301, pp. 405–417, 2012.
c(cid:2) Springer-Verlag Berlin Heidelberg 2012

406

X. He et al.

Table 1. Microdata T

Table 2. Generalization T

∗

Andy
Bob
Jane
Alex
Mary
Lily
Lucy

Age
20
20
30
40
50
60
60

Zip
25
30
25
30
10
5
10

Diesease

Flu

Bronchitis
Gastritis
Penumonia

Flu

Bronchitis
Gastritis

G-ID

Age

Zip

Diesease

1
1
2
2
3
3
3

[20-20]
[20-20]
[30-40]
[30-40]
[50-60]
[50-60]
[50-60]

Flu

Flu

[25-30]
[25-30] Bronchitis
Gastritis
[25-30]
[25-30]
Penumonia
[5-10]
[5-10]
[5-10]

Bronchitis
Gastritis

Zipcode can be potentially used to identify an individual in Table 1, and has
been called a quasi-identiﬁer (QI for short)[1] in literatures. If an adversary has
the background knowledge about Bob, that is: Age=20 and Zipcode=30, then
by joining the background knowledge to Table 1, he can accurately infer Bob’s
disease, that is bronchitis.
To protect privacy against re-identifying individuals by joining multiple public
data sources, k-anonymity (k ≥ 2) was proposed, which requires that each record
in a table is indistinguishable from at least k − 1 other records with respect to
certain quasi-identiﬁers. Generally, to achieve k-anonymity, generalization [1–3]
is a popular methodology of privacy preservation for preventing linking attacks.
Enough degree of generalization will hide a record in a crowd with at least k
records with the same QI-values, thereby achieving k-anonymity. Table 2 demon-
strates a generalized version of Table 1 (e.g., the Zip 30 of Bob, for instance, has
been generalized to an interval [25, 30]). The generalization results in 3 equiva-
lence classes, as indicated by their group-IDs. Each equivalence class is referred
to as a QI-group. As a result, given Table 2, even if an adversary has the exact
QI-values of Bob, s/he still can not exactly ﬁgure out the tuple of Bob from the
ﬁrst QI-group.

1.1 Motivation

Although generalization-based algorithms have successfully achieved the privacy
protection objective, as another key issue in data anonymization utility still
needs to be carefully addressed. Great eﬀorts have been dedicated to develop-
ing algorithms that improve utility of anonymized data while ensuring enough
privacy-preservation. One of the direct measures of the utility of the generalized
data is information loss. In order to make the anonymized data as useful as
possible for certain applications, it is required to reduce the information loss as
much as possible. In general, the less total information loss leads to better utility,
which reﬂects its usefulness as one of the steps in exploratory data analysis.

Clustering [4] is a method commonly used to automatically partition a data
set into many groups. As an example of clustering is depicted in Figure 1-3. The
input points are shown in Figure 1, and the steps to the desired clusters are
shown in Figure 2 and Figure 3. Here, points belonging to the same cluster are
given the same color.

Clustering-Based k-Anonymity

407

Zip

 
 
 
 
 

0
3

 
 
 
 
 
 

0
2

 
 
 
 
 
 
 

0
1

Zip

 
 
 
 
 
0
3
 
 
 
 
 
 
0
2
 
 
 
 
 
 
 
0
1

Age

Zip

 
 
 
 
 

0
3

 
 
 
 
 
 

0
2

 
 
 
 
 
 
 

0
1

Age

Age

   20     40     60  

   20     40     60  

   20     40     60  

Fig. 1. The points inTable 1

Fig. 2. Data Clustering
(Step 1)

Fig. 3. Data Clustering
(Step 2)

Then, we may wonder: Can we signiﬁcantly improve the utility while pre-
serving k-anonymity by clustering-based approaches ? The answer depends on
whether it is possible to partition microdata into clusters with less information
loss while still ensuring k-anonymity. Intuitively, data points within a cluster
are more similar to each other than they are to a point belonging to a diﬀerent
cluster.

The above observation motivates us to devise a new solution to improve the
data utility of clustering-based solutions. As an example, we illustrate the details
to generalize Table 1 by our approach. Let gen be a generalization function that
takes as input a set of tuples and returns a generalized domain. Firstly, Table
1 is divided into 2 clusters, denoted by red and blue in Figure 2, respectively.
Then, the cluster denoted by blue is further divided into 2 cluster, denoted by
black and green color in Figure 3. Finally, tuples with same color are general-
ized as a QI-group, that is, tuple Andy and Bob consists of the ﬁrst QI-group,
and assign gen({Andy, Bob})=(cid:3)[20 − 20], [25 − 30](cid:4) to the ﬁrst QI-group. Sim-
ilarly, {Jane,Alex}, {Mary, Lily, Lucy} make the second and third QI-group.
Eventually, table 2 is the ﬁnal result by our approach.

In this paper, we mainly focused on the basic k-anonymity model due to the
following reasons: (i) k-anonymity is a fundamental model for privacy protection,
which has received wide attention in the literatures; (ii) k-anonymity has been
employed in many real applications such as location-based services [5, 6], where
there are no additional (sensitive) attributes; (iii) There is no algorithm that
is suitable for so many privacy metrics such as l-diversity[7], t-Closeness [8],
but algorithms for k-anonymity are simple yet eﬀective, and can be further
adopted for other privacy metrics. Apart from the k-anonymity model, we also
consider the scenarios with stronger adversaries, extending our approach to l-
diversity(Section 4)

The rest of the paper is organized as follows. In Section 2, we give the deﬁni-
tions of basic concept and the problem will be addressed in this paper. In Section
3, we present the details of our generalization algorithm. Section 4 discusses the
extension of our methodology for l-diversity. We review the previously related
research in Section 5. In Section 6, we experimentally evaluate the eﬃciency and
eﬀectiveness of our techniques. Finally, the paper is concluded in Section 7.

408

X. He et al.

2 Fundamental Deﬁnitions

Let T be a microdata table that contains the private information of a set of
individuals and has d QI-attributes A1, ..., Ad, and a sensitive attribute As. We
consider that As is numerical, and every QI-attribute Ai(1 ≤ i ≤ d) can be
either numerical or categorical. All attributes have ﬁnite and positive domains.
For each tuple t ∈ T, t.Ai(1 ≤ i ≤ d) denotes its value on Ai, and t.As represents
its SA value.

2.1 Basic Concept

A quasi-identiﬁer QI = {A1, A2,··· , Ad} ⊆ {A1, A2,··· , An} is a minimal set

of attributes, which can be joined with external information in order to reveal
the personal identity of individual records.
A partition P consists of several subsets Gi(1 ≤ i ≤ m) of T , such that each
i Gi. We refer to each subset

tuple in T belongs to exactly one subset and T =
Gi as a QI-group.

(cid:2)m

2.2 K-means Clustering

K-means clustering [4] is a method commonly used to automatically partition
a data set into K groups. It proceeds by selecting K initial cluster centers and
then iteratively reﬁning them as follows:

Step 1. Each tuple ti is assigned to its closest cluster center.

Step 2. Each cluster center Cj is updated to be the mean of its constituent

instances.

The algorithm converges when there is no further change in assignment of tu-
ples to clusters. In this work, we initialize the clusters using instances picked at
random from the data set. The data sets we used are composed solely of either
numeric features or categorical features. For both numeric and categorical fea-
tures, we adopt the normalized certainty penalty(see the deﬁnition 1) to measure
the distance.

The ﬁnal issue is how to choose K. To keep the algorithm simple in this paper,

we consider binary partitioning, that is, K is ﬁxed as 2.

2.3 Problem Deﬁnition

Some methods have been developed to measure the information loss in anonymiza-
tion. In this paper, we adopt the normalized certainty penalty to measure the
information loss.

Deﬁnition 1 (Normalized Certainty Penalty [9]). Suppose a table T is
. In the domain of each attribute in T , suppose there exists a
anonymized to T

∗

Clustering-Based k-Anonymity

409

∗

global order on all possible values in the domain. If a tuple t in T
has range
[xi, yi] on attribute Ai(1 ≤ i ≤ d), then the normalized certainty penalty in t on
, where |Ai| is the domain of the attribute Ai. For
Ai is N CPAi (t) =
i wi · N CPAi (t),

tuple t, the normalized certainty penalty in t is N CP (t) =
where wi is the weight of attribute Ai. The normalized certainty penalty in T is
(cid:3)

|yi−xi|
|Ai|

(cid:3)d

t∈T ∗ N CP (t).

Now, we are ready to give the formal deﬁnition about the problem that will be
addressed in this paper. Information loss is an unfortunate consequence of data
anonymization. We aim to generate a utility-friendly version anonymizaiton for
a microdata such that the privacy can be guaranteed by k-anonymity and the
information loss quantiﬁed by N CP is minimized. Now, we are ready to give
the formal deﬁnition about the problem that will be addressed in this paper.
(Limited by space, all proofs are omitted.)

Deﬁnition 2 (Problem Deﬁnition). Given a table T and an integer k,
is k-anonymity and the to-
anonymize it by clustering to be T
tal information loss is minimized measured by N CP .

such that T

∗

∗

Theorem 1. (Complexity) The problem of optimal clustering-based anonymiza-
tion is NP-hard under the metric N CP .

3 Clustering-Based Generalization Algorithm

In this section, we will present the details of our clustering-based anonymization
approach. The key of our algorithm is to divide all tuples into more compact
clusters eﬃciently and correctly. We now proceed to a discussion of our modiﬁ-
cations to the K-means algorithm.

To keep the algorithm simple, we consider binary clustering. That is, in each
round, we partition a set of tuples into two subsets by clustering. In order to
reduce the total information loss, we will cluster the microdata following the idea:
distribute tuples sharing the same or quite similar QI-attributes into the same
cluster. We adopt the N CP to measure the distance. The detailed partitioning
procedure is presented in Figure 4. Initially, S contains T itself (line 1); then,

each G ∈ S is divided into two generalizable subsets G1 and G2 such that
G1 ∪ G2 = G, G1 ∩ G2 = ∅ (line 5-7).
The size of the two subsets should ≥ k, otherwise adjustment is needed (line
8). Without loss of generality, assume that G1 < k, we need to borrow k − |G1|
tuples from G2 to make sure that G1 has a cardinality ≥ k.

The tries to converges will cost unacceptable time, to accelerate the partition-
ing, the attempts to cluster G are tried r times and tuples of G are randomly
shuﬄed for each time (line 4). Our experimental results show that most of G can
be partitioned into two sub-tables by up to k = 15 tries. The algorithm stops
when no sub-tables in S can be further partitioned.
By the Lemma in the paper [9, 10] that the optimal k-anonymity partitioning
of microdata does not contain groups of more than 2k − 1 records, we have that

410

X. He et al.

the partitioning algorithm will terminate when the size of all groups is between
k and 2k − 1. If at least one group contains a cardinality more than 2k − 1, the
partitioning algorithm will continue.

In the above procedure, the way that we partition G into two subsets G1 and
G2 is inﬂuential on the information loss of the resulting solution. In the ﬁrst
round, we randomly choose two tuples t1, t2 as the center points C1, C2 , and
then insert them G1 and G2 separately. Then, we distribute each tuple w ∈ G:
for each tuple w, we compute Δ1 = N CP (C1 ∪ w) and Δ2 = N CP (G2 ∪ w), and
add tuple w to the group that leads to lower penalty (line 7). If Δ1 = Δ2, assign
the tuple to the group who has lower cardinality. After successfully partitioning
G, remove the tuples t1 and t2 from G1 − {t1} and G2 − {t2}. At the later each

(cid:2)

round, the center points Ci are conducted as follows: Ci =
is, for each attribute Aj(1 ≤ j ≤ d), Ci.Aj =

t.Aj

(cid:2)

t∈Gi
|Gi|

t

t∈Gi
|Gi|
, i = 1, 2.

, i = 1, 2. that

After the each partition, if the current partition is better than previous tries,
record the partition result G1, G2 and the total sum of N CP (G1) and N CP (G2).
That is, we pick the one that that minimizes the sum of N CP (G1) and N CP (G2)
as the ﬁnal partition among the r partitions(line 9). Each round of G can be
accomplished in O(r · (|G| · (6 + λ))) expected time, where λ is the cost of
evaluating loss. The computation cost is theoretically bounded in Theorem 2.

Theorem 2. For microdata T , the clustering-based algorithm can be accom-
plished in O(r·|T|· log(|T|)) average time, where r is the number of rounds , and
|T| is the cardinality of microdata T .

;

∗

Input: A microdata T , integers k and rounds r
Output: anonymized table T
Method:
/* the parameter r is number of rounds to cluster G*/
1. S = {T};
2. While(∃G ∈ S that |G| ≥ 2k)
3.
4.

Randomly shuﬄe the tuples of G;

For i = 1 to r

5.
6.
7.

(cid:2)

t∈Gi t
|Gi|

Set Center Ci =
Set G1 = G2 = ∅;
Distribute each tuple w in G:

;

compute Δ1 = N CP (w ∪ C1) and Δ2 = N CP (w ∪ C2);
If(Δ1 < Δ2) then add w to G1, else add w to G2;

Adjust G1, G2 that each group has at least k tuples;
If the current partition is better than previous tries, record G1 and G2;

Remove G from S, and add G1, G2 to S;

8.
9.
10.
11. Return S;

Fig. 4. The partitioning algorithm

Clustering-Based k-Anonymity

411

4 Extension to l-Diversity

In this section, we discuss how we can apply clustering-based anonymization
for other privacy principles. In particular, we focus on l-diversity, described in
Deﬁnition 3.

∗

∗

Deﬁnition 3 (l-diversity[7]). A generalized table T
group QIi ∈ T
value in QIi, and ci(v) be the number of tuples t ∈ QIi, then

is l-diversity if each QI-
satisﬁes the following condition: let v be the most frequent As

ci(v)

|QIi| ≤ 1
l .

To generalize a table through clustering-based anonymization, we partition a
table into sub-tables Ti which satisfy l-diversity: after each round of the above
partitioning, if both (G1 and G2)) satisfy l-diversity, we remove G from S, and
add G1, G2 to S; otherwise G is retained in S. Then for each subset Ti ∈ S,

we conduct the splitting algorithm (see Figure 5) to produce the ﬁnal l-diverse
partitions.

|QIi|

The principle l-diversity demands that: the number of the most frequent As
value in each QI-group QIi can’t exceed
. Motivated by this, we arrange
the tuples to a list ordered by its As values, then distribute the tuples in L into
QIi(1 ≤ i ≤ g) a round-robin fashion. The resulting splitting is guaranteed to
be l-diversity, which is stated in Theorem 3. (If table T with sensitive attribute
As satisﬁes max{c(v) : v ∈ T.As} >
, then there exists no partition that is
l-diversity.)

|T|
l

l

Input: table T , parameter l
Output: QI-groups QIj that satisfy l-diversity;
Method:
1. If max{c(v) : v ∈ T.As} ≥ |T|
2. Hash the tuples in T into groups Q1, Q2, ··· , Qλ by their As values;
3. Insert these groups Q1, Q2,··· , Qλ into a list L in order;
l , set QI-groups QI1 = QI2 = ··· = QIg = ∅;
|T|
4. Let g =
5. Assign tuple ti ∈ L (1 ≤ i ≤ |L|) to QIj, where j = (i mod g) + 1

l , Return;

Fig. 5. The splitting algorithm

Theorem 3. If table T with sensitive attribute As satisﬁes max{c(v) : v ∈
T.As} ≤ |T|
l (where c(v) is the number of tuples in T with sensitive value v), the
partition produced by our splitting algorithm fulﬁlls l-diversity.

5 Related Work

In this section, previous related work will be surveyed. Existing generalization
algorithms can be further divided into heuristic-based and theoretical-based ap-
proaches. Generally, appropriate heuristics are general so that they can be used

412

X. He et al.

Table 3. Summary of attributes

 Attribute 

Age

Gender

Education

Marital
Race 

Work-class

Country

Occupation

 Number of
distinct values

78
2
17
6
9
10
83
50

 Types  

  Numerical  
  Categorical  
 Numerical  
 Categorical  
  Numerical  
 Categorical  
  Numerical  

Sensitive

 Attribute 

  Age 

Occupation  
Birthplace
 Gender
Education

Race 

Work-class

 Marital
Income

 Number of
distinct values

78
711
983
2
17
9
9
6

   [1k,10k] 

 Types  

Numerical
Numerical
Numerical
Categorical
Categorical
Categorical
 Categorical
Categorical
Sensitive

(a) SAL

(b) INCOME

Table 4. Parameters and tested values

Parameter Values

k

cardinality n

 250,200,150,100,50

100k,200k,300k,400k,500k

number of QI-attributes d

 3,4,5,6

in many anonymization models. To reduce information loss, eﬃcient greedy so-
lutions following certain heuristics have been proposed [9–13] to obtain a near
optimal solution. Generally, these heuristics are general enough to be used in
many anonymization models. Incognito [14] provides a practical framework for
implementing full-domain generalization, borrowing ideas from frequent item set
mining, while [10] presents a framework mapping the multi-dimensional quasi-
identiﬁers to 1-Dimensional(1-D) space. For 1-D quasi-identiﬁers, an algorithm of
O(K · N ) time complexity for optimal solution is also developed. It is discovered
that k-anonymizing a data set is strikingly similar to building a spatial index
over the data set, so that classical spatial indexing techniques can be used for
anonymization [15]. To achieve k-anonymity, Mondrian [16] takes a partitioning
approach reminiscent of KD-trees.

The idea of non-homogeneous generalization was ﬁrst introduced in [17], which
studies techniques with a guarantee that an adversary cannot associate a gener-
alized tuple to less than K individuals, but suﬀering additional types of attack.
Authors of paper [13] proposed a randomization method that prevents such type
of attack and showed that k-anonymity is not compromised by it, but its par-
titioning algorithm is only a special of the top-down algorithm presented in [9].
The model of the paper [13, 17], the size of QI-groups is ﬁxed as 1.

The algorithms mentioned above work well on practical data sets, but do
not have attractive asymptotical performance in the worst case. This motivates
studies on the theoretical aspects of k-anonymity [16, 18]. Most of these works
show that the problem of optimal k-anonymity is NP-hard even a simple quality
metric is employed.

Clustering-Based k-Anonymity

413

6 Empirical Evaluation

In this section, we will experimentally evaluate the eﬀectiveness and eﬃciency
of the proposed techniques. Speciﬁcally, we will show that by our technique
(presented in Section 3) have signiﬁcantly improved the utility of the anonymized
data with quite small computation cost.

Towards this purpose, two widely-used real databases sets: SAL and IN-
COME(downloadable from http://ipums.org) with 500k and 600k tuples, respec-
tively, will be used in following experiments. Each tuple describes the personal
information of an American. The two data sets are summarized in Table 3.

In the following experiments, we compare our cluster-based anonymity algo-
rithm (denoted by CB) with the existing state-of-the-art technique: the non-
homogeneous generalization [13](NH for short). (The fast algorithm [10] was
cited and compared with NH in the paper [13], therefore, we omit the details of
the fast algorithm.)

In order to explore the inﬂuence of dimensionality, we create two sets of micro-
data tables from SAL and INCOME. The ﬁrst set has 4 tables, denoted as SAL-3,
··· , SAL-6, respectively. Each SAL-d (3 ≤ d ≤ 6) has the ﬁrst d attributes in
Table 3 as its QI-attributes and Occupation as its sensitive attribute(SA). For
example, SAL-4 is 5-Dimensional, and contains QI-attributes: Age, Gender, and

0.014

0.012

)

P
C
G

(
 
s
s
o
L

0.008

 

n
o

i
t

a
m
r
o

0.004

f

n

I

NH
CB

NH
CB

0.32

)

P
C
G

(
 
s
s
o
L
n
o

 

i
t

a
m
r
o
n

f

I

0.26

0.22

0.18

0.14

NH
CB

0.14

0.1

0.06

)

P
C
G

(
 
s
s
o
L

 

n
o

i
t

a
m
r
o

f

n

I

0
50

100

150
K

200

250

50

100

150
K

200

250

0.02

50

100

150
K

200

250

(a) SAL-3

(b) INC-3

(c) SAL-4

NH
CB

0.4

0.35

)

P
C
G

0.25

(
 
s
s
o
L
n
o

 

i
t

a
m
r
o

0.15

f

n

I

NH
CB

0.35

0.3

0.25

)

P
C
G

(
 
s
s
o
L

0.2

 

n
o

i
t

0.15

a
m
r
o

f

0.1

n

I

0.05

0.22

0.2

)

P
C
G

NH
CB

0.16

(
 
s
s
o
L
n
o

 

i
t

a
m
r
o

0.12

f

n

I

0.08

50

0.32
0.3

0.26

0.22

0.18

0.14

)

P
C
G

(
 
s
s
o
L
 
n
o
i
t
a
m
r
o

f

n

I

100

150
K

200

250

0.05

50

100

150
K

200

250

0
50

100

150
K

200

250

(d) INC-4

(e) SAL-5

(f) INC-5

NH
CB

NH
CB

0.35

0.25

0.15

)

P
C
G

(
 
s
s
o
L

 

n
o

i
t

a
m
r
o

f

n

I

50

100

150
K

200

250

0.05

50

100

150
K

200

250

(g) SAL-6

(h) INC-6

Fig. 6. The Global Certainty Penalty vs. parameters k and d

414

X. He et al.

Education, Marital. The second set also has 4 tables INC-3, ··· , INC-6, where
each INC-d (3 ≤ d ≤ 6) has the ﬁrst d attributes as QI-attributes and income
as the SA.

In the experiments, we investigate the inﬂuence of the following parameters
on information loss of our approach: (i) value of k in k-anonymity; (ii)number of
attributes d in the QI-attributes; (iii)number of tuples n. Table 4 summarizes the
parameters of our experiments, as well as their values examined. Default values
are in bold font. Data sets with diﬀerent cardinalities n are also generated by
randomly sampling n tuples from the full SAL-d or INC-d (3 ≤ d ≤ 6). All
experiments are conducted on a PC with 1.9 GHz AMD Dual Core CPU and 1
gigabytes memory. All the algorithms are implemented with VC++ 2008.

We measure the information loss of the generalized tables using GCP, which
is ﬁrst used in [10]. Note that GCP essentially is equivalent to N CP with only
a diﬀerence of constant number d × N . Speciﬁcally, under the same partition
d×N ( d is the size of QI-attributes), when all the
P of table T , GCP (T ) =
weights are set to 1.0.

N CP (T )

6.1 Privacy Level K

In order to study the inﬂuence of k on data utility, we observe the evolution of
GCP that has been widely used to measure the information loss of the general-
ized tables by varying k from 50 to 250 with the increment of 50. In all following
experiments, without explicit statements, default values in Table 4 will be used
for all other parameters. The results on SAL-d and INC-d (3 ≤ d ≤ 6) data are

NH
CB

0.25

0.2

)

P
C
G

(
 
s
s
o
L

0.15

 

n
o

i
t

a
m
r
o

f

n

0.1

0.05

NH
CB

0.35

)

P
C
G

0.25

(
 
s
s
o
L

 

n
o

i
t

0.15

a
m
r
o
f
n
I

I

0
3

4

5

d

(a) SAL-d

6

0.05
3

4

d

5

6

(b) INC-d

Fig. 7. The Global Certainty Penalty vs. QI-Dimensionality d

0.23
0.22

)

P
C
G

0.19

(
 
s
s
o
L

 

n
o

NH
CB

0.16

i
t

a
m
r
o

f

n

I

0.13

)

P
C
G

0.26
0.24

NH
CB

0.2

0.16

(
 
s
s
o
L
 
n
o
i
t
a
m
r
o

0.12

f

n

I

0.08

100

200

300

n (in thousands)

400

500

100

200

300

n (in thousands)

400

500

(a) SAL-7

(b) INC-7

Fig. 8. The Global Certainty Penalty vs. Cardinality n

Clustering-Based k-Anonymity

415

shown in Figure 6 (a)-6(h). From the results, we can clearly see that information
loss of CB sustains a big improvement over NH, for the tested data except the on
SAL-3. Another advantage of our model over NH is that the utility achieved by
our model is less sensitive to domain size than NH. From the ﬁgures, we can see
that data sets generated by NH has a lower GCP on SAL-d than that on INC-d
(4 ≤ d ≤ 7) due to the fact that domain size of SAL is smaller than that of INC.
Such a fact implies that the information loss of NH is positively correlated to
the domain size. However, in our model, domain size of diﬀerent data set has
less inﬂuence on the information loss of the anonymized data.

Results of this experiment also suggest that for almost all tested data sets the
GCP of these algorithms grows linearly with k. This can be reasonably explained
since larger k will lead to more generalized QI-groups, which inevitably will
sacriﬁce data utility. NH performs well when the dimensionality of QI-Attributes
is low and the domain size is small, see the experiment results in the paper[13].

6.2 QI-Attributes Dimensionality d

Experiments of this subsection is designed to show the relation between the
information loss of these algorithms and data dimensions d. In general, the in-
formation loss will increase with d, since data sparsity or more speciﬁcally the
data space characterized by a set of attributes exponentially increases with the
number of attributes in the set, i,e, dimensions of the table. Figure 7(a) and 7(b)
compare the information loss of the anonymization generated by the these four
methods with respect to diﬀerent values of d on SAL-d and INC-d, respectively.
It is clear that the anonymization generated by the cluster-based method has a
lower global certainty penalty compared to that of NH. The advantage of CB is
obvious, and such an advantage of CB can be consistently achieved when d lies
between 4 to 6.

6.3 Cardinality of Data Set n

In this subsection, we investigate the inﬂuence of the the table size n on infor-
mation loss. The results of experiments on two data sets SAL-7 and INC-7 are
shown in Figure 8(a) and 8(b), respectively. We can see that the information

NH
CB

400

300

200

100

)
s
(
 

e
m

i
t
 

i

g
n
n
n
u
r

NH
CB

600

500

400

300

200

100

)
s
(
 
e
m

i

i
t
 
g
n
n
n
u
r

0
100

200

300

n (in thousands)

400

500

0
100

200

300

n(in thousands)

400

500

(a) SAL-7

(b) INC-7

Fig. 9. Running time vs. Cardinality n

416

X. He et al.

loss of these methods on both two data sets decreases with the growth of n. This
observation can be attributed to the fact that when the table size increases more
tuples will share the same or quite similar QI-attributes. As a result, it is easier
for the partitioning strategies to ﬁnd very similar tuples to generalize. Similar
to previously experimental results, our method is the clear winner since infor-
mation loss of CB is signiﬁcantly small than that of NH, which is consistently
observed for various database size.

6.4 Eﬃciency

Finally, we evaluate the overhead of performing anonymization. Figure 9(a) and
9(b) show the computation cost of the these anonymization methods on two
data sets, respectively. We compare CB with NH when evaluating computational
cost. The running time of tow algorithms increases linearly when n grows from
100k to 500k, which is expected since more tuples that need to be anonymized
will cost longer time to ﬁnish the anonymization procedure. The NH method
is more eﬃcient. Comparison results show that the advantages of our method
in anonymization quality do not come for free. However, in the worst case, our
algorithm can be ﬁnished in 500 seconds, which is acceptable. In most real appli-
cations quality is more important than running time, which justiﬁes the strategy
to sacriﬁce certain degree of time performance to achieve higher data utility.

Summary. Above results clearly show that clustering-based anonymization
achieves less information loss than the non-homogeneous anonymization (NH)
in cases where the dimensionality of QI-attribute d > 3 . NH has a good perfor-
mance when the domain size is small, and the dimensionality of QI-Attributes
is low. This is due to its greedy partitioning algorithm.

7 Conclusion

As privacy becomes a more and more serious concern in applications involving
microdata, good anonymization is of signiﬁcance. In this paper, we propose an
algorithm which is based on clustering to produce a utility-friendly anonymized
version of microdata. Our extensive performance study shows that our methods
outperform the non-homogeneous technique where the size of QI-attribute is
larger than 3.

Acknowledgement. This work was supported in part by the National Nat-
ural Science Foundation of China (NO.6090303, NO.60902097, NO.60973047),
the Natural Science Foundation of Zhejiang Province of China under Grant No.
Y1091189 and No.Y1090571, the Research Fund for the Doctoral Program of
Higher Education(No. 20090072120056), the Special Fund for Information De-
velopment of Shanghai (No. 200901015), the National High-Tech Research and
Development Plan of China (No. 2008AA04Z106), the Project of Science and
Technology Commission of Shanghai Municipality (NO.08DZ1122300), and the
Major Scientiﬁc & Technology Speciﬁc Programs of Zhejiang Province for Key
Industrial Project(No.2011C11042).

Clustering-Based k-Anonymity

417

References

1. Sweeney, L.: k-anonymity: a model for protecting privacy. Int. J. Uncertain. Fuzzi-

ness Knowl.-Based Syst. 10(5), 557–570 (2002)

2. Samarati, P.: Protecting respondents’ identities in microdata release. TKDE 13(6),

1010–1027 (2001)

3. Samarati, P., Sweeney, L.: Generalizing data to provide anonymity when disclosing

information. In: PODS 1998, p. 188. ACM, New York (1998)

4. MacQueen, J.B.: Some methods for classiﬁcation and analysis of multivariate ob-

servations, Berkeley, pp. 281–297 (1967)

5. Kalnis, P., Ghinita, G., Mouratidis, K., Papadias, D.: Preventing location-based
identity inference in anonymous spatial queries. TKDE 19(12), 1719–1733 (2007)
6. Mokbel, M.F., Chow, C.-Y., Aref, W.G.: The new casper: query processing for lo-
cation services without compromising privacy. In: VLDB 2006, pp. 763–774 (2006)
7. Machanavajjhala, A., Gehrke, J., Kifer, D., Venkitasubramaniam, M.: l-diversity:

Privacy beyond k-anonymity. In: ICDE 2006, p. 24 (2006)

8. Li, N., Li, T.: t-closeness: Privacy beyond k-anonymity and l-diversity. In: KDD

2007, pp. 106–115 (2007)

9. Xu, J., Wang, W., Pei, J., Wang, X., Shi, B., Fu, A.W.-C.: Utility-based anonymiza-

tion using local recoding. In: KDD 2006, pp. 785–790. ACM (2006)

10. Ghinita, G., Karras, P., Kalnis, P., Mamoulis, N.: Fast data anonymization with

low information loss. In: VLDB 2007, pp. 758–769. VLDB Endowment (2007)

11. Fung, B.C.M., Wang, K., Yu, P.S.: Top-down specialization for information and

privacy preservation, pp. 205–216 (2005)

12. LeFevre, K., DeWitt, D.J., Ramakrishnan, R.: Workload-aware anonymization. In:

KDD 2006, pp. 277–286. ACM, New York (2006)

13. Wong, W.K., Mamoulis, N., Cheung, D.W.L.: Non-homogeneous generalization in
privacy preserving data publishing. In: SIGMOD 2010, pp. 747–758. ACM, New
York (2010)

14. LeFevre, K., DeWitt, D.J., Ramakrishnan, R.: Incognito: eﬃcient full-domain k-

anonymity. In: SIGMOD 2005, pp. 49–60. ACM, New York (2005)

15. Iwuchukwu, T., Naughton, J.F.: K-anonymization as spatial indexing: toward scal-

able and incremental anonymization. In: VLDB 2007, pp. 746–757 (2007)

16. LeFevre, K., DeWitt, D.J., Ramakrishnan, R.: Mondrian multidimensional k-

anonymity. In: ICDE 2006, Washington, DC, USA, p. 25 (2006)

17. Gionis, A., Mazza, A., Tassa, T.: k-anonymization revisited. In: ICDE 2008, pp.

744–753. IEEE Computer Society, Washington, DC (2008)

18. Bayardo, R.J., Agrawal, R.: Data privacy through optimal k-anonymization. In:

ICDE 2005, pp. 217–228. IEEE Computer Society, Washington, DC (2005)


