Semi-supervised Clustering

on Heterogeneous Information Networks

Chen Luo1, Wei Pang2, and Zhe Wang1,(cid:2)

1 College of Computer Science and Technology, Jilin University,

Changchun 130012, China

rackingroll@163.com, wz2000@jlu.edu.com

2 School of Natural and Computing Sciences, University of Aberdeen,

Aberdeen, AB24 3UE, UK

pang.wei@abdn.ac.uk

clustering

on

information

Abstract. Semi-supervised
networks
combines both the labeled and unlabeled data sets with an aim to im-
prove the clustering performance. However, the existing semi-supervised
clustering methods are all designed for homogeneous networks and do
not deal with heterogeneous ones. In this work, we propose a semi-
supervised clustering approach to analyze heterogeneous information
networks, which include multi-typed objects and links and may contain
more useful semantic information. The major challenge in the clustering
task here is how to handle multi-relations and diverse semantic meanings
in heterogeneous networks. In order to deal with this challenge, we intro-
duce the concept of relation-path to measure the similarity between two
data objects of the same type. Thereafter, we make use of the labeled
information to extract diﬀerent weights for all relation-paths. Finally, we
propose SemiRPClus, a complete framework for semi-supervised learn-
ing in heterogeneous networks. Experimental results demonstrate the
distinct advantages in eﬀectiveness and eﬃciency of our framework in
comparison with the baseline and some state-of-the-art approaches.

Keywords: Heterogeneous information network, Semi-supervised clus-
tering.

1

Introduction

The real world is interconnected: objects and inter-connections between these ob-
jects constitute various information networks. Clustering methods in information
networks [1] become more and more popular in recent years. One can discover
much interesting knowledge from the information networks by using appropriate
clustering methods, and the clustering result can also be used in many ﬁelds
such as information retrieval [2] and recommendation systems [3]. In particular,
the real world information networks are often heterogeneous [4], which means in
these networks objects and links between these objects may belong to diﬀerent

(cid:2) Corresponding Author.

V.S. Tseng et al. (Eds.): PAKDD 2014, Part II, LNAI 8444, pp. 548–559, 2014.
c(cid:2) Springer International Publishing Switzerland 2014

Semi-supervised Clustering on Heterogeneous Information Networks

549

types. In order to handle the multi-relational data in heterogeneous networks,
semi-supervised learning methods [5] can be an appropriate tool. In this paper,
we focus on the semi-supervised clustering task in heterogeneous information
networks.

Up till now many semi-supervised clustering algorithms have been proposed
for information networks [6, 7, 8]. Some of these algorithms consider the labeled
information as constraints for clustering tasks [6]. These constraints can guide
the clustering process to achieve better results. Others focus on semi-supervised
learning on graphs [7], which uses a small portion of labeled objects to label all
the other objects in the same network by propagating the labeled information.
The semi-supervised algorithm, proposed in [8], integrates both the constraint-
based learning and distance-function learning methods. All the above-mentioned
link-based clustering methods are speciﬁcally designed for homogeneous infor-
mation networks, in which all the links in the network are assumed to be of the
same type [1]. However, most of the real-world networks are heterogeneous ones
[4]. In KDD-2012, Sun et.al proposed PathSelClus [9], a user guided clustering
method in heterogeneous information networks. PathSelClus integrates both the
meta-path selection and clustering processes. The experimental results produced
by PathSelClus also showed that more meaningful results could be obtained by
considering the clustering task on the heterogeneous information networks in-
stead of the homogeneous ones. However, in PathSelCLus, the number of clusters
needs to be pre-speciﬁed at the beginning of the algorithm, which is not realistic
in many real-world problems.

In this paper, we will investigate semi-supervised clustering [5] in heteroge-
neous information networks, and intend to develop a clustering algorithm that
does not need to pre-specify the number of clusters. In a heterogeneous infor-
mation network, two objects may be connected via diﬀerent relation paths or
sequences of relations [9]. These diﬀerent relation paths have diﬀerent semantic
meanings. For example, in the academic community network, two authors can
be connected via either the co-author relationship or the co-institution relation-
ship, but these two relations have very diﬀerent meanings. Sun et.al proposes
the concept of ‘meta-path’ [10] to indicate the relation sequence. In this research
we propose a similar deﬁnition —‘relation-path’, which is speciﬁcally for our
clustering task. Correspondingly, we also propose a topological measure for our
relation-path, which is diﬀerent from existing path topological measures [10, 11].
By using a logistic regression approach, we evaluate each weight of the relation-
path. Finally, SemiRPClus, a novel framework for clustering in heterogeneous
information network, is presented. Experiments on DBLP showed the distinct
advantages in eﬀectiveness and eﬃciency of SemiRPClus in comparison with
some clustering methods on information networks.

The rest of this paper is organized as follows: in Section 2 some important
deﬁnitions used in this paper are introduced. The proposed framework, named
SemiRPClus, is described in Section 3. In Section 4, we present a series of exper-
iments on DBLP, which demonstrated the eﬀectiveness and eﬃciency of SemiR-
PClus. Finally, we conclude our work in Section 5.

550

C. Luo, W. Pang, and Z. Wang

(cid:2)m
i=1

2 Problem Deﬁnition
As in [4], we use G = (cid:2)V, E, W(cid:3) to represent a heterogeneous network, where
Xi, and X1 = {x11, ..., x1n1}, ..., Xm = {xm1, ..., xmnm} denote the m
V =
diﬀerent types of nodes. E is the set of links between any two data objects of V ,
and W is the set of weight values on the links. TG = (cid:2)A, R(cid:3) denotes the network
schema [10], which is a directed graph deﬁned over object types A, with edges
as relations from R. For more details about heterogeneous networks, please refer
[4, 10]. First, the semi-supervised clustering in heterogeneous network is given
below:

.

Deﬁnition 1 (Semi-supervised clustering in heterogeneous informa-
tion network). In a heterogeneous information network G = (cid:2)V, E, W(cid:3) fol-
lowing a network schema TG = (cid:2)A, R(cid:3), suppose V (cid:3)
is a subset of V and V (cid:3) ⊆
V ∈ Xi, where Xi is the target type for clustering, and each data object O in V (cid:3)
is labeled with a value γ indicating which cluster O should be in. Given a set of
relation-path (see Deﬁnition 2), the learning task is to predict the labels for all
the unlabeled objects V − V (cid:3)
Second, we give the deﬁnition of relation-path, which can be considered as a
special case of meta-path [10]:
Deﬁnition 2 (Relation-path). Given a network schema TG = (cid:2)A, R(cid:3), a
Rl−l→ At, which deﬁnes
relation-path RP is in the form of At
a composite relation RP = R1 ◦ R2 ◦ ... ◦ Rl−1 between two objects in the same
target type At, and ◦ is the composition operator on relations.
Diﬀerent from the deﬁnition of meta-path [10], in relation-path the starting ob-
ject and the end object of the relation-path must belong to the same target type.
From Deﬁnition 2 we can see that a relation-path is always a meta-path, but not
vice versa. More importantly, as the relation-path is deﬁned for objects of the
same target type, it will be more suitable for our clustering task. Third, we deﬁne
a transform of our relation-path named ‘inverse relation-path’ as follow:

R2→ ...Al−1

R1→ A2

R1→
Rl−l→ At, RP −1 is the Inverse Relation-path of RP , if RP −1 is

Deﬁnition 3 (Inverse Relation-path). Given a relation-path RP : At
A2
At

Rl→ At, where R−1 is the inverse relation of R.

R2→ ...Al−1
−1→ Al−1

Rl−1

Rl−2

−1→ ...A1

After deﬁning all the above concepts, we introduce a typical heterogeneous in-
formation network used in the experiments of our research: the DBLP network,
which has been used as test cases in a number of papers [12, 4, 9].

Example 1 (The DBLP bibliographic network). DBLP, computer science bib-
liography database, is a representative of heterogeneous information networks.
The DBLP schema is shown in Figure 1. There are four types of objects in the
schema: Paper, Author, Term, and Conference. Links between Author and Pa-
per are deﬁned by the relation of ”write” and ”written by”, denoted as ”write−1”.

Semi-supervised Clustering on Heterogeneous Information Networks

551

Relation between Term and Paper is ”mention” and ”mentioned by”, denoted
as ”mention−1”. Relation between Paper and Conference is ”publish” and ”pub-
lished by”, denoted as ”publish−1”. The ”cite” relation exists between the papers
in the schema. In this research we extract the ”cite” relation from the Microsoft
Academic Search API.

Term

cite/cite-1

mention/mention-1

Paper

write/write-1

publish/publish-1

Author

Conf.

Fig. 1. DBLP schema

3 The SemiRPClus Framework

As mentioned in [4], there are two constraints which determine the clustering
results on heterogeneous information networks: ﬁrst, the clustering result should
be consistent with the network structure; second, the clustering results should
be consistent with the labeled information pre-assigned for some data objects.
Our semi-supervised clustering process will follow these two constraints.

In this section, we ﬁrst introduce in detail the proposed framework, SemiRP-
Clus, which includes two components: (1) the linear regression based topological
measure and (2) the relation extraction model. Then we present the overall clus-
tering framework.

3.1 Linear Regression Based Topological Measure

Topological features, also called structural features, are connectivity properties
extracted from a network for some pairs of objects. Many topological features
have been proposed for the homogeneous networks, and see more details in [13].
There are also some topological features proposed for heterogeneous networks,
and we redeﬁne them based on relation-path as below:

- Path Count Measure [12]. Given a relation-path, denoted as RP , the Path
Count can be calculated as the number of path instances of RP between two
RP (xt,i, xt,j), where xt,i, xt,j ∈ Xt
objects, say xt,i and xt,j, denoted as SP C
and Xt is the target type.

- Random Walk Measure [12]. Random walk measure following a relation-
RP (xt,i, :) de-

path RP is deﬁned as SRW
notes the path count value following RP starting from x(t,i).

RP (xt,i, xt,j) =

. Here, SP C

SP C

RP (xt,i,xt,j )
SP C

RP (xt,i,:)

552

C. Luo, W. Pang, and Z. Wang

- PathSim Measure [10]. Given a relation-path RP , PathSim between two

objects xt,i, xt,j is deﬁned as :

SP S
RP (xt,i, xt,j ) =

2∗SP C

RP (xt,i,xt,j)

SP C

RP (xt,i,xt,i)+SP C

RP−1 (xt,j ,xt,j )

RP is a path count measure. In the above RP −1 denotes the inverse
Here, SP C
path-relation of RP (see Deﬁnition 3);
- HeteSim Measure [11]: Given a relation-path RP = R1 ◦ R2 ◦ ... ◦ Rl (as

in Deﬁnition 2), HeteSim [11] is deﬁned as follows:
SHS
RP (R1◦R2◦...◦Rl)(xt,i, xt,j) =
(cid:2)|I(xt,j |Rl)|

(cid:2)|O(xt,i|R1)|

p=1

q=1

RP (R2◦R3◦...◦Rl−1)(Op(xt,i|R1),Iq(xt,j|Rl))
SHS

SP C

RP (xt,i,:)+SP C

RP−1 (:,xt,j)

In the above, xt,i, xt,j ∈ Xt, O(xt,i|R1) is the set of out-neighbors of xt,i
based on relation R1, and I(xt,j|Rl) is the set of in-neighbors of xt,j based
on relation Rl.

All the above-described topological measures only focus on the topological
structure of the networks. However, in the semi-supervised clustering process,
diﬀerent labeled information will lead to diﬀerent similarity measures and dif-
ferent clustering results [9]. As a result, we propose a linear regression based
measure which considers the small amount of labeled information. We use the
labeled information as guidance, and propose a linearly combined measure, which
is deﬁned as follows:

SLS
RP (xt,i, xt,j) =

m(cid:3)

d=1

αdsd(xt,i, xt,j)

(1)

RP is the linear regression based measure of xt,i, xt,j ∈ Xt, and
where SLS
s(xt,i, xt,j) = [s1(xt,i, xt,j ), s2(xt,i, xt,j), ..., sm(xt,i, xt,j)]T is the topological fea-
tures following the given relation-path RP , and each feature is calculated us-
ing one of the formulae introduced at the beginning of this section, and m is
the number of measures used in the framework. For example, s1(xt,i, xt,j) =
SP C
RP (xt,i, xt,j), s2 = SRW
RP (xt,i, xt,j).
Here, α = [α1, α2, ..., αm]T denotes the weights for all measures. An optimization
algorithm can be used to solve the following approximation problem:
(cid:4)
(cid:4)
(cid:4)
(cid:4)
αdsd(xt,i, xt,j))
(cid:4)
(cid:4)

(R(xt,i, xt,j ) − m(cid:3)

RP (xt,i, xt,j), s3 = SP S

RP (xt,i, xt,j), s4 = SHS

αopt = arg minα

(cid:4)
(cid:4)
(cid:4)
(cid:4)
(cid:4)
(cid:4)

n(cid:3)

n(cid:3)

(2)

i=1

j=1

d=1

In the above, n denotes the number of labeled objects. Matrix R is obtained

from the pre-labeled information as follow:

Semi-supervised Clustering on Heterogeneous Information Networks

553

(cid:5)

R(xt,i, xt,j) =

1 xt,i, xt,j are labeled as the same label
0

(3)
where xt,i, xt,j ∈ Xt and Xt is the target type for clustering. Eq. (2) is actually
a linear regression problem, which can be eﬃciently solved by many existing
algorithms [14]. In this paper, we use the gradient descent method [14] to solve
this problem.

otherwise

3.2 Relationship Extraction Model

In our clustering task, given a set of relation-paths, each object within the target
type may be connected via these relation-paths. By using these relation-paths, a
heterogeneous information network can be reduced into a multi-relational net-
work [15], in which the objects correspond to those of the target type in the
original heterogeneous network and the diﬀerent relations correspond to the
given diﬀerent relation-paths.

Similar to the model proposed in [15], the basic motivation of our relationship
extraction model is as follows: diﬀerent relation-paths correspond to diﬀerent re-
lation graphs1, which can provide diﬀerent clustering results. By combining these
diﬀerent clustering results through diﬀerent weights of corresponding relation-
paths, the ﬁnal clustering result may be improved [15]. In this paper, logistic
regression method [16] is used to handle the relation extraction problem.

The set of pre-labeled objects of the target type are regarded as the training
set. Each two objects in the labeled set is regarded as a training pair, denoted
as xt,i, xt,j ∈ Xt, and Xt is the target type for clustering. We ﬁrst extract the
topological features for these objects, and then build an extraction model to
learn the weight values associated with these features. For each training pair
xt,i, xt,j ∈ Xt, all the features are calculated by the linear regression based
measure as in Eq. (1), denoted as F = [f1, f2, ..., fd], where d is the number
of relation-paths between the two objects. Here we denote the training set as
X T rain = [X 1, X 2, ..., X n], where X i denotes the i − th training pair, and n is
the number of pairs in the training set. We deﬁne yi as a label indicating whether
these two objects are in the same cluster: if these two objects are in the same
cluster, yi = 1, and 0 otherwise, which is denoted as Y T rain = [y1, y2, ..., yn],
where yi ∈ {0, 1}. The set of weights for all relation-paths is denoted as Λ =
[λ1, λ2, ..., λd]. We use the Entropy maximization [17] method to calculate Λ:
ﬁrst, the conditional probability of the two objects in X i belong to the same
cluster can be modeled as:

pΛ(y = yi|X i) =

1

Z(X i)

d(cid:3)

exp(

fi(X i) ∗ λi)

i=1

(4)

1 A relation graph is a homogeneous network reduced by the heterogeneous network

using a typical relation-path.

554

C. Luo, W. Pang, and Z. Wang

where Z is the normalization term calculated as Z(X i) = 1+exp(

fi(X i)∗
λi). Second, we use the MLE (Maximum Likelihood Estimation) approach to de-
rive Λ by maximizing the likelihood of all the training pairs:

(cid:6)d

i=1

L(Λ) =

n(cid:7)

[pΛ(y = yi|X i)]yi

[pΛ(y = yi|X i)]1−yi

i

Third, Λ = [λ1, λ2, ..., λd] can be obtained as follows:

Λ∗

= arg maxΛ=[λ1,λ2,...,λd]L(Λ)

(5)

(6)

In this research we use the gradient descent [14] method to calculate Λ∗

. Fi-
nally the combined aﬃnity matrix W combine is deﬁned by the following equation:

d(cid:3)

λi ∗ Wi

W combine =

i=0

(7)
Here Wi is the similarity matrix of i − th homogeneous network reduced by
i − th relation-path. It is noted that the similarity of each two objects in Wi
is calculated by the measure introduced in section 3.1. We can see from the
Eq. (7) that the combined aﬃnity matrix W combine is a linear combination of
diﬀerent relation graphs. After obtaining W combine, we then perform clustering
on W combine to obtain the ﬁnally result.

3.3 The Detailed Steps of SemiRPClus

After presenting the calculation method for each relevant variable, the detailed
steps of SemiRPClus is given as follows:
Step 1 Given a heterogeneous information network G = (cid:2)V, E, W(cid:3), a set of
relation-paths, the target type Xt for clustering and labeled information Y .

Step 2 Use Eq. (3) to calculate the relation matrix R.
Step 3 Calculation of the linear based similarity measure

Step 3-a Calculate each kind of relation-path measure using the measure

methods introduced in Section 3.1.

Step 3-b Use Eq. (2) to calculate the weight α = [α1, α2, ..., αm]T for each

measure.

Step 3-c Calculate the linear based similarity SLS

RP using Eq. (1).

Step 4 Use Eq. (6) to obtain the weight of each relation-path: Λ = [λ1, λ2, ..., λd],

then use Eq. (7) to calculate the combine aﬃnity matrix W combine.

Step 5 Cluster the relation matrix W combine to obtain the ﬁnal clustering re-

sult.

It is pointed out that many useful clustering methods [15, 18] can be used in
Step 5, no matter whether the cluster number is pre-assigned or not.

Semi-supervised Clustering on Heterogeneous Information Networks

555

3.4 Complexity Analysis

In this section, we consider the time complexity of the SemiRPClus. At the be-
ginning of our framework, all the traditional topological features are calculated,
and the time complexity is O(kpathn2). Here kpath is the number of relation-paths
selected for the framework, and n is the number of target objects. For the linear
m |Tm|). Here
based measure calculation process, the time complexity is O(t1
t1 is the number of iterations, and m is the dimension of the training dataset. For
m |Tm|). Here
the Relationship Selection Model, the time complexity is O(t2
t2 is the number of iterations of this model. Assuming that the time complexity
of the clustering used in Step 5 is Ocluster, the overall time complexity of our
framework is O(kpathn2) + O(t1

m |Tm|) + Ocluster.

(cid:6)

(cid:6)

m |Tm|) + O(t2

(cid:6)

(cid:6)

4 Experimental Results

In this section, we use the DBLP dataset2 as a test bed to evaluate both the
eﬀectiveness and eﬃciency of our approach compared with some existing meth-
ods.

4.1 Datasets

The DBLP dataset is used for the performance test. Following [9], we extract
a sub network of DBLP, “four-area dataset”, which contains 20 major confer-
ences in four areas: Data Mining, Database, Information Retrieval and Machine
Learning. Each area contains ﬁve top conferences. In this dataset, the term is
extracted from the paper titles, and the paper citation relationship is obtained
by the Microsoft academic search API3. We use the following three datasets for
our experiments.

DataSet-1 top 100 authors in the DBLP within the 20 major conferences, and

the corresponding papers published by these authors after 2007.

DataSet-2 top 500 authors in the DBLP within the 20 major conferences, and

the corresponding papers.

DataSet-3 top 2000 authors in the DBLP within the 20 major conferences, and

the corresponding papers published by them after 2007.

The ground truth used in our experiment is obtained from the “four-area
dataset [9]”. It is pointed out that the labeled information and the true clustering
result are all obtained from the ground truth.
As in [12], we choose 10 types of relation-paths as bellow: author − paper −
author, author → paper → paper − author, author → paper ← paper →
author, author → paper → conf erence ← paper ← author, author → paper ←
author → paper ← author, author → paper → term ← paper ← author,
author → paper → paper → paper ← author, author → paper → paper ←

2

3

http://www.informatik.uni-trier.de/~ley/db/
http://academic.research.microsoft.com/

556

C. Luo, W. Pang, and Z. Wang

paper ← author, author → paper ← paper ← paper ← author, author →
paper ← paper → paper ← author. For example, author − paper − author
denotes the co-author relationship, and author → paper ← paper → paper ←
author denotes two authors’ papers are cited in the same paper.

4.2 Case Study on Eﬀectiveness

In this section, we study the eﬀectiveness of our algorithm by comparing it with
several existing methods on the three datasets given in Section 4.1. For the ease
of comparison, we choose the hierarchical-cluster algorithm [19] to cluster the
similarity matrix, and the cluster number is pre-assigned as the input of the
cluster algorithm.

Three clustering methods are used in our experiment for comparison: Path-
SelClus [9], GNetMine [20] and LP [7]. The ﬁrst two algorithms are proposed for
heterogeneous networks, and they are regarded as the state-of-the-art clustering
algorithms. LP is proposed for homogeneous network, thus we use two homoge-
neous networks reduced by two corresponding relation-paths. The two selected
relation-paths have the highest weight in SemiRPClus.

Two evaluation methods are used for testing the clustering result: Accuracy
[9], which is calculated as the percentage of target objects clustered into the
correct clusters; and Normalized Mutual Information (NMI) [9], which is one
of the most popular evaluation methods to evaluate the quality of clustering
results.

The clustering results are presented in Table 1. In the table, performance
under diﬀerent percentage of labeled information (5%, 10% and 20%) in each
cluster is tested. All the results are averaged for 10 times. In Table 1, results in
bold indicate the best performance among all algorithms.

From Table 1 we see that the performance of SemiRPClus is comparable with
PathSelClus and GNetMine, and better in some cases. From the result we can
also see that SemiRPClus can have a better result evaluated by NMI in some
cases. NMI considers not only the accuracy, but also the distribution of the
objects within each cluster. From this perspective, SemiRPClus is more eﬀective
than the other three algorithms. The LP algorithm always performs worse than
all other three heterogeneous clustering algorithms. This demonstrates that by
considering the heterogeneous information better results can be obtained. On
the other hand, we can see that mining heterogeneous networks can gain more
useful information than homogeneous ones.

4.3 Case Study on Eﬃciency

In this section, we study the eﬃciency of SemiRPClus. We use the same hard-
ware conﬁguration to run SemiRPClus and the other three algorithms. Every
algorithm is run 10 trials and the average performance is calculated. The CPU
execution time for each algorithm is showed in Fig. 2. It is pointed out that we
use LP-RP1 to represent LP algorithm in this section. In Fig. 2, we can see that

Semi-supervised Clustering on Heterogeneous Information Networks

557

Table 1. Cluster Accuracy and NMI for Three Dataset

Labeled Evaluation SemiRPClus LP-RP14 LP-RP55 PathSelClus GNetMine

Dataset-1

5%
5%
10%
10%
20%
20%

Dataset-2

5%
5%
10%
10%
20%
20%

Dataset-3

5%
5%
10%
10%
20%
20%

NMI

Accuracy

NMI

Accuracy

NMI

Accuracy

NMI

Accuracy

NMI

Accuracy

NMI

Accuracy

NMI

Accuracy

NMI

Accuracy

NMI

Accuracy

.048±.015 .078±.012 .020±.002 .457±.095 .387±.089
.380±.021 .350±.036 .280±.016 .570±.040 .520±.073
.318±.032 .056±.021 .031±.015 .523±.026 .408±.127
.510±.024 .320±.041 .390±.012 .710±.096 .550±.048
.696±.032 .069±.009 .036±.009 .541±.081
.488±.057
.680±.042 .320±.023 .320±.084 .730±.070 .620±.058
.621±.103 .014±.007 .004±.008 .609±.045 .677±.042
.720±.087 .306±.085 .272±.052 .786±.116 .884±.034
.698±.038 .023±.010 .006±.005 .646±.073
.664±.117
.736±.085 .316±.034 .284±.094 .830±.042 .664±.042
.774±.034 .026±.006 .013±.024 .718±.049
.702±.039
.862±.046 .356±.088 .282±.044 .854±.0350 .900±.028
.621±.045
.798±.046 .001±.006 .007±.002 .652±.089
.750±.048 .254±.012 .207±.034 .872±.015 .862±.065
.759±.095 .003±.014 .004±.002 .664±.015
.632±.015
.784±.014 .254±.074 .271±.045 .880±.034 .868±.034
.868±.015 .002±.001 .004±.002 .697±.095
.676±.024
.800±.031 .261±.049 .275±.041 .897±.012 .889±.025

SemiRPClus is more eﬃcient than PathSelClus and GNetMine: it is three to
four orders of magnitude faster than PathSelClus in all experiments.

4.4 Case Study on Relation Path Weight

In this section, we study the learned weights for diﬀerent relation-paths obtained
by SemiRPClus compared with PathSelClus. As the ranking of the relation-paths
showed in Table 2, the ranking learned by SemiRPClus is fundamentally the same
as the ranking learned by the PathSelClus.
From the result we can see the relation-path author − paper − author always
has a more trusted weight than other relation paths. This is consistent with
human intuition: two authors having the co-author relationship means that they
are very likely to have a very similar research interest. On the other hand, the
relation-path author → paper → term ← paper ← author has the lowest weight
in both algorithms. This is consistent with real-world scenarios: it is not rare
that two papers from diﬀerent areas can have the same term. For example, the
words “optimization” and “method” appear in many papers from diﬀerent areas.
4 author − paper − author.
5 author → paper ← author → paper ← author.

558

C. Luo, W. Pang, and Z. Wang

)
d
n
o
c
e
s
(
 
E
M
I
T
 
N
O
I
T
U
C
E
X
E
 
U
P
C

102

100

10−2

10−4

 

PathSelClus

GNetMine

SemiRPClus

 

LP

0.05

0.1

SEED FRACTION

0.2

)
d
n
o
c
e
s
(
 
E
M
I
T
 
N
O
I
T
U
C
E
X
E
 
U
P
C

104

102

100

10−2

 

PathSelClus

GNetMine

SemiRPClus

 

LP

0.05

0.1

SEED FRACTION

0.2

)
d
n
o
c
e
s
(
 
E
M
I
T
 
N
O
I
T
U
C
E
X
E
 
U
P
C

104

102

100

10−2

 

PathSelClus

GNetMine

SemiRPClus

 

LP

0.05

0.1

SEED FRACTION

0.2

(a) Eﬃciency in DataSet-1

(b) Eﬃciency in DataSet-2

(c) Eﬃciency in DataSet-3

Fig. 2. Running time of SemiRPClus compared with the other three algorithms

Table 2. Relation-Paths Weight Comparison

Rank PathSelClus

PathSelClus
A − P − A

A − P − A6
A → P ← A → P ← A A → P ← A → P ← A
A → P ← P ← P ← A A → P ← P → P ← A
A → P ← P → A
A → P → P − A
A → P → T ← P ← A
A → P ← P → A
A → P → P → P ← A A → P → P − A
A → P → T ← P ← A A → P → P → P ← A
A → P ← P → P ← A A → P → C ← P ← A
A → P → C ← P ← A A → P ← P ← P ← A
A → P → T ← P ← A A → P → T ← P ← A

1
2
3
4
5
6
7
8
9
10

5 Conclusions and Future Work

In this work, we explore the semi-supervised clustering analysis in heterogeneous
information networks. Firstly, a similarity measure, which is more suitable for the
semi-supervised clustering task, is proposed for measuring the similarity between
objects in heterogeneous information networks. Secondly, a logistic regression
model is used for extracting the relations. At last, an overall computational
framework is proposed to perform semi-supervised clustering in heterogeneous
information networks. Experimental results on the DBLP dataset demonstrate
the eﬀectiveness and eﬃciency of SemiRPClus.

In the future, we intend to apply SemiRPClus to more real-world clustering
problems. In addition, another direction of our future research is to explore the
potential of SemiRPClus on big data problems, such as massive social media
and bioinformatics problems.

Acknowledgements. WP is supported by the partnership fund from dot.rural,
RCUK Digital Economy research. This work is supported by the National Nat-
ural Science Foundation of China (NSFC) under Grant No. 61373051; the Na-
tional Science and Technology Pillar Program (Grant No. 2013BAH07F05), Jilin
Province Science and Technology Development Program (Grant No. 20111020);

6 A: author, P: paper, C: conference, T: term.

Semi-supervised Clustering on Heterogeneous Information Networks

559

Project of Science and Technology Innovation Platform of Computing and Soft-
ware Science (985 engineering), and the Key Laboratory for Symbolic Compu-
tation and Knowledge Engineering, Ministry of Education, China.

References

[1] Fortunato, S.: Community detection in graphs. Physics Reports 486(3), 75–174

(2010)

[2] Lipka, N., Stein, B., Anderka, M.: Cluster-based one-class ensemble for classiﬁ-
cation problems in information retrieval. In: SIGIR 2012, pp. 1041–1042. ACM
(2012)

[3] Pham, M.C., Cao, Y., et al.: A clustering approach for collaborative ﬁltering rec-

ommendation using social network analysis. J. UCS 17(4), 583–604 (2011)

[4] Sun, Y., Han, J., Zhao, P., et al.: Rankclus: integrating clustering with ranking for
heterogeneous information network analysis. In: ICDT 2009, pp. 565–576. ACM
(2009)

[5] Zhu, X.: Semi-supervised learning literature survey. Computer Science, University

of Wisconsin-Madison 2, 3 (2006)

[6] Basu, S., Banerjee, A., Mooney, R.J.: Semi-supervised clustering by seeding. In:

ICML, vol. 2, pp. 27–34 (2002)

[7] Zhou, D., Bousquet, O., Lal, T.N., et al.: Learning with local and global consis-
tency. Advances in Neural Information Processing Systems 16(16), 321–328 (2004)
[8] Bilenko, M., Basu, S., Mooney, R.J.: Integrating constraints and metric learning

in semi-supervised clustering. In: ICML, p. 11. ACM (2004)

[9] Sun, Y.E.: Integrating meta-path selection with user-guided object clustering in
heterogeneous information networks. In: KDD 2012, pp. 1348–1356. ACM (2012)
[10] Sun, Y., Han, J., Yan, X., Yu, P.S., Wu, T.: Pathsim: Meta path-based top-k

similarity search in heterogeneous information networks. In: VLDB 2011 (2011)

[11] Shi, C., Kong, X., Yu, P.S., Xie, S., Wu, B.: Relevance search in heterogeneous

networks. In: ICDT 2012, pp. 180–191. ACM (2012)

[12] Sun, Y., Barber, R., Gupta, M., et al.: Co-author relationship prediction in het-
erogeneous bibliographic networks. In: ASONAM 2011, pp. 121–128. IEEE (2011)
[13] L¨u, L., Zhou, T.: Link prediction in complex networks: A survey. Physica A:

Statistical Mechanics and its Applications 390(6), 1150–1170 (2011)

[14] Montgomery, D.C., Peck, E.A., Vining, G.G.: Introduction to linear regression

analysis, vol. 821. Wiley (2012)

[15] Cai, D., Shao, Z., He, X., Yan, X., Han, J.: Mining hidden community in hetero-

geneous social networks. In: LinkKDD, pp. 58–65. ACM (2005)

[16] Hosmer Jr., D.W., Lemeshow, S., Sturdivant, R.X.: Applied logistic regression.

Wiley. com (2013)

[17] Berger, A.L., Pietra, V.J.D., Pietra, S.A.D.: A maximum entropy approach to

natural language processing. Computational Linguistics 22(1), 39–71 (1996)

[18] Frey, B.J., Dueck, D.: Clustering by passing messages between data points. Sci-

ence 315(5814), 972–976 (2007)

[19] Murtagh, F.: A survey of recent advances in hierarchical clustering algorithms.

The Computer Journal 26(4), 354–359 (1983)

[20] Ji, M., Sun, Y., Danilevsky, M., Han, J., Gao, J.: Graph regularized transductive
classiﬁcation on heterogeneous information networks. In: Balc´azar, J.L., Bonchi,
F., Gionis, A., Sebag, M. (eds.) ECML PKDD 2010, Part I. LNCS (LNAI),
vol. 6321, pp. 570–586. Springer, Heidelberg (2010)


